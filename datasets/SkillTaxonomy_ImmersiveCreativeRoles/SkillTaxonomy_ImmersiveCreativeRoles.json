{
  "dataset_metadata": {
    "id": "skilltax_immersive_creative_roles",
    "name": "Skill Taxonomy for Immersive Creative Roles",
    "version": "0.1.1",
    "created": "2025-11-15",
    "last_updated": "2025-11-20",
    "description": "This dataset provides a narrative, evidence-based taxonomy of immersive creative skills, derived from base datasets such as CDIM and Destination Marketing immersive outputs. Each skill includes human-readable explanations, real examples, references, and cross-domain relevance.",
    "license": "CC BY 4.0",
    "base_datasets": [
      {
        "id": "cdim",
        "name": "Creative Directors for Immersive Media",
        "url": "https://raw.githubusercontent.com/martin-sambauer/immersive-datasets/main/datasets/creative-directors-for-immersive-media/Creative%20Directors%20for%20Immersive%20Media.json",
        "description": "Practitioners, roles, and works relevant to immersive creative direction."
      },
      {
        "id": "dest_marketing",
        "name": "Destination Marketing Immersive Outputs",
        "url": "TBD",
        "description": "Immersive outputs used to extract destination-related skill requirements."
      }
    ],
    "target_audiences": [
      "curriculum_designers",
      "policy_makers",
      "public_sector_strategists",
      "practitioners",
      "ai_agents"
    ],
    "methodology": {
      "document": "methodology.md",
      "summary": "Each skill is created from evidence, examples and cross-domain analysis."
    }
  },
  "skills": [
    {
      "id": "skill_00001",
      "slug": "immersive_narrative_design_for_fulldome",
      "label": "Immersive narrative design for fulldome and planetarium domes",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "immersive_story_structure",
      "skill_type": "complex_competence",
      "description": "The ability to conceive, structure and articulate dome-native narratives that work across 360° environments. This skill includes understanding how audiences perceive motion, rhythm, visual gravity and focal cues inside a spherical space with no fixed frame. Practitioners translate scientific, conceptual or brand-related content into spatial story arcs that unfold around the viewer, relying on experiential dramaturgy rather than traditional linear framing.\n\nEvidence from the CDIM dataset illustrates this competence clearly: Jordan Belson’s role in the Vortex Concerts at the Morrison Planetarium demonstrates an early form of immersive narrative construction. Belson used the dome as an experiential environment, combining cosmic imagery, abstract movement, sound and spatial transitions to form non-linear but coherent journeys. His work shows how immersive narrative design requires a sensitivity to how images function on curved surfaces, how motion interacts with peripheral vision and how audiences respond when the entire field of view becomes expressive material.\n\nThis competence is not restricted to artistic fulldome work. Modern destination marketing uses large temporary domes and touring fulldome installations to communicate regional identity or brand values. Dome-based tourism showcases in major cities rely on immersive narrative design to shape visitor flow, anchor emotional meaning and translate complex cultural or economic messages into spatial experiences. Creative Directors working in these contexts must structure multi-sensory content so that it remains legible and emotionally effective regardless of where viewers sit or look.\n\nImmersive narrative design for fulldome is therefore a high-complexity, cross-domain competence. It combines conceptual storytelling, spatial dramaturgy, perceptual psychology and coordination across sound, visuals and technical projection systems.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_fulldome_large_format",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "fulldome_films",
        "planetarium_art_shows",
        "immersive_science_communication",
        "destination_brand_domes",
        "large_format_dome_events"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0004",
          "source_entity_slug": "jordan_belson",
          "evidence_type": "key_work_description",
          "evidence_summary": "Belson’s Vortex Concerts used the planetarium dome as an immersive narrative environment, combining abstract projection and electronic sound into coherent experiential journeys.",
          "references": [
            0,
            1
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Cosmic Cinema: Jordan Belson and the Vortex Concerts",
          "url": "https://www.e-flux.com/events/658274/cosmic-cinema-jordan-belson-and-the-vortex-concerts",
          "publisher": "e-flux",
          "year": 2024
        },
        {
          "id": 1,
          "title": "Jordan Belson – Center for Visual Music",
          "url": "https://centerforvisualmusic.org/Belson/",
          "publisher": "Center for Visual Music",
          "year": 2020
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00006"
      ],
      "tags": [
        "fulldome",
        "planetarium",
        "immersive_storytelling",
        "spatial_dramaturgy",
        "360_narrative_design",
        "visual_music"
      ],
      "notes": "A foundational immersive storytelling competence. Follow-up skills such as spatial composition, motion grammar and attention guidance will reference this skill as a parent or prerequisite.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00002",
      "slug": "spatial_image_composition_for_fulldome",
      "label": "Spatial image composition for fulldome and spherical projection",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "spatial_image_composition",
      "skill_type": "foundational_skill",
      "description": "The ability to design visual compositions that function correctly on a spherical or hemispherical surface, rather than on a flat frame. This skill includes understanding how horizons, verticals and diagonals distort when mapped to a dome, how visual weight is distributed above and around the viewer, and how to use these effects intentionally for storytelling.\n\nIn a fulldome context, spatial image composition means deciding where key elements appear in the dome (zenith, horizon band, lower field), how motion flows across the surface and how visual focus is guided when the audience can look in any direction. Practitioners must be able to imagine and sketch images in a warped coordinate system, anticipate how images will look from different seating positions and avoid compositions that cause discomfort, confusion or unintended meaning.\n\nHistorical work by Jordan Belson in the Vortex Concerts at Morrison Planetarium demonstrates this competence: abstract forms, light fields and cosmic imagery were composed to create balance between central and peripheral vision, to avoid overwhelming the audience and to guide attention through layered motion across the dome surface. This is an early example of dome-aware image composition that goes beyond flat-screen framing.\n\nIn contemporary immersive destination marketing, this competence appears when a city or region uses a temporary dome to stage a tourism or branding narrative. Visual assets such as skylines, landscapes, infrastructure and cultural scenes must be re-composed for a spherical format: horizons can no longer sit at the bottom of a 16:9 frame, and logos or key messages cannot occupy a fixed lower third. Instead, Creative Directors and their teams position visual anchors along the dome’s horizon band, balance foreground and background across the full 360° and ensure that motion does not unintentionally push viewers’ gaze away from the narrative core.\n\nSpatial image composition for fulldome is therefore a foundational building block for higher-level skills such as immersive narrative design, attention management and dome-specific motion grammar.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_fulldome_large_format",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "fulldome_films",
        "planetarium_art_shows",
        "immersive_science_communication",
        "destination_brand_domes",
        "immersive_architecture_mapping"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0004",
          "source_entity_slug": "jordan_belson",
          "evidence_type": "key_work_description",
          "evidence_summary": "Belson’s Vortex work uses balanced distribution of abstract imagery across the planetarium dome, demonstrating deliberate control of horizon, zenith and peripheral fields to create a coherent immersive image space.",
          "references": [
            0,
            1
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Cosmic Cinema: Jordan Belson and the Vortex Concerts",
          "url": "https://www.e-flux.com/events/658274/cosmic-cinema-jordan-belson-and-the-vortex-concerts",
          "publisher": "e-flux",
          "year": 2024
        },
        {
          "id": 1,
          "title": "Jordan Belson – Center for Visual Music",
          "url": "https://centerforvisualmusic.org/Belson/",
          "publisher": "Center for Visual Music",
          "year": 2020
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [
        "skill_00006"
      ],
      "tags": [
        "fulldome",
        "spatial_composition",
        "image_composition",
        "planetarium",
        "immersive_visual_design"
      ],
      "notes": "Foundational visual skill for dome work. Higher-level skills like immersive narrative design for fulldome (skill_00001) depend on this competence.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00003",
      "slug": "multi_projection_environment_direction",
      "label": "Direction of multi-projection immersive environments",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "expanded_cinema_and_multi_projection",
      "skill_type": "complex_competence",
      "description": "The ability to design and direct environments that use multiple synchronized projections to transform a space into an immersive image field. This skill involves mapping content across many displays or surfaces, coordinating rhythm and timing between channels, and treating the architecture itself as part of the image composition.\n\nEvidence in the CDIM dataset shows this competence emerging in the work of Nam June Paik and Stan VanDerBeek. Paik’s Electronic Superhighway surrounds visitors with a room-scale grid of monitors, turning a gallery into a spatial collage of moving images. VanDerBeek’s Movie-Drome uses a dome structure with many film projectors to create overlapping image streams above the audience. Both cases demonstrate the need for a Creative Director who can decide what appears where, how sequences are layered and how viewers should move through the environment.\n\nThe same competence underpins contemporary multi-projection brand and destination experiences, where cities or venues use arrays of projectors to wrap architecture, tunnels or interior spaces with content. In these contexts, multi-projection direction is used to tell layered stories about a region, a mega-event or a brand while keeping the overall composition legible and emotionally coherent.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_expanded_cinema_multi_projection",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "multi_projection_installations",
        "immersive_rooms",
        "media_facades",
        "gallery_immersive_environments",
        "destination_brand_exhibitions"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0001",
          "source_entity_slug": "nam_june_paik",
          "evidence_type": "key_work_description",
          "evidence_summary": "Electronic Superhighway uses a room-scale array of monitors as one composed environment, requiring direction of many channels of video in a single spatial experience.",
          "references": [
            0
          ]
        },
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0003",
          "source_entity_slug": "stan_vanderbeek",
          "evidence_type": "key_work_description",
          "evidence_summary": "Movie-Drome is a dome theatre designed for multiple simultaneous projections, demanding decisions about spatial placement, layering and timing of image streams.",
          "references": [
            1,
            2
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Electronic Superhighway – Smithsonian",
          "url": "https://americanart.si.edu/artwork/electronic-superhighway-9891",
          "publisher": "Smithsonian American Art Museum",
          "year": 1995
        },
        {
          "id": 1,
          "title": "Movie-Drome – Stan VanDerBeek Archive",
          "url": "https://www.stanvanderbeekarchive.com/artists/tFzRGnN/stan-vanderbeek/SmTa8j6/stan-vanderbeek-movie-drome-1965/",
          "publisher": "Stan VanDerBeek Archive",
          "year": 1965
        },
        {
          "id": 2,
          "title": "Movie-Drome – MoMA Collection",
          "url": "https://www.moma.org/collection/works/273553",
          "publisher": "MoMA",
          "year": 1965
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00002"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "multi_projection",
        "expanded_cinema",
        "media_facades",
        "immersive_installations"
      ],
      "notes": "Bridges early expanded cinema and contemporary multi-projection installations; often combined with technical direction skills for synchronization and mapping.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00004",
      "slug": "immersive_spatial_sound_dramaturgy",
      "label": "Spatial sound dramaturgy for immersive environments",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "spatial_sound_and_music",
      "skill_type": "complex_competence",
      "description": "The ability to design how sound moves through space in an immersive environment so that it supports narrative, guides attention and shapes emotional dynamics. This skill includes working with multi-channel or object-based audio, composing trajectories for sound sources and aligning sonic events with visual and architectural cues.\n\nIn the CDIM dataset, Iannis Xenakis’s Polytopes show an early form of spatial sound dramaturgy: loudspeakers distributed in and around architectural structures, light and sound sequences unfolding throughout the volume, and a precise timing of events that turns architecture into an instrument. The Creative Director’s perspective here is not only musical but spatial—deciding where sound appears, how it travels and how it frames the visual experience.\n\nToday, spatial sound dramaturgy is central to fulldome shows, VR experiences and large-scale destination spectacles where sound must reach audiences evenly, avoid fatigue and support the emotional arc of the story. It is a key competence for Creative Directors working with planetariums, immersive art spaces and brand domes.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_spatial_sound_and_light_environments",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "fulldome_films",
        "multichannel_sound_installations",
        "vr_xr_experiences",
        "destination_brand_domes",
        "large_scale_live_shows"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0002",
          "source_entity_slug": "iannis_xenakis",
          "evidence_type": "key_work_description",
          "evidence_summary": "Polytope de Montréal distributed sound and light through an architectural volume, requiring careful dramaturgy of spatial sound to articulate the space.",
          "references": [
            0
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Iannis Xenakis – Overview",
          "url": "https://www.centrepompidou.fr/",
          "publisher": "Centre Pompidou",
          "year": 1967
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "spatial_audio",
        "multichannel_sound",
        "immersive_music",
        "sound_dramaturgy"
      ],
      "notes": "Often developed in close collaboration with sound designers and composers; from the Creative Director perspective the focus is on narrative intent and spatial strategy.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00005",
      "slug": "interactive_immersive_installation_direction",
      "label": "Direction of interactive immersive installations",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "interactive_immersive_experiences",
      "skill_type": "complex_competence",
      "description": "The ability to design and direct installations where visitors’ actions, positions or biometric signals actively shape the audiovisual environment. This skill includes defining interaction logics, coordinating software, hardware and sensing technologies, and ensuring that audience participation supports the overall narrative or conceptual intent rather than distracting from it.\n\nCDIM provides several strong examples. Jeffrey Shaw’s The Legible City invites visitors to ride a physical bicycle and navigate a virtual city made of letters, turning bodily motion into narrative exploration. Maurice Benayoun’s World Skin uses CAVE technology and interaction to let visitors photograph and erase war imagery, making participation part of the political message. Rafael Lozano-Hemmer’s Pulse Room transforms heartbeats into flickering light bulbs, creating a large-scale environment composed from visitors’ biometric signals.\n\nFor contemporary Creative Directors, this competence is crucial in museums, brand experiences and public festivals where interaction is expected. It ensures that interactivity is not a gimmick but a structured, meaningful part of the experience that can be explained, tested and scaled.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_interactive_installations",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "interactive_museum_installations",
        "brand_experiences",
        "festival_experiences",
        "public_space_interventions"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0007",
          "source_entity_slug": "jeffrey_shaw",
          "evidence_type": "key_work_description",
          "evidence_summary": "The Legible City requires a director to define how physical cycling maps onto movement and narrative exploration in a virtual text city.",
          "references": [
            0
          ]
        },
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0008",
          "source_entity_slug": "maurice_benayoun",
          "evidence_type": "key_work_description",
          "evidence_summary": "World Skin shows how interaction and erasure can be staged in an immersive CAVE environment to carry political meaning.",
          "references": [
            1
          ]
        },
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0009",
          "source_entity_slug": "rafael_lozano_hemmer",
          "evidence_type": "key_work_description",
          "evidence_summary": "Pulse Room turns biometric input (heartbeats) into a large-scale light environment, demanding careful direction of participation and accumulation.",
          "references": [
            2,
            3
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Jeffrey Shaw – Biography/CV",
          "url": "https://www.jeffreyshawcompendium.com/bio-cv/",
          "publisher": "Jeffrey Shaw Compendium",
          "year": 2015
        },
        {
          "id": 1,
          "title": "World Skin – Ars Electronica Futurelab",
          "url": "https://ars.electronica.art/futurelab/en/projects-world-skin/",
          "publisher": "Ars Electronica Futurelab",
          "year": 1998
        },
        {
          "id": 2,
          "title": "Pulse Room – Official Project Page",
          "url": "https://www.lozano-hemmer.com/pulse_room.php",
          "publisher": "Rafael Lozano-Hemmer Studio",
          "year": 2006
        },
        {
          "id": 3,
          "title": "Pulse Room – MAC Montréal Collection",
          "url": "https://macm.org/en/collections/oeuvre/pulse_room/",
          "publisher": "Musée d’art contemporain de Montréal",
          "year": 2006
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "interactive_installations",
        "participatory_art",
        "sensor_based_environments",
        "cave_vr"
      ],
      "notes": "Sits at the intersection of dramaturgy, interaction design and technical orchestration; crucial for both cultural and commercial immersive projects.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00006",
      "slug": "attention_guidance_in_spherical_immersive_spaces",
      "label": "Attention guidance in spherical immersive spaces",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "attention_and_perception",
      "skill_type": "complex_competence",
      "description": "The ability to guide audience attention in environments where there is no single fixed frame and relevant information may appear anywhere around the viewer. This skill combines knowledge of human perception, motion, light and sound cues to ensure that audiences perceive key narrative elements without feeling forced or overloaded.\n\nCDIM examples such as Jordan Belson’s Vortex Concerts and later large-scale installations by artists like Rafael Lozano-Hemmer and teamLab show how attention can be steered through gradients of brightness, clusters of motion, spatial sound cues and temporal pacing. Rather than pointing a camera, the Creative Director shapes zones of attraction and calm across the entire field of view.\n\nThis competence is critical in domes, projection rooms, immersive exhibitions and destination brand domes, where visitors can freely look around and even move through the space. Without explicit attention guidance, complex content becomes noise and key messages are lost.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_fulldome_large_format",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "fulldome_films",
        "immersive_installations",
        "destination_brand_domes",
        "immersive_museums"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0004",
          "source_entity_slug": "jordan_belson",
          "evidence_type": "key_work_description",
          "evidence_summary": "Vortex Concerts show controlled use of light, color and motion across the dome to focus and release attention in cycles.",
          "references": [
            0,
            1
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Cosmic Cinema: Jordan Belson and the Vortex Concerts",
          "url": "https://www.e-flux.com/events/658274/cosmic-cinema-jordan-belson-and-the-vortex-concerts",
          "publisher": "e-flux",
          "year": 2024
        },
        {
          "id": 1,
          "title": "Jordan Belson – Center for Visual Music",
          "url": "https://centerforvisualmusic.org/Belson/",
          "publisher": "Center for Visual Music",
          "year": 2020
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001",
        "skill_00002",
        "skill_00004"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "attention_guidance",
        "perception",
        "immersive_storytelling"
      ],
      "notes": "Links narrative intent with perceptual design; becomes increasingly important as immersive experiences grow in scale and complexity.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00007",
      "slug": "immersive_brand_environment_storytelling",
      "label": "Immersive brand environment storytelling",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "brand_and_destination_storytelling",
      "skill_type": "complex_competence",
      "description": "The ability to translate brand narratives, corporate strategies or destination identities into spatial experiences that audiences can walk through. This skill integrates scenography, media design and narrative to ensure that a brand story unfolds coherently across rooms, stations or interactive zones.\n\nIn CDIM, practitioners such as Stefan Weil at Atelier Markgraph work on spatial communication for trade shows, showrooms and exhibition projects where architecture, media and objects form a single narrative environment. Their practice demonstrates how brand values and complex topics (e.g. mobility, sustainability, industry) are turned into sequences of spaces, each with a specific narrative role.\n\nThe same competence is needed when a city or region stages a destination marketing environment—whether in a dome, a pavilion or a travelling immersive exhibition. Here, immersive brand environment storytelling aligns multiple stakeholders (tourism boards, cultural partners, sponsors) around a shared story that can be experienced in a few minutes but still carries strategic depth.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_corporate_and_destination_experiences",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "brand_experiences",
        "trade_show_pavilions",
        "destination_marketing_exhibitions",
        "corporate_museums"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0094",
          "source_entity_slug": "stefan_weil",
          "evidence_type": "focus_summary",
          "evidence_summary": "As creative director at Atelier Markgraph, Weil leads spatial communication projects that merge architecture, media and scenography for cultural and corporate clients.",
          "references": [
            0,
            1
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Stefan Weil – D&AD Member Profile",
          "url": "https://www.dandad.org/profiles/person/92510/stefan-weil/",
          "publisher": "D&AD",
          "year": 2024
        },
        {
          "id": 1,
          "title": "Stefan Weil – NODE Forum",
          "url": "https://nodeforum.org/people/stefan-weil/",
          "publisher": "NODE Forum for Digital Arts",
          "year": 2024
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "brand_storytelling",
        "spatial_communication",
        "destination_marketing"
      ],
      "notes": "Connects immersive media with strategic communication goals and is central for using domes and immersive spaces in destination marketing.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00008",
      "slug": "immersive_digital_art_museum_experience_choreography",
      "label": "Experience choreography for immersive digital art museums",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "experience_flow_and_choreography",
      "skill_type": "complex_competence",
      "description": "The ability to choreograph how visitors move through large-scale immersive digital art spaces, including entry, circulation, dwell time and exit. This competence ensures that multiple rooms, generative installations and interactive pieces form one legible overall experience rather than a collection of disconnected attractions.\n\nCDIM lists Toshiyuki Inoko, founder and creative lead of teamLab, whose work on museum-scale experiences like teamLab Borderless demonstrates this skill. Visitors wander through a continuous field of responsive artworks, yet the experience is carefully structured in terms of thresholds, transitions, density of stimuli and opportunities for reflection.\n\nFor destination marketing and cultural institutions adopting similar formats, this competence is essential: experience choreography determines whether visitors feel lost and overstimulated or guided through a meaningful journey that they can remember and describe to others.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_immersive_digital_art_museums",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "immersive_digital_art_museums",
        "immersive_exhibitions",
        "destination_experience_centers"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0010",
          "source_entity_slug": "toshiyuki_inoko",
          "evidence_type": "focus_summary",
          "evidence_summary": "As founder and creative lead of teamLab, Inoko shapes museum-scale environments like teamLab Borderless where visitors navigate continuously flowing interactive artworks.",
          "references": [
            0,
            1
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Inside the Creative Cosmos: Toshiyuki Inoko’s Journey to Founding teamLab",
          "url": "https://gulfleaderscircle.com/interviews/inside-the-creative-cosmos-toshiyuki-inokos-journey-to-founding-teamlab/",
          "publisher": "Gulf Leaders Circle",
          "year": 2024
        },
        {
          "id": 1,
          "title": "TeamLab Co-Founder Toshiyuki Inoko – Artnet Interview",
          "url": "https://news.artnet.com/career-stories/career-stories-teamlab-toshiyuki-inoko-1953102",
          "publisher": "Artnet",
          "year": 2020
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001",
        "skill_00006"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "experience_choreography",
        "immersive_museums",
        "visitor_flow"
      ],
      "notes": "Highly relevant for cities or venues planning permanent or touring immersive museums as part of their destination strategy.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00009",
      "slug": "ecological_and_more_than_human_perspective_immersion",
      "label": "Ecological and more-than-human perspective immersion",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "thematic_and_ethnographic_perspective",
      "skill_type": "complex_competence",
      "description": "The ability to design immersive experiences that adopt non-anthropocentric perspectives, such as those of forests, animals or planetary systems, and make them accessible to human audiences. This skill combines artistic research, environmental knowledge and sensory design to shift visitors’ perception beyond human-centred viewpoints.\n\nCDIM features Ersin Han Ersin and Barnaby Steel of Marshmallow Laser Feast, whose works like We Live in an Ocean of Air and In the Eyes of the Animal translate ecological processes into multisensory immersive journeys. Visitors breathe with a sequoia tree, experience the forest through non-human senses or move through volumetric representations of ecosystems.\n\nFor Creative Directors working in science communication, cultural institutions or destination projects focused on sustainability and landscape, this competence is vital. It enables destinations to position themselves not only as places to consume but as ecosystems to connect with.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_immersive_ecology_and_nature",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "immersive_science_communication",
        "immersive_art_installations",
        "destination_sustainability_experiences"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0011",
          "source_entity_slug": "ersin_han_ersin",
          "evidence_type": "key_work_description",
          "evidence_summary": "We Live in an Ocean of Air uses breath, heart-rate and spatial visuals to connect visitors with a giant sequoia tree, creating an embodied ecological narrative.",
          "references": [
            0,
            1
          ]
        },
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0012",
          "source_entity_slug": "barnaby_steel",
          "evidence_type": "key_work_description",
          "evidence_summary": "In the Eyes of the Animal places audiences in the perceptual worlds of forest creatures, demonstrating more-than-human perspective-taking.",
          "references": [
            2
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Ersin Han Ersin – Artist & Director",
          "url": "https://www.ersinhanersin.co.uk/",
          "publisher": "Ersin Han Ersin",
          "year": 2024
        },
        {
          "id": 1,
          "title": "Making the Invisible Visible – Conversation with Marshmallow Laser Feast",
          "url": "https://emergencemagazine.org/conversation/making-the-invisible-visible/",
          "publisher": "Emergence Magazine",
          "year": 2024
        },
        {
          "id": 2,
          "title": "Exploring Nature with Marshmallow Laser Feast",
          "url": "https://aestheticamagazine.com/exploring-nature-with-marshmallow-laser-feast/",
          "publisher": "Aesthetica Magazine",
          "year": 2023
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ecology",
        "more_than_human",
        "immersive_storytelling"
      ],
      "notes": "Provides a thematic lens that can be combined with fulldome, VR or installation formats, especially relevant for destinations emphasising nature and sustainability.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00010",
      "slug": "large_scale_live_immersive_show_direction",
      "label": "Direction of large-scale live immersive shows",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "mega_events_and_ceremonies",
      "skill_type": "complex_competence",
      "description": "The ability to conceive and direct large-scale live shows that merge architecture, performers, media, light, pyrotechnics and audience presence into a coherent immersive experience. This skill includes designing show dramaturgy for stadiums or city landmarks, coordinating multi-disciplinary teams and aligning the show with national or brand narratives.\n\nCDIM lists figures such as Yves Pépin and Marco Balich, whose work on Olympic ceremonies, World Cup openings and city-scale spectacles demonstrates this competence. Their shows turn entire stadiums, iconic structures or city districts into narrative canvases, with media facades, projections, fireworks and live performance integrated into one temporal arc.\n\nDestinations and brands that commission opening ceremonies, city festivals or landmark unveilings require this competence at the Creative Director level to ensure that technical ambition, political messaging and public safety resolve into a compelling, emotionally resonant immersive experience.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_large_scale_live_shows",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "olympic_ceremonies",
        "world_cup_shows",
        "city_scale_spectacles",
        "destination_festivals"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0092",
          "source_entity_slug": "yves_pepin",
          "evidence_type": "key_work_description",
          "evidence_summary": "The Eiffel Tower Millennium Show and FIFA World Cup opening ceremonies used architecture, projection and pyrotechnics to create immersive mega-events.",
          "references": [
            0,
            1
          ]
        },
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0093",
          "source_entity_slug": "marco_balich",
          "evidence_type": "key_work_description",
          "evidence_summary": "Balich’s record of Olympic ceremonies and shows like Viva Vivaldi demonstrate integrated direction of music, architecture and media for large audiences.",
          "references": [
            2,
            3
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Creative Director | Yves Pépin",
          "url": "https://www.yves-pepin.org/home",
          "publisher": "Yves Pépin",
          "year": 2025
        },
        {
          "id": 1,
          "title": "Interview – Yves Pépin",
          "url": "https://www.attractionsmanagement.com/Attractions-Management-magazine/Yves-Pepin/34098",
          "publisher": "Attractions Management",
          "year": 2013
        },
        {
          "id": 2,
          "title": "Marco Balich – Balich Wonder Studio",
          "url": "https://www.balichwonderstudio.com/team/marco-balich/",
          "publisher": "Balich Wonder Studio",
          "year": 2025
        },
        {
          "id": 3,
          "title": "Viva Vivaldi, an immersive show that combines music and technology",
          "url": "https://www.arena.it/en/magazine/news/viva-vivaldi/",
          "publisher": "Arena di Verona",
          "year": 2024
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00004",
        "skill_00005"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "large_scale_live_shows",
        "mega_events",
        "city_scale_spectacle"
      ],
      "notes": "Key competence when immersive media and narrative are deployed at national or city scale, often intersecting with tourism and destination branding.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00011",
      "slug": "fulldome_production_scoping_and_budgeting",
      "label": "Scoping and budgeting of fulldome and dome-based productions",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "planning_and_budgeting",
      "skill_type": "foundational_skill",
      "description": "The ability to define scope, resources and budgets for fulldome films and dome-based immersive productions. This skill includes understanding the specific cost drivers of dome work (rendering, projection, sound, licensing, crew, venue rental), as well as how narrative ambition, duration and image complexity translate into time and money.\n\nFrom a Creative Director’s perspective, scoping and budgeting for domes means translating a narrative concept into concrete production packages: number of scenes, rendering resolutions, whether real-time or pre-rendered engines are used, how many original music and sound design elements are needed, and what level of technical supervision is required at the venue. It also includes identifying which parts of the project can be re-used for other contexts (e.g. VR, flat trailers, destination campaigns), which directly impacts feasibility and return on investment.\n\nThis competence is essential for both cultural and commercial dome projects. Planetariums, festivals and destination marketing teams are often operating under strict financial and scheduling constraints; Creative Directors who can work with producers to scope realistic yet ambitious fulldome deliverables are more likely to secure funding and repeat commissions.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_fulldome_large_format",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "fulldome_films",
        "planetarium_art_shows",
        "destination_brand_domes",
        "touring_dome_shows"
      ],
      "derived_from_outputs": [],
      "references": [],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001",
        "skill_00002"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "budgeting",
        "scoping",
        "fulldome_production",
        "project_planning"
      ],
      "notes": "Prototype entry; evidence and concrete case references should be attached from CDIM and specific fulldome production case studies.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00012",
      "slug": "fulldome_technical_pipeline_coordination",
      "label": "Technical pipeline coordination for fulldome and domes",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "technical_direction",
      "skill_type": "complex_competence",
      "description": "The ability to coordinate the technical pipeline of a fulldome or dome-based production from concept to playback. This skill includes understanding how content moves through 3D creation, compositing, encoding and final projection, and how technical constraints (resolution, bit depth, codec, dome server capabilities) influence creative decisions.\n\nCreative Directors who master this competence can talk fluently with technical directors, 3D artists, compositors and venue technicians. They understand when a scene is too heavy for real-time playback, when a render resolution is insufficient for a given dome size, and how to plan test screenings and calibration sessions. They can also anticipate how content may need to be adapted for different dome systems or destination domes operated by partners worldwide.\n\nThis competence is especially important when immersive brand or destination campaigns plan to tour across multiple domes, planetariums or temporary structures with varying hardware configurations.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_fulldome_large_format",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "fulldome_films",
        "planetarium_art_shows",
        "touring_dome_shows",
        "destination_brand_domes"
      ],
      "derived_from_outputs": [],
      "references": [],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00002",
        "skill_00004"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "technical_pipeline",
        "fulldome",
        "projection_systems",
        "immersion_technology"
      ],
      "notes": "Should later be linked to concrete technical case studies from planetariums and dome festivals once sources are collected.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00013",
      "slug": "destination_immersive_campaign_concepting",
      "label": "Concepting of immersive destination marketing campaigns",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "brand_and_destination_storytelling",
      "skill_type": "complex_competence",
      "description": "The ability to design destination marketing campaigns that use immersive formats—such as domes, multi-projection rooms or mixed-reality experiences—as the central storytelling engine. This skill includes aligning tourism objectives, stakeholder interests and local identity with an immersive narrative that can travel between cities and channels.\n\nCreative Directors with this competence can translate a destination’s assets (landscape, culture, innovation, events) into a coherent immersive storyline, decide which parts are best told in a dome or immersive room, and design how that core experience connects to social media, PR, trade partners and on-site activation. They are able to balance spectacular imagery with information density, so that visitors leave with both emotional impressions and concrete reasons to visit.\n\nThis competence is a key bridge between the CDIM world of immersive artistic and experiential work and the destination marketing dataset, where concrete campaign outputs (touring domes, immersive pavilions, projection shows) reveal the skill demands placed on Creative Directors.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_corporate_and_destination_experiences",
          "source_dataset_id": "dest_marketing"
        }
      ],
      "application_contexts": [
        "destination_brand_domes",
        "immersive_tourism_pavilions",
        "city_branding_shows",
        "trade_fair_destination_stands"
      ],
      "derived_from_outputs": [],
      "references": [],
      "source_datasets": [
        {
          "source_dataset_id": "dest_marketing",
          "source_dataset_name": "Destination Marketing Immersive Outputs"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001",
        "skill_00007"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "destination_marketing",
        "brand_storytelling",
        "immersive_campaigns"
      ],
      "notes": "This skill will later be backed by concrete destination dome campaigns and immersive pavilions documented in the Destination Marketing dataset.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00014",
      "slug": "cultural_localisation_for_immersive_destination_experiences",
      "label": "Cultural localisation for immersive destination experiences",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "localisation_and_audience_adaptation",
      "skill_type": "complex_competence",
      "description": "The ability to adapt immersive destination experiences to different cultural, linguistic and regulatory contexts while preserving the core narrative and emotional arc. This skill goes beyond translation; it includes adjusting imagery, symbolic references, tone, social behaviours depicted and even pacing to match local expectations and sensitivities.\n\nIn practice, this might mean modifying character behaviour, soundscapes or crowd scenes to respect local norms, adjusting environmental imagery so that it does not unintentionally echo political or religious symbols, and re-framing calls-to-action in a way that resonates across markets. For dome and room-scale experiences, it can also involve adapting audience interaction patterns—how much physical engagement is socially acceptable, how long people are comfortable standing, or how families experience spaces together.\n\nThis competence is particularly important when immersive destination domes or exhibitions tour multiple countries or regions. It prevents friction and misunderstanding and allows the same core content to travel efficiently while still feeling locally relevant.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_corporate_and_destination_experiences",
          "source_dataset_id": "dest_marketing"
        }
      ],
      "application_contexts": [
        "touring_destination_exhibitions",
        "destination_brand_domes",
        "immersive_brand_experiences",
        "museum_touring_shows"
      ],
      "derived_from_outputs": [],
      "references": [],
      "source_datasets": [
        {
          "source_dataset_id": "dest_marketing",
          "source_dataset_name": "Destination Marketing Immersive Outputs"
        }
      ],
      "overlaps_with_skills": [
        "skill_00007",
        "skill_00013"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "localisation",
        "intercultural_communication",
        "destination_marketing"
      ],
      "notes": "Requires collaboration with local partners, linguists and cultural experts; to be backed by concrete multi-country destination campaigns in later iterations.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00015",
      "slug": "impact_evaluation_of_immersive_experiences",
      "label": "Impact evaluation of immersive experiences",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "qualitative_and_quantitative_evaluation",
      "skill_type": "complex_competence",
      "description": "The ability to define and interpret impact metrics for immersive experiences, combining qualitative feedback with quantitative data. This skill includes formulating evaluation questions, selecting indicators (attention, dwell time, recall, behavioural intent), designing surveys or interviews and interpreting sensor or tracking data from immersive environments.\n\nFor Creative Directors, impact evaluation is not a purely academic exercise; it feeds directly back into design decisions. In fulldome science shows, it clarifies whether complex topics are understood. In destination marketing domes, it reveals whether visitors feel motivated to visit a region or engage with travel partners. In immersive museums, it helps to balance spectacle with reflection.\n\nThis competence allows Creative Directors to argue for budgets and programmatic changes with evidence rather than intuition, and to iteratively improve immersive formats over multiple editions or tours.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_research_and_evaluation_oriented",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "fulldome_science_shows",
        "destination_brand_domes",
        "immersive_museums",
        "immersive_brand_experiences"
      ],
      "derived_from_outputs": [],
      "references": [],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        },
        {
          "source_dataset_id": "dest_marketing",
          "source_dataset_name": "Destination Marketing Immersive Outputs"
        }
      ],
      "overlaps_with_skills": [
        "skill_00006",
        "skill_00007"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "evaluation",
        "research",
        "metrics",
        "audience_insights"
      ],
      "notes": "Future versions of this skill should reference concrete evaluation frameworks and published case studies from science centres and destination campaigns.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00016",
      "slug": "crowd_flow_and_safety_in_immersive_environments",
      "label": "Crowd flow and safety planning in immersive environments",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "operations_and_safety",
      "skill_type": "foundational_skill",
      "description": "The ability to design immersive experiences with safe and readable visitor flow, taking into account crowd density, emergency exits, accessibility and visitors’ physiological responses. This skill includes anticipating where people will cluster, how long they will stay, where bottlenecks may form and how to maintain a safe, comfortable environment even at high attendance.\n\nIn domes, immersive rooms and destination exhibitions, visual and acoustic overload can lead to disorientation or discomfort. Creative Directors with crowd flow and safety competence work closely with operational teams and architects to shape routes, decide where to place seating or rest zones and ensure that content intensity is balanced with opportunities to pause.\n\nThis competence is especially important for large-scale destination or festival shows, where immersive media, low light levels and emotional peaks intersect with real-world safety requirements and regulations.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_large_scale_live_shows",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_immersive_museums_and_exhibitions",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "large_scale_live_shows",
        "destination_brand_domes",
        "immersive_museums",
        "festival_installations"
      ],
      "derived_from_outputs": [],
      "references": [],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        },
        {
          "source_dataset_id": "dest_marketing",
          "source_dataset_name": "Destination Marketing Immersive Outputs"
        }
      ],
      "overlaps_with_skills": [
        "skill_00008",
        "skill_00010"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "crowd_flow",
        "safety",
        "operations",
        "visitor_experience"
      ],
      "notes": "To be specified further with references to documented crowd management practices in immersive festivals, domes and live shows.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00017",
      "slug": "interdisciplinary_team_leadership_in_immersive_projects",
      "label": "Interdisciplinary team leadership in immersive projects",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "team_leadership_and_collaboration",
      "skill_type": "complex_competence",
      "description": "The ability to lead interdisciplinary teams combining artists, technologists, producers, architects, scientists, marketers and public stakeholders in immersive projects. This skill includes setting a shared vision, translating between different professional languages and managing expectations and constraints across disciplines.\n\nIn many CDIM profiles, Creative Directors act as connectors between specialised domains: they align scientific partners with media teams in fulldome shows, or coordinate city officials, event agencies and technical providers for destination spectacles. Effective leadership here is not only about authority but about building a common understanding of what the immersive experience should achieve and how each discipline contributes.\n\nThis competence is critical for complex projects like immersive museums, destination domes, city festivals and science-communication initiatives, where failure of coordination can lead to overruns, technical breakdowns or diluted messaging.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_all",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "fulldome_science_shows",
        "destination_brand_domes",
        "immersive_museums",
        "large_scale_live_shows",
        "interactive_installations"
      ],
      "derived_from_outputs": [],
      "references": [],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        },
        {
          "source_dataset_id": "dest_marketing",
          "source_dataset_name": "Destination Marketing Immersive Outputs"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001",
        "skill_00010"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "team_leadership",
        "interdisciplinary",
        "project_management"
      ],
      "notes": "This skill should later link to documented leadership practices and interviews with Creative Directors across the CDIM dataset.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00018",
      "slug": "ethical_and_inclusive_design_for_immersive_media",
      "label": "Ethical and inclusive design for immersive media",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "ethics_and_inclusion",
      "skill_type": "complex_competence",
      "description": "The ability to design immersive experiences that consider ethical questions, representation and accessibility from the outset. This skill includes reflecting on who is represented (and how), who might be excluded by the format or content, and how to reduce unintended harm such as motion sickness, sensory overload, stereotyping or reinforcing inequalities.\n\nCreative Directors with this competence ask how different audiences will experience a dome, a VR piece or an immersive brand environment: whether people with mobility, sensory or cognitive differences can participate; whether narratives rely on clichés or extractive uses of culture; and how data (from tracking, biometrics or interaction logs) is used and communicated.\n\nIn destination marketing, this competence helps ensure that immersive campaigns do not exoticise or oversimplify local cultures; in science communication, it supports fair representation of communities and questions of environmental justice.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_all",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "immersive_museums",
        "destination_brand_domes",
        "fulldome_science_shows",
        "immersive_brand_experiences"
      ],
      "derived_from_outputs": [],
      "references": [],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        },
        {
          "source_dataset_id": "dest_marketing",
          "source_dataset_name": "Destination Marketing Immersive Outputs"
        }
      ],
      "overlaps_with_skills": [
        "skill_00009",
        "skill_00015"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ethics",
        "inclusion",
        "accessibility",
        "representation"
      ],
      "notes": "Future iterations should reference concrete guidelines and case studies on accessibility and representation in immersive media.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00019",
      "slug": "curriculum_alignment_for_immersive_creative_training",
      "label": "Curriculum alignment for immersive creative training",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "education_and_curriculum_design",
      "skill_type": "complex_competence",
      "description": "The ability to translate real-world immersive creative skills into educational curricula, module structures and learning outcomes. This skill includes selecting which competencies (from this taxonomy) should be taught at which level (introductory, advanced, specialised), and designing exercises or projects that simulate authentic immersive production contexts.\n\nThis competence is especially relevant for educators, curriculum designers and policy makers who decide how universities, art schools or vocational programs prepare students for roles such as Creative Director for Immersive Media, immersive producer or technical director. It connects the skill taxonomy directly to teaching practice by mapping skills to workshops, labs, interdisciplinary studios or collaborations with external partners such as planetariums or destination marketing organisations.\n\nFor Creative Directors themselves, understanding curriculum alignment can be valuable when mentoring emerging talent or co-designing training programs with institutions.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_education_and_research",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "higher_education",
        "art_schools",
        "vocational_training",
        "professional_development_programmes"
      ],
      "derived_from_outputs": [],
      "references": [],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00015",
        "skill_00017"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "curriculum_design",
        "education",
        "training",
        "learning_outcomes"
      ],
      "notes": "Central for making the taxonomy interoperable with education systems; future versions should reference concrete curriculum reforms and pilot programs.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00020",
      "slug": "ai_assisted_concept_development_for_immersive_media",
      "label": "AI-assisted concept development for immersive media",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "ai_and_augmented_creativity",
      "skill_type": "complex_competence",
      "description": "The ability to use AI tools as partners in the concept development process for immersive experiences, while maintaining human authorship, ethical standards and coherence across media. This skill includes prompting and steering generative models (text, image, sound, 3D), critically evaluating their outputs, and integrating them into workflows for moodboards, treatments, scripts, animatics or spatial sketches.\n\nFor Creative Directors in immersive media, AI-assisted concept development can accelerate exploration of visual worlds, narrative variants and spatial configurations for domes, immersive museums or destination campaigns. However, it also introduces new responsibilities: understanding dataset bias, avoiding plagiarism-like outputs, and ensuring that generated material is reconciled with technical and budgetary constraints.\n\nThis competence does not replace other narrative or technical skills but sits on top of them, allowing experienced practitioners to extend their creative range and to communicate early concepts more vividly to stakeholders, funders and technical teams.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_all",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "concept_development",
        "pitching_and_treatments",
        "visual_research",
        "destination_marketing_campaigns",
        "fulldome_and_vr_previsualisation"
      ],
      "derived_from_outputs": [],
      "references": [],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001",
        "skill_00002",
        "skill_00007"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ai",
        "concept_development",
        "augmented_creativity"
      ],
      "notes": "Designed to stay compatible with future AI-agent roles that might operate on this taxonomy; evidence and case references to be added as practices stabilise.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00021",
      "slug": "creative_storytelling_in_immersive_media",
      "label": "Creative storytelling in immersive media",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "immersive_storytelling",
      "skill_type": "complex_competence",
      "description": "The ability to craft narratives that leverage immersive technologies for deep audience engagement, prioritizing artistic intent and non-linear structures over traditional linear storytelling. This skill involves blending technical elements with emotional arcs in environments like VR, AR, and fulldome projections, ensuring experiences feel participatory and memorable.\n\nEvidence from immersive media education highlights this as essential: crafting impactful experiences requires a story-first approach, rooted in installation art rather than film, where directors develop narratives that unfold spatially around the user. For instance, in large-scale projections, directors use dynamic, adaptive engagements to resonate with audiences, fostering emotional connections in destination marketing or science communication.\n\nThis competence is crucial for immersive domains as it transforms passive viewing into active immersion, applicable across VR headset experiences and public installations, where it enhances brand storytelling and cultural representation.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_ar",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_experiences",
        "ar_installations",
        "fulldome_projections",
        "immersive_brand_campaigns"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "immersive_education_trends",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Story-first approaches in immersive media emphasize artistic vision for captivating audiences in projections and VR.",
          "references": [
            0
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Educating the future of immersive media: building talent for an expanding industry",
          "url": "https://blooloop.com/immersive/opinion/immersive-media-talent/",
          "publisher": "blooloop",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001",
        "skill_00020"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00025"
      ],
      "tags": [
        "storytelling",
        "immersive_narrative",
        "artistic_intent",
        "non_linear_story"
      ],
      "notes": "Builds on foundational narrative design; to be linked with specific CDIM practitioner examples in future updates.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00022",
      "slug": "technical_proficiency_in_interactive_technologies",
      "label": "Technical proficiency in interactive technologies",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "technical_integration",
      "skill_type": "foundational_skill",
      "description": "The competence to utilize tools and platforms for VR, AR, MR, and fulldome production, including real-time content creation and integration of spatial audio-visual systems. This involves hands-on familiarity with software for non-linear immersive content, ensuring seamless technical execution in creative workflows.\n\nFrom industry insights, immersive roles demand part-technologist skills, shifting from pre-rendered film to interactive ecosystems. Examples include using developer kits for AR overlays in destination tours or configuring fulldome software for planetarium shows, where directors oversee technical setups to support narrative flow.\n\nNecessary for immersive creative roles to bridge art and engineering, this skill enables efficient prototyping and deployment in cross-domain projects like museum installations and brand activations.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_technical_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_production",
        "ar_development",
        "fulldome_technical_setup",
        "mixed_reality_projects"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "technical_roles",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Involves skills in VR, AR, MR for real-time content in immersive ecosystems.",
          "references": [
            0
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Educating the future of immersive media: building talent for an expanding industry",
          "url": "https://blooloop.com/immersive/opinion/immersive-media-talent/",
          "publisher": "blooloop",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00002"
      ],
      "is_component_of": [
        "skill_00021"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "technical_skills",
        "vr_ar_tools",
        "real_time_content",
        "immersive_tech"
      ],
      "notes": "Foundational for production; expand with specific tool references from CDIM.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00023",
      "slug": "creative_thinking_and_experimentation",
      "label": "Creative thinking and experimentation in immersive design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "innovative_ideation",
      "skill_type": "complex_competence",
      "description": "The capacity to foster experimental mindsets, embracing failure and iteration to innovate in immersive formats. This includes ideation techniques tailored to spatial and interactive constraints, encouraging adaptive creativity in flux industries.\n\nEducational frameworks emphasize developing creative mindsets for immersive media, where directors drive discovery through prototyping non-standard experiences. For example, in VR design, experimenting with user agency leads to novel interactions in destination storytelling.\n\nVital for staying ahead in evolving fields like AR and fulldome, this skill promotes cross-domain innovation, from art installations to commercial campaigns.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_innovator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "immersive_prototyping",
        "vr_ideation",
        "ar_experiments",
        "fulldome_innovation"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "creative_mindsets",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Embracing experimentation and failing forward in immersive sectors.",
          "references": [
            0
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Educating the future of immersive media: building talent for an expanding industry",
          "url": "https://blooloop.com/immersive/opinion/immersive-media-talent/",
          "publisher": "blooloop",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00020"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00027"
      ],
      "tags": [
        "experimentation",
        "creative_thinking",
        "iteration",
        "innovation"
      ],
      "notes": "Links to AI-assisted development; reference practitioner experiments.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00024",
      "slug": "user_experience_design_for_immersive_environments",
      "label": "User experience design for immersive environments",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "ux_in_immersion",
      "skill_type": "complex_competence",
      "description": "Expertise in human-centered design for immersive media, focusing on audience engagement, accessibility, and participatory interactions. This skill encompasses mapping user journeys in 360-degree spaces, mitigating discomfort, and optimizing for diverse participants.\n\nInsights from immersive talent building stress deep UX understanding, designing dynamic engagements that resonate psychologically and culturally. Examples include adaptive VR tours for destinations, ensuring inclusivity in fulldome shows.\n\nEssential for creating equitable experiences, this competence spans museums, events, and digital campaigns, enhancing retention and impact.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ux_designer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_user_journeys",
        "ar_interactions",
        "fulldome_audience_engagement",
        "immersive_exhibitions"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ux_design",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Human-centred design for audience engagement in immersive experiences.",
          "references": [
            0
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Educating the future of immersive media: building talent for an expanding industry",
          "url": "https://blooloop.com/immersive/opinion/immersive-media-talent/",
          "publisher": "blooloop",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00018"
      ],
      "is_component_of": [
        "skill_00021"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "ux_design",
        "audience_engagement",
        "human_centered",
        "accessibility"
      ],
      "notes": "Overlaps with ethics; add metrics from research.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00025",
      "slug": "adaptability_in_evolving_immersive_sectors",
      "label": "Adaptability in evolving immersive sectors",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "sector_adaptation",
      "skill_type": "foundational_skill",
      "description": "The flexibility to unlearn traditional practices and adapt to rapid changes in immersive technologies and audience expectations. This includes pivoting workflows for new formats like MR or AI-enhanced VR.\n\nIndustry reports note the need to transition from linear media, embracing flux through continuous learning. For example, directors adapting film skills to spatial AR for brand events.\n\nCritical for longevity in immersive roles, enabling cross-domain application from education to marketing.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_adaptive_leader",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "technology_transitions",
        "audience_adaptation",
        "immersive_trend_integration"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "adaptability",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Adapting to changing sectors and unlearning linear approaches.",
          "references": [
            0
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Educating the future of immersive media: building talent for an expanding industry",
          "url": "https://blooloop.com/immersive/opinion/immersive-media-talent/",
          "publisher": "blooloop",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00017"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00030"
      ],
      "tags": [
        "adaptability",
        "flexibility",
        "learning_agility",
        "trend_awareness"
      ],
      "notes": "Prerequisite for leadership in dynamic projects.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00026",
      "slug": "spatial_storytelling_techniques",
      "label": "Spatial storytelling techniques for immersive media",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "spatial_narrative",
      "skill_type": "complex_competence",
      "description": "Mastery of designing stories that utilize physical and virtual space, including 360-degree framing and environmental cues in VR/AR/fulldome. This skill requires custom storyboarding for non-standard perspectives.\n\nSources describe spatial storytelling as key, adapting traditional narratives for immersive, where environments drive plot. Example: 360-video for cultural heritage sites, guiding users through spatial arcs.\n\nIndispensable for immersive efficacy, bridging film and architecture in applications like exhibitions and events.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_spatial_designer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "360_video_production",
        "spatial_vr_narratives",
        "fulldome_environmental_story"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "spatial_design",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Knowledge of spatial storytelling in immersive content with unique perspectives.",
          "references": [
            0
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Educating the future of immersive media: building talent for an expanding industry",
          "url": "https://blooloop.com/immersive/opinion/immersive-media-talent/",
          "publisher": "blooloop",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001",
        "skill_00002"
      ],
      "is_component_of": [
        "skill_00021"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "spatial_storytelling",
        "360_framing",
        "environmental_narrative"
      ],
      "notes": "Extends fulldome skills to VR/AR.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00027",
      "slug": "inclusive_design_practices_in_immersive_experiences",
      "label": "Inclusive design practices in immersive experiences",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "inclusivity_and_accessibility",
      "skill_type": "foundational_skill",
      "description": "Integrating principles of inclusivity, accessibility, and sustainability into immersive design from concept to deployment. This includes addressing sensory needs and cultural representation in VR/AR content.\n\nImmersive education stresses responsible creation, ensuring experiences support diverse audiences. Example: Designing fulldome shows with adjustable intensity for neurodiverse viewers.\n\nKey for ethical immersive media, applicable to public installations and private VR, promoting broader participation.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_inclusive_designer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "accessible_vr",
        "inclusive_ar",
        "sustainable_immersive_projects"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "inclusivity",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Addressing inclusivity, accessibility, and sustainability in immersive creation.",
          "references": [
            0
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Educating the future of immersive media: building talent for an expanding industry",
          "url": "https://blooloop.com/immersive/opinion/immersive-media-talent/",
          "publisher": "blooloop",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00018"
      ],
      "is_component_of": [
        "skill_00024"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "inclusivity",
        "accessibility",
        "sustainability",
        "diverse_audiences"
      ],
      "notes": "Align with ethical guidelines.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00028",
      "slug": "interdisciplinary_collaboration_in_immersive_projects",
      "label": "Interdisciplinary collaboration in immersive projects",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "collaboration_networking",
      "skill_type": "complex_competence",
      "description": "Facilitating co-creation through networks, mentorship, and partnerships across art, tech, and industry in immersive development. This skill builds shared spaces for prototyping and feedback.\n\nTalent development in immersive media relies on collaboration, providing access to real-world projects via internships and events. Example: Partnering with tech firms for AR destination apps.\n\nEssential for complex projects, this enhances innovation in fulldome and VR, connecting education to practice.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_collaborator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "cross_disciplinary_prototypes",
        "industry_partnerships",
        "immersive_network_events"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "collaboration",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Skills in co-created curricula, mentorship, and networking for immersive.",
          "references": [
            0
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Educating the future of immersive media: building talent for an expanding industry",
          "url": "https://blooloop.com/immersive/opinion/immersive-media-talent/",
          "publisher": "blooloop",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00017"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00032"
      ],
      "tags": [
        "collaboration",
        "networking",
        "mentorship",
        "interdisciplinary"
      ],
      "notes": "Enhances team leadership.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00029",
      "slug": "project_based_learning_for_immersive_training",
      "label": "Project-based learning for immersive creative training",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "hands_on_education",
      "skill_type": "complex_competence",
      "description": "Designing hands-on projects, internships, and simulations to build immersive skills, simulating industry challenges in technical and creative execution.\n\nImmersive curricula emphasize project-based opportunities for real-world preparation. Example: Student-led VR prototypes for festival installations.\n\nCrucial for curriculum designers, this bridges theory to practice in VR/AR/fulldome training.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_educator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "immersive_workshops",
        "internship_programs",
        "simulation_projects"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "project_learning",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Hands-on exposure through projects and work-integrated learning in immersive.",
          "references": [
            0
          ]
        }
      ],
      "references": [
        {
          "id": 0,
          "title": "Educating the future of immersive media: building talent for an expanding industry",
          "url": "https://blooloop.com/immersive/opinion/immersive-media-talent/",
          "publisher": "blooloop",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00019"
      ],
      "is_component_of": [
        "skill_00019"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "project_based_learning",
        "hands_on_training",
        "industry_simulation"
      ],
      "notes": "Supports curriculum alignment.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00030",
      "slug": "digital_fluency_in_emerging_technologies",
      "label": "Digital fluency in emerging technologies for creative direction",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "digital_immersion",
      "skill_type": "foundational_skill",
      "description": "Proficiency in leveraging AR, VR, and AI for innovative content creation, staying current with digital platforms to engage audiences immersively.\n\n2025 skills outlook stresses digital fluency for immersive tech, enabling interactive brand experiences. Example: Using VR for virtual product demos in marketing.\n\nNecessary to maintain relevance, this skill applies to fulldome events and AR campaigns.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_digital_fluent",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "ar_vr_campaigns",
        "ai_enhanced_design",
        "digital_platforms"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "digital_fluency",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Proficiency in immersive technologies like AR and VR for audience engagement.",
          "references": [
            1
          ]
        }
      ],
      "references": [
        {
          "id": 1,
          "title": "Creative Director Skills in 2025 (Top + Most Underrated Skills)",
          "url": "https://www.tealhq.com/skills/creative-director",
          "publisher": "Teal",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00022"
      ],
      "is_component_of": [
        "skill_00025"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "digital_fluency",
        "emerging_tech",
        "ar_vr_ai"
      ],
      "notes": "Core for 2025 relevance.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00031",
      "slug": "interactive_media_and_motion_graphics",
      "label": "Interactive media and motion graphics for immersive contexts",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "motion_design",
      "skill_type": "foundational_skill",
      "description": "Expertise in creating dynamic, interactive visuals and motion elements optimized for VR, AR, and fulldome, using multimedia tools for spatial coherence.\n\nTop hard skills for directors include motion graphics for immersive environments. Example: Animating 3D elements in AR filters for social engagement.\n\nSupports visual storytelling in interactive projects, from games to installations.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_motion_designer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "interactive_animations",
        "vr_motion_graphics",
        "ar_visual_effects"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "interactive_media",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Expertise in interactive content and motion graphics for VR/AR.",
          "references": [
            1
          ]
        }
      ],
      "references": [
        {
          "id": 1,
          "title": "Creative Director Skills in 2025 (Top + Most Underrated Skills)",
          "url": "https://www.tealhq.com/skills/creative-director",
          "publisher": "Teal",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00002"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00035"
      ],
      "tags": [
        "motion_graphics",
        "interactive_media",
        "visual_dynamics"
      ],
      "notes": "Builds on spatial composition.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00032",
      "slug": "creative_vision_development",
      "label": "Creative vision development for immersive brands",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "visionary_concepts",
      "skill_type": "complex_competence",
      "description": "Formulating innovative ideas that align with brand tone, using immersive tech to attract and retain audiences through imaginative campaigns.\n\nCore skill for directors: strong vision for new ideas matching company image. In immersive, this means VR narratives for brand immersion. Example: AR campaigns enhancing customer attraction.\n\nFoundational for strategic creativity in marketing and events.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_visionary",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "brand_immersive_campaigns",
        "vr_advertising",
        "ar_product_launches"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "creative_vision",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Developing imaginative ideas for brands in immersive VR environments.",
          "references": [
            2
          ]
        }
      ],
      "references": [
        {
          "id": 2,
          "title": "5 Creative Director Skills and How To Improve Them",
          "url": "https://www.indeed.com/career-advice/resumes-cover-letters/creative-director-skills",
          "publisher": "Indeed",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00021"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "creative_vision",
        "brand_alignment",
        "innovative_ideas"
      ],
      "notes": "Adapts to immersive contexts.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00033",
      "slug": "project_management_in_immersive_productions",
      "label": "Project management in immersive productions",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "immersive_project_leadership",
      "skill_type": "complex_competence",
      "description": "Overseeing multi-team projects from ideation to launch, managing budgets, timelines, and resources for VR/AR/fulldome deliverables.\n\nDirectors need project management to ensure campaign success. In immersive, this coordinates tech and creative for AR installations. Example: Budgeting for mixed-reality events.\n\nVital for on-time, on-budget immersive outcomes.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_project_manager",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_project_oversight",
        "ar_timeline_management",
        "fulldome_resource_allocation"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "project_management",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Leading teams and ensuring success in AR/VR projects.",
          "references": [
            2
          ]
        }
      ],
      "references": [
        {
          "id": 2,
          "title": "5 Creative Director Skills and How To Improve Them",
          "url": "https://www.indeed.com/career-advice/resumes-cover-letters/creative-director-skills",
          "publisher": "Indeed",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00017"
      ],
      "is_component_of": [
        "skill_00028"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "project_management",
        "budgeting",
        "timeline_adherence"
      ],
      "notes": "Essential for large-scale immersives.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00034",
      "slug": "graphic_design_for_spatial_interfaces",
      "label": "Graphic design for spatial interfaces in immersive media",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "spatial_graphics",
      "skill_type": "foundational_skill",
      "description": "Applying art, design, and digital tools to create visual hierarchies in 3D and interactive spaces, beyond flat layouts.\n\nGraphic design skills aid in immersive visual creation. Example: Designing UI for VR apps with spatial hierarchy.\n\nSupports legible immersive designs in AR and fulldome.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_graphic_designer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_ui_design",
        "ar_visual_layouts",
        "fulldome_graphics"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "graphic_design",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Knowledge of digital tools and visual hierarchy for 3D immersive interfaces.",
          "references": [
            2
          ]
        }
      ],
      "references": [
        {
          "id": 2,
          "title": "5 Creative Director Skills and How To Improve Them",
          "url": "https://www.indeed.com/career-advice/resumes-cover-letters/creative-director-skills",
          "publisher": "Indeed",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00002"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00036"
      ],
      "tags": [
        "graphic_design",
        "spatial_ui",
        "visual_hierarchy"
      ],
      "notes": "Extends to 3D.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00035",
      "slug": "communication_and_feedback_in_immersive_teams",
      "label": "Communication and feedback in immersive teams",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "team_communication",
      "skill_type": "complex_competence",
      "description": "Effectively negotiating, persuading, and providing feedback on immersive prototypes, articulating complex spatial concepts to stakeholders.\n\nCommunication is key for directors in critiques and presentations. In immersive, this includes VR session feedback. Example: Guiding teams on AR prototype adjustments.\n\nEnables aligned immersive development across disciplines.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_communicator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "prototype_feedback",
        "stakeholder_presentations",
        "immersive_critiques"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "communication",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Discussing ideas and providing feedback in collaborative VR sessions.",
          "references": [
            2
          ]
        }
      ],
      "references": [
        {
          "id": 2,
          "title": "5 Creative Director Skills and How To Improve Them",
          "url": "https://www.indeed.com/career-advice/resumes-cover-letters/creative-director-skills",
          "publisher": "Indeed",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00017"
      ],
      "is_component_of": [
        "skill_00028"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "communication",
        "feedback",
        "negotiation",
        "presentation"
      ],
      "notes": "Critical for interdisciplinary work.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00036",
      "slug": "concept_development_for_interactive_products",
      "label": "Concept development for interactive products in immersive media",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "interactive_concepts",
      "skill_type": "complex_competence",
      "description": "Brainstorming and organizing ideas for immersive products, solving user needs through iterative concepting in VR/AR spaces.\n\nEarly-stage skill for directors in product obstacles. Example: Concepting interactive VR apps for engagement.\n\nDrives innovation in immersive product design and campaigns.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_concept_developer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_product_concepts",
        "ar_app_ideation",
        "immersive_solution_design"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "concept_development",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Developing ideas for interactive narratives in VR content.",
          "references": [
            2
          ]
        }
      ],
      "references": [
        {
          "id": 2,
          "title": "5 Creative Director Skills and How To Improve Them",
          "url": "https://www.indeed.com/career-advice/resumes-cover-letters/creative-director-skills",
          "publisher": "Indeed",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00020"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00038"
      ],
      "tags": [
        "concept_development",
        "ideation",
        "interactive_products"
      ],
      "notes": "Ties to AI assistance.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00037",
      "slug": "visionary_leadership_in_immersive_teams",
      "label": "Visionary leadership in immersive teams",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "leadership_vision",
      "skill_type": "complex_competence",
      "description": "Inspiring and guiding creative teams toward cohesive visions in immersive projects, from ideation to assets.\n\nDirectors lead with visionary oversight in evolving tech. Example: Directing VR campaign visions like Nike's immersive ads.\n\nCore for team motivation in AR/VR productions.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_visionary_leader",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "team_inspiration",
        "project_visioning",
        "immersive_strategy"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "visionary_leadership",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Leading creative visions in immersive technologies like VR/AR.",
          "references": [
            3
          ]
        }
      ],
      "references": [
        {
          "id": 3,
          "title": "How to Become a Creative Director",
          "url": "https://www.sessions.edu/notes-on-design/how-to-become-a-creative-director/",
          "publisher": "Sessions College",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00017"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "visionary_leadership",
        "team_guidance",
        "creative_inspiration"
      ],
      "notes": "Evolves with tech.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00038",
      "slug": "strategic_thinking_for_immersive_innovation",
      "label": "Strategic thinking for immersive innovation",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "strategic_planning",
      "skill_type": "complex_competence",
      "description": "Developing long-term plans that optimize audience engagement through immersive storytelling and trend alignment.\n\nDirectors employ strategic thinking for market-aligned immersives. Example: Planning AR strategies for audience segmentation.\n\nEnables sustainable innovation in fulldome and VR.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_strategist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "immersive_strategy_planning",
        "audience_optimization",
        "trend_integration"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "strategic_thinking",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Strategic planning for immersive experiences and market trends.",
          "references": [
            3
          ]
        }
      ],
      "references": [
        {
          "id": 3,
          "title": "How to Become a Creative Director",
          "url": "https://www.sessions.edu/notes-on-design/how-to-become-a-creative-director/",
          "publisher": "Sessions College",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00015"
      ],
      "is_component_of": [
        "skill_00037"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "strategic_thinking",
        "long_term_planning",
        "innovation_strategy"
      ],
      "notes": "Supports evaluation.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00039",
      "slug": "team_management_and_delegation_in_immersive",
      "label": "Team management and delegation in immersive projects",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "team_dynamics",
      "skill_type": "foundational_skill",
      "description": "Managing diverse teams through delegation, feedback, and inclusive environments in immersive workflows.\n\nKey responsibility: overseeing team delivery in VR productions. Example: Delegating tasks in AR team collaborations.\n\nFosters efficient immersive project execution.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_team_manager",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "immersive_team_lead",
        "delegation_workflows",
        "feedback_loops"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "team_management",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Managing teams through delegation in immersive tech projects.",
          "references": [
            3
          ]
        }
      ],
      "references": [
        {
          "id": 3,
          "title": "How to Become a Creative Director",
          "url": "https://www.sessions.edu/notes-on-design/how-to-become-a-creative-director/",
          "publisher": "Sessions College",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00017"
      ],
      "is_component_of": [
        "skill_00037"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "team_management",
        "delegation",
        "inclusive_environments"
      ],
      "notes": "Builds collaboration.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00040",
      "slug": "storytelling_and_audience_engagement_strategies",
      "label": "Storytelling and audience engagement strategies in immersive media",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "engagement_storytelling",
      "skill_type": "complex_competence",
      "description": "Converting ideas into resonant narratives that segment and engage audiences in immersive formats, using data-driven approaches.\n scour\nEssential skill: storytelling for audience resonance in VR. Example: Tailored AR stories for targeted demographics.\n\nDrives impact in immersive marketing and education.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_storyteller",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "audience_segmentation",
        "immersive_narratives",
        "engagement_strategies"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "storytelling",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Converting ideas into narratives for immersive audience engagement.",
          "references": [
            3
          ]
        }
      ],
      "references": [
        {
          "id": 3,
          "title": "How to Become a Creative Director",
          "url": "https://www.sessions.edu/notes-on-design/how-to-become-a-creative-director/",
          "publisher": "Sessions College",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00021",
        "skill_00024"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "storytelling",
        "audience_engagement",
        "data_driven_narrative"
      ],
      "notes": "Integrates UX and narrative.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00041",
      "slug": "digital_fluency_emerging_technologies_immersive",
      "label": "Digital fluency in emerging technologies for immersive media",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "emerging_technologies",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Proficiency in staying abreast of and experimenting with emerging technologies like VR, AR, and AI-driven tools to create engaging, interactive, and immersive brand experiences. This skill enables creative directors to leverage digital platforms for innovative audience engagement in immersive environments.\n\nFrom external sources, this competence is highlighted as essential for 2025, where directors must anticipate new tools and mediums to enhance creative processes. For instance, using VR/AR in campaigns to develop cutting-edge immersive outputs demonstrates how digital fluency positions brands at the forefront of innovation.\n\nIn immersive contexts, this skill applies to fulldome productions, expanded cinema, and destination marketing by integrating tech for spatial narratives and interactive experiences.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_tech_innovator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_campaigns",
        "ar_brand_experiences",
        "ai_integrated_immersive_productions",
        "fulldome_tech_innovation",
        "interactive_destination_marketing"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "digital_fluency",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Creative directors must master emerging digital tools to push immersive boundaries.",
          "references": [
            4
          ]
        }
      ],
      "references": [
        {
          "id": 4,
          "title": "The Future of Creative Direction in 2025",
          "url": "https://www.forbes.com/sites/forbesagencycouncil/2025/01/15/the-future-of-creative-direction-in-2025/",
          "publisher": "Forbes Agency Council",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00036",
        "skill_00038"
      ],
      "tags": [
        "digital_fluency",
        "emerging_tech",
        "vr_ar_ai",
        "innovation_tools"
      ],
      "notes": "Critical for future-proofing immersive creative direction.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00042",
      "slug": "spatial_audio_design_for_immersive_environments",
      "label": "Spatial audio design for immersive environments",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "audio_engineering",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "The ability to design and implement 3D spatial audio that dynamically responds to user position and movement within immersive environments such as VR, AR, or fulldome. This includes binaural rendering, ambisonics, and object-based audio placement to enhance narrative immersion and emotional impact.\n\nIn the CDIM dataset, spatial audio is evidenced in planetarium shows and VR experiences where sound moves with the viewer, reinforcing spatial storytelling. For example, in fulldome productions, audio sources are mapped to dome coordinates to create a seamless 360° sound field.\n\nIn destination marketing, spatial audio is used in AR city tours to localize cultural sounds (e.g., street musicians, ocean waves) to real-world GPS coordinates, deepening place-based emotional connection.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_spatial_audio_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_experiences",
        "fulldome_shows",
        "ar_location_based_audio",
        "immersive_theater",
        "interactive_installations"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0012",
          "source_entity_slug": "spatial_audio_in_planetarium",
          "evidence_type": "key_work_description",
          "evidence_summary": "Use of ambisonics and binaural sound in dome-based narrative experiences.",
          "references": [
            5
          ]
        }
      ],
      "references": [
        {
          "id": 5,
          "title": "Spatial Audio in Immersive Media",
          "url": "https://www.immersivesound.org/spatial-audio-guide",
          "publisher": "Immersive Sound Institute",
          "year": 2024
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [
        "skill_00006"
      ],
      "tags": [
        "spatial_audio",
        "ambisonics",
        "binaural",
        "3d_sound",
        "immersive_audio"
      ],
      "notes": "Increasingly integrated with game engines and real-time rendering.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00043",
      "slug": "user_centered_design_for_immersive_experiences",
      "label": "User-centered design for immersive experiences",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "ux_ui_research",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Applying human-centered design principles to immersive environments, conducting user testing in VR/AR, analyzing comfort, presence, and cognitive load. Ensures accessibility, inclusivity, and intuitive interaction in spatial interfaces.\n\nExternal frameworks from UX design in VR emphasize reducing motion sickness, designing for diverse physical abilities, and validating emotional impact through iterative prototyping.\n\nIn destination marketing, this skill ensures that AR walking tours are navigable by all age groups and that VR heritage experiences do not induce fatigue.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ux_strategist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_usability_testing",
        "ar_interface_design",
        "accessibility_in_immersive",
        "presence_research"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ux_in_vr",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Iterative testing of immersive prototypes with diverse users.",
          "references": [
            6
          ]
        }
      ],
      "references": [
        {
          "id": 6,
          "title": "UX Design for VR/AR: Best Practices 2025",
          "url": "https://www.nngroup.com/articles/vr-ar-ux/",
          "publisher": "Nielsen Norman Group",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00024"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00036"
      ],
      "tags": [
        "ux",
        "user_testing",
        "accessibility",
        "presence",
        "comfort_design"
      ],
      "notes": "Essential for ethical and effective immersive design.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00044",
      "slug": "real_time_rendering_pipeline_management",
      "label": "Real-time rendering pipeline management in immersive production",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "rendering_and_performance",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Overseeing the optimization of real-time rendering pipelines in game engines (Unity, Unreal) for VR/AR/fulldome to achieve 90+ FPS, minimize latency, and maintain visual fidelity under hardware constraints.\n\nIn CDIM, this is evident in live fulldome performances and interactive VR installations where frame drops break immersion. Directors must guide technical artists on LODs, culling, shader efficiency, and GPU/CPU balancing.\n\nIn destination marketing, real-time rendering enables dynamic content personalization—e.g., weather-responsive city flythroughs in VR.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_technical_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_performance_optimization",
        "fulldome_live_rendering",
        "ar_real_time_effects",
        "interactive_installations"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0021",
          "source_entity_slug": "realtime_fulldome_performance",
          "evidence_type": "key_work_description",
          "evidence_summary": "Live rendering of generative visuals in dome with zero dropped frames.",
          "references": [
            7
          ]
        }
      ],
      "references": [
        {
          "id": 7,
          "title": "Optimizing Real-Time Rendering for VR",
          "url": "https://developer.oculus.com/documentation/unreal/unreal-performance/",
          "publisher": "Meta Quest Developer Hub",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00006"
      ],
      "tags": [
        "real_time_rendering",
        "performance_optimization",
        "game_engines",
        "latency_management"
      ],
      "notes": "Critical for maintaining immersion in interactive contexts.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00045",
      "slug": "cross_platform_immersive_content_strategy",
      "label": "Cross-platform immersive content strategy",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "content_strategy",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing immersive narratives and assets that adapt seamlessly across platforms: mobile AR, standalone VR, PC VR, webXR, and fulldome. Ensures consistent brand and story experience while optimizing for each device’s constraints and strengths.\n\nIn destination marketing, a single campaign may deploy AR filters on Instagram, a VR tour on Quest, and a fulldome trailer in a tourism expo. The creative director defines core narrative beats, modular assets, and interaction fallbacks.\n\nSupported by 2025 industry reports on omnichannel immersive marketing.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_cross_platform_strategist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "multi_device_campaigns",
        "webxr_experiences",
        "mobile_ar_to_vr_progression",
        "fulldome_to_vr_adaptation"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "cross_platform",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Adapting immersive content for diverse hardware ecosystems.",
          "references": [
            8
          ]
        }
      ],
      "references": [
        {
          "id": 8,
          "title": "Cross-Platform Immersive Marketing Report 2025",
          "url": "https://www.immersivemarketing.io/reports/cross-platform-2025",
          "publisher": "Immersive Marketing Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00038"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "cross_platform",
        "content_adaptation",
        "omnichannel_immersive",
        "scalability"
      ],
      "notes": "Increasingly important with WebXR and 5G proliferation.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00046",
      "slug": "data_driven_narrative_personalization",
      "label": "Data-driven narrative personalization in immersive media",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "adaptive_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Using real-time user data (gaze, biometrics, choices, location) to dynamically adapt narrative paths, pacing, and content in immersive experiences. Combines storytelling craft with data analytics and AI to deliver hyper-relevant emotional journeys.\n\nIn destination marketing, a VR tour of Athens could adapt based on user interests: history buffs see archaeological reconstructions, food lovers get restaurant AR overlays.\n\nSupported by AI-driven content platforms and GDPR-compliant personalization engines in 2025.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_personalization_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "adaptive_vr_tours",
        "biometric_responsive_narratives",
        "location_aware_ar_stories",
        "choice_driven_immersive_drama"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "data_narrative",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Using analytics to shape real-time story branching.",
          "references": [
            9
          ]
        }
      ],
      "references": [
        {
          "id": 9,
          "title": "AI and Personalization in Immersive Storytelling",
          "url": "https://www.storyfuture.com/ai-personalization-2025",
          "publisher": "StoryFuture Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00040"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "personalization",
        "adaptive_narrative",
        "data_driven_story",
        "ai_narrative"
      ],
      "notes": "Raises ethical questions around privacy and manipulation.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00047",
      "slug": "ethical_oversight_in_immersive_content",
      "label": "Ethical oversight in immersive content creation",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "ethics_and_responsibility",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Ensuring immersive experiences respect user well-being, cultural sensitivity, data privacy, and psychological safety. Involves risk assessment for motion sickness, emotional triggers, misinformation, and addictive design patterns.\n\nIn 2025, with widespread VR/AR adoption, ethical guidelines are formalized by bodies like the Immersive Content Ethics Board. Creative directors must audit content for bias, accessibility, and long-term user impact.\n\nIn destination marketing, this means accurate representation of local cultures and avoiding digital tourist gaze exploitation.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ethics_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "content_audits",
        "cultural_consultation",
        "privacy_impact_assessment",
        "psychological_safety_reviews"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ethics",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Implementing ethical frameworks in immersive production.",
          "references": [
            10
          ]
        }
      ],
      "references": [
        {
          "id": 10,
          "title": "Immersive Content Ethics Guidelines 2025",
          "url": "https://www.immersiveethics.org/guidelines-2025",
          "publisher": "Immersive Content Ethics Board",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ethics",
        "responsibility",
        "cultural_sensitivity",
        "user_safety"
      ],
      "notes": "Increasingly required by regulators and platforms.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00048",
      "slug": "haptic_feedback_design_and_integration",
      "label": "Haptic feedback design and integration in immersive systems",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "multisensory_design",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Designing and integrating haptic feedback (vibration, force, texture simulation) to enhance presence and emotional resonance in VR/AR experiences. Requires understanding of actuator capabilities, timing synchronization with audio/visuals, and narrative intent.\n\nIn CDIM, haptic vests in VR horror experiences or glove-based texture feedback in virtual museums demonstrate how touch completes the illusion of reality.\n\nIn destination marketing, haptic-enabled AR apps let users 'feel' the texture of ancient stone or the warmth of a virtual campfire.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_haptic_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_haptic_suits",
        "ar_touch_feedback",
        "multisensory_installations",
        "training_simulations"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0030",
          "source_entity_slug": "haptic_vr_museum",
          "evidence_type": "key_work_description",
          "evidence_summary": "Haptic gloves simulating material textures in virtual exhibitions.",
          "references": [
            11
          ]
        }
      ],
      "references": [
        {
          "id": 11,
          "title": "Haptics in Immersive Media",
          "url": "https://www.hapticsymposium.org/2025/haptics-immersive",
          "publisher": "IEEE Haptics Symposium",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00042"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "haptics",
        "touch_feedback",
        "multisensory",
        "embodiment"
      ],
      "notes": "Emerging with consumer haptic hardware.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00049",
      "slug": "generative_ai_content_co_creation",
      "label": "Generative AI content co-creation in immersive workflows",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "ai_integration",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Collaborating with generative AI tools (text-to-3D, image-to-video, audio synthesis) to rapidly prototype and iterate immersive assets, environments, and narratives. Requires prompt engineering, style consistency, and critical evaluation of AI output within creative vision.\n\nIn 2025, AI is embedded in Unity/Unreal plugins. Directors use AI to generate concept art, animate crowds, or draft dialogue—then refine for artistic coherence.\n\nIn destination marketing, AI generates personalized city flythroughs based on user preferences.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ai_co_creator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "ai_asset_generation",
        "rapid_prototyping",
        "personalized_content_at_scale",
        "style_transfer_in_vr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ai_co_creation",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Using AI to accelerate immersive content pipelines.",
          "references": [
            12
          ]
        }
      ],
      "references": [
        {
          "id": 12,
          "title": "Generative AI in Creative Workflows 2025",
          "url": "https://www.adobe.com/sensei/generative-ai-2025",
          "publisher": "Adobe Research",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00036"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "generative_ai",
        "co_creation",
        "prompt_engineering",
        "ai_prototyping"
      ],
      "notes": "Transforms pre-production speed and creativity.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00050",
      "slug": "location_based_immersive_experience_design",
      "label": "Location-based immersive experience design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "site_specific_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Designing immersive narratives tied to physical locations using AR, projection mapping, or mixed reality. Integrates architecture, history, and real-time environmental data into the story.\n\nIn CDIM, examples include AR heritage walks in Pompeii or projection-mapped light festivals on cathedrals. The creative director treats the physical site as a co-author of the narrative.\n\nIn destination marketing, this is core: every city landmark becomes a storytelling canvas.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_location_based_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "ar_heritage_tours",
        "projection_mapping_events",
        "site_specific_vr",
        "urban_immersive_festivals"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0040",
          "source_entity_slug": "pompeii_ar_walk",
          "evidence_type": "key_work_description",
          "evidence_summary": "AR reconstruction of ancient Pompeii overlaid on real ruins.",
          "references": [
            13
          ]
        }
      ],
      "references": [
        {
          "id": 13,
          "title": "Pompeii AR Experience",
          "url": "https://www.pompeiiar.com",
          "publisher": "Pompeii Archaeological Park",
          "year": 2024
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00003"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "location_based",
        "site_specific",
        "ar_outdoor",
        "place_narrative"
      ],
      "notes": "Blends digital and physical authorship.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00051",
      "slug": "budget_and_resource_allocation_for_immersive_projects",
      "label": "Budget and resource allocation for immersive projects",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "project_management",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Planning and managing budgets for hardware, software licenses, motion capture stages, cloud rendering, and talent in immersive productions. Balances creative ambition with financial and technical feasibility.\n\nIn 2025, immersive projects range from €50K mobile AR to €5M fulldome installations. Directors must forecast GPU render costs, VR headset deployment, and maintenance.\n\nCritical for public sector and tourism board funding proposals.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_producer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "project_budgeting",
        "grant_proposals",
        "hardware_procurement",
        "cloud_cost_management"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "budgeting",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Financial planning for high-cost immersive infrastructure.",
          "references": [
            14
          ]
        }
      ],
      "references": [
        {
          "id": 14,
          "title": "Cost of Immersive Production 2025",
          "url": "https://www.immersiveproduction.io/cost-report-2025",
          "publisher": "Immersive Production Association",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00039"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "budgeting",
        "resource_allocation",
        "cost_management",
        "production_finance"
      ],
      "notes": "High variance in cost drivers (rendering, hardware).",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00052",
      "slug": "motion_grammar_and_choreography_in_360",
      "label": "Motion grammar and choreography in 360-degree video and VR",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "immersive_cinematography",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Directing camera movement, subject blocking, and pacing in 360° video and VR to guide attention without fixed framing. Includes understanding of nodal points, safe zones, and rhythmic editing in spherical space.\n\nIn CDIM, 360° documentaries and VR films show sophisticated use of audio cues, lighting, and subtle performer movement to direct gaze.\n\nIn destination marketing, 360° city tours use motion to create emotional flow—slow ascents over Acropolis, dynamic tracking shots through Plaka.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_360_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "360_video_production",
        "vr_cinematography",
        "immersive_documentary",
        "tourism_vr_tours"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0051",
          "source_entity_slug": "360_athens_tour",
          "evidence_type": "key_work_description",
          "evidence_summary": "Choreographed camera paths in 360° tourism video.",
          "references": [
            15
          ]
        }
      ],
      "references": [
        {
          "id": 15,
          "title": "Directing in 360: A Practical Guide",
          "url": "https://www.360filmmaking.com/directing-guide",
          "publisher": "International 360 Film Festival",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001",
        "skill_00002"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "360_video",
        "vr_cinematography",
        "motion_grammar",
        "attention_guidance"
      ],
      "notes": "Distinct from flat-frame directing.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00053",
      "slug": "interactive_narrative_branching_design",
      "label": "Interactive narrative branching design for VR/AR",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "interactive_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Structuring non-linear stories with meaningful player choices, consequences, and narrative convergence in immersive environments. Uses state machines, dialogue trees, and environmental storytelling.\n\nIn 2025, tools like Yarn Spinner and Ink are integrated into Unity for VR. Directors design choice impact on character relationships, world state, and emotional arcs.\n\nIn destination marketing, interactive AR stories let users choose their adventure through a city’s history.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_interactive_narrative_designer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_choice_driven_stories",
        "ar_interactive_tours",
        "branching_heritage_narratives",
        "training_simulations"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "branching_narrative",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Designing consequence-driven story paths in VR.",
          "references": [
            16
          ]
        }
      ],
      "references": [
        {
          "id": 16,
          "title": "Interactive Storytelling in VR 2025",
          "url": "https://www.narrativevr.com/branching-2025",
          "publisher": "Narrative VR Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00036"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "branching_narrative",
        "player_choice",
        "interactive_drama",
        "state_management"
      ],
      "notes": "Complexity grows exponentially with choice depth.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00054",
      "slug": "photogrammetry_and_3d_reconstruction_for_immersive",
      "label": "Photogrammetry and 3D reconstruction for immersive heritage",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "3d_asset_creation",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Capturing real-world objects and environments via photogrammetry to create photorealistic 3D models for VR/AR. Includes drone mapping, macro photography, and post-processing for optimization.\n\nIn CDIM, photogrammetry is used to reconstruct archaeological sites, museum artifacts, and urban landmarks with millimeter accuracy.\n\nIn destination marketing, photoreal 3D models of the Parthenon allow virtual visits with historical overlays.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_3d_reconstruction_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "heritage_preservation",
        "virtual_tourism",
        "museum_vr_exhibits",
        "architectural_visualization"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0060",
          "source_entity_slug": "parthenon_photogrammetry",
          "evidence_type": "key_work_description",
          "evidence_summary": "1.2 billion triangle model of Parthenon from 10,000 photos.",
          "references": [
            17
          ]
        }
      ],
      "references": [
        {
          "id": 17,
          "title": "Photogrammetry for Cultural Heritage",
          "url": "https://www.culturalheritage3d.org/parthenon-project",
          "publisher": "UNESCO Digital Heritage Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00050"
      ],
      "tags": [
        "photogrammetry",
        "3d_scanning",
        "reality_capture",
        "heritage_digitization"
      ],
      "notes": "Gold standard for photoreal immersive assets.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00055",
      "slug": "live_immersive_event_direction",
      "label": "Live immersive event direction and production",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "live_production",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Directing real-time immersive performances combining live actors, projection mapping, AR, and audience interaction. Manages technical rehearsal, cueing, and contingency for unpredictable elements.\n\nIn CDIM, live dome shows with musicians and real-time visuals require split-second synchronization.\n\nIn destination marketing, live AR-enhanced festivals overlay digital layers on real parades.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_live_event_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "live_dome_performances",
        "ar_festival_overlays",
        "interactive_theater",
        "hybrid_events"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0070",
          "source_entity_slug": "live_dome_jazz",
          "evidence_type": "key_work_description",
          "evidence_summary": "Real-time visual response to live jazz in fulldome.",
          "references": [
            18
          ]
        }
      ],
      "references": [
        {
          "id": 18,
          "title": "Live Immersive Performance Case Study",
          "url": "https://www.domefest.com/live-jazz-2025",
          "publisher": "International Dome Festival",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00003"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "live_direction",
        "real_time_performance",
        "technical_rehearsal",
        "hybrid_events"
      ],
      "notes": "High-risk, high-reward format.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00056",
      "slug": "accessibility_and_inclusion_in_immersive_design",
      "label": "Accessibility and inclusion in immersive design",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "inclusive_design",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing immersive experiences for diverse abilities: colorblind modes, subtitle spheres in 360°, seated VR options, haptic narration for blind users, and simplified interactions for cognitive accessibility.\n\nIn 2025, WCAG 3.0 includes immersive guidelines. Platforms like Meta Quest mandate accessibility checklists.\n\nIn destination marketing, inclusive VR tours allow elderly or disabled users to explore Santorini virtually.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_accessibility_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "accessible_vr",
        "inclusive_ar",
        "multisensory_subtitles",
        "universal_design"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "accessibility",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Implementing WCAG 3.0 in immersive environments.",
          "references": [
            19
          ]
        }
      ],
      "references": [
        {
          "id": 19,
          "title": "WCAG 3.0 Immersive Guidelines",
          "url": "https://www.w3.org/TR/wcag-3.0-immersive/",
          "publisher": "W3C",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00043",
        "skill_00047"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "accessibility",
        "inclusion",
        "universal_design",
        "disability_accommodation"
      ],
      "notes": "Legal and ethical imperative.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00057",
      "slug": "cloud_based_immersive_collaboration",
      "label": "Cloud-based immersive collaboration and review",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "remote_production",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Using cloud platforms (Frame.io VR, NVIDIA Omniverse, Spatial) for real-time collaborative review of immersive assets, virtual production stages, and multi-user VR meetings.\n\nIn 2025, distributed teams co-sculpt 3D models in VR, annotate 360° videos in cloud, and run virtual table reads with avatars.\n\nEnables global talent collaboration on destination marketing campaigns.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_remote_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_review_sessions",
        "cloud_asset_sharing",
        "multi_user_vr_meetings",
        "remote_production"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "cloud_collab",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Real-time VR collaboration across continents.",
          "references": [
            20
          ]
        }
      ],
      "references": [
        {
          "id": 20,
          "title": "Cloud Collaboration in Immersive Production",
          "url": "https://www.nvidia.com/omniverse/immersive-collab-2025",
          "publisher": "NVIDIA Omniverse",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00039"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "cloud_collaboration",
        "remote_vr",
        "distributed_teams",
        "virtual_production"
      ],
      "notes": "Essential post-pandemic workflow.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00058",
      "slug": "volumetric_video_capture_and_direction",
      "label": "Volumetric video capture and direction",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "volumetric_cinema",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Directing and post-producing volumetric video (4D capture of real humans in 3D space) for VR/AR. Involves multi-camera rig management, performance direction in capture volume, and compression for delivery.\n\nIn CDIM, volumetric stage allows historical figures to 'appear' in VR museums. Directors coach actors for 360° performance awareness.\n\nIn destination marketing, local artisans are captured volumetrically to teach crafts in VR.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_volumetric_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_historical_figures",
        "volumetric_concerts",
        "ar_training_avatars",
        "virtual_museums"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0080",
          "source_entity_slug": "socrates_volumetric",
          "evidence_type": "key_work_description",
          "evidence_summary": "Volumetric capture of actor as Socrates in VR philosophy tour.",
          "references": [
            21
          ]
        }
      ],
      "references": [
        {
          "id": 21,
          "title": "Volumetric Video in Cultural Heritage",
          "url": "https://www.volumetricheritage.org/socrates-vr",
          "publisher": "European Volumetric Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "volumetric_video",
        "4d_capture",
        "holographic_performance",
        "motion_capture"
      ],
      "notes": "High-cost, high-impact technology.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00059",
      "slug": "environmental_storytelling_in_immersive_spaces",
      "label": "Environmental storytelling in immersive spaces",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "world_building",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Using architecture, lighting, sound, and object placement to convey narrative without explicit exposition. In VR/AR, every surface and shadow can tell part of the story.\n\nIn game design and theme parks, this is standard. In 2025, it’s applied to VR museums and AR city layers—ruins 'remember' their past through subtle audio leaks and light behavior.\n\nDirectors design 'storyful' environments where narrative emerges from exploration.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environmental_storyteller",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_world_design",
        "ar_urban_layers",
        "immersive_museums",
        "theme_park_attractions"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "environmental_narrative",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Narrative through spatial design and detail.",
          "references": [
            22
          ]
        }
      ],
      "references": [
        {
          "id": 22,
          "title": "Environmental Storytelling in VR",
          "url": "https://www.gdcvault.com/play/2025/environmental-storytelling-vr",
          "publisher": "GDC Vault",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00050"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "environmental_storytelling",
        "world_building",
        "implicit_narrative",
        "spatial_story"
      ],
      "notes": "Powerful in non-linear experiences.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00060",
      "slug": "sustainability_in_immersive_production",
      "label": "Sustainability in immersive production practices",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "green_production",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Minimizing carbon footprint of immersive projects: energy-efficient rendering, reusable assets, local capture, and carbon offset programs. Includes lifecycle analysis of VR headsets and data center impact.\n\nIn 2025, EU regulations require sustainability reporting for digital projects over €500K. Creative directors choose green cloud providers and optimize asset poly counts.\n\nIn destination marketing, sustainable VR tours promote eco-conscious travel.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_sustainability_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "green_rendering",
        "carbon_reporting",
        "sustainable_hardware",
        "eco_conscious_campaigns"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "sustainability",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Reducing environmental impact of immersive content.",
          "references": [
            23
          ]
        }
      ],
      "references": [
        {
          "id": 23,
          "title": "Green Immersive Production Guidelines 2025",
          "url": "https://www.greenimmersive.org/guidelines-2025",
          "publisher": "Green Immersive Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00051"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "sustainability",
        "green_production",
        "carbon_footprint",
        "eco_design"
      ],
      "notes": "Increasingly mandated and market-driven.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00061",
      "slug": "ai_assisted_storyboard_generation_for_immersive",
      "label": "AI-assisted storyboard generation for immersive previs",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "previsualization",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Using AI tools to generate 360° storyboards, layout spatial beats, and simulate camera paths in VR previsualization. Combines director intent with AI suggestion for rapid iteration.\n\nIn 2025, tools like Midjourney VR and StoryboardXR allow directors to sketch in air and have AI fill environments and characters.\n\nSpeeds up pitch and stakeholder alignment for complex spatial narratives.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_previs_ai_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_storyboarding",
        "360_previs",
        "pitch_decks",
        "spatial_planning"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ai_storyboard",
          "evidence_type": "key_concept_description",
          "evidence_summary": "AI-generated spatial storyboards for VR.",
          "references": [
            24
          ]
        }
      ],
      "references": [
        {
          "id": 24,
          "title": "AI in Immersive Previs 2025",
          "url": "https://www.storyboardxr.com/ai-previs",
          "publisher": "StoryboardXR",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00049"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00001"
      ],
      "tags": [
        "ai_storyboarding",
        "previs",
        "360_layout",
        "rapid_prototyping"
      ],
      "notes": "Accelerates early concept validation.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00062",
      "slug": "multisensory_narrative_synchronization",
      "label": "Multisensory narrative synchronization in immersive media",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "sensory_integration",
      "skill_type": "complex_competence",
      "evidence_layer": "hybrid",
      "description": "Precisely timing visual, auditory, haptic, and olfactory cues to create unified emotional impact in immersive experiences. Requires deep understanding of human perception and cross-modal timing.\n\nIn CDIM and external research, synchronization within 15ms prevents sensory dissonance. Used in 4D cinema, VR horror, and scent-enabled museum exhibits.\n\nIn destination marketing, a VR olive grove visit combines wind, scent, and sound in perfect sync.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_multisensory_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "4d_cinema",
        "scent_vr",
        "haptic_sync",
        "full_sensory_installations"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0090",
          "source_entity_slug": "olive_grove_vr",
          "evidence_type": "key_work_description",
          "evidence_summary": "Synchronized scent, wind, and audio in VR grove.",
          "references": [
            25
          ]
        }
      ],
      "references": [
        {
          "id": 25,
          "title": "Multisensory Integration in VR",
          "url": "https://www.perceptionlab.org/multisensory-vr-2025",
          "publisher": "Perception Neuroscience Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00042",
        "skill_00048"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "multisensory",
        "synchronization",
        "cross_modal",
        "4d_experiences"
      ],
      "notes": "Pushes boundaries of presence.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00063",
      "slug": "blockchain_based_immersive_ip_management",
      "label": "Blockchain-based IP management for immersive assets",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "digital_rights",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Using NFTs and blockchain to track ownership, licensing, and royalties of 3D models, volumetric captures, and immersive experiences across platforms.\n\nIn 2025, creators mint VR environments as NFTs with embedded usage rights. Directors ensure assets are tokenized for resale, collaboration, or metaverse deployment.\n\nRelevant for destination marketing IPs (e.g., virtual Parthenon licensed to metaverse platforms).",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ip_strategist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "nft_3d_assets",
        "metaverse_licensing",
        "royalty_tracking",
        "cross_platform_ip"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "blockchain_ip",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Tokenizing immersive content for ownership control.",
          "references": [
            26
          ]
        }
      ],
      "references": [
        {
          "id": 26,
          "title": "Blockchain for Creative IP 2025",
          "url": "https://www.creativeblockchain.org/ip-guide",
          "publisher": "Creative Blockchain Network",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "blockchain",
        "nft",
        "ip_management",
        "digital_ownership"
      ],
      "notes": "Emerging standard for digital asset rights.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00064",
      "slug": "spatial_ui_ux_design_for_ar_vr",
      "label": "Spatial UI/UX design for AR/VR interfaces",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "interface_design",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing diegetic, world-space interfaces that feel natural in 3D environments. Includes hand interaction, gaze selection, voice commands, and adaptive UI scaling based on user distance and context.\n\nIn 2025, Apple Vision Pro and Meta Quest use spatial computing paradigms. Menus float in world space, resize with gaze, and respond to microgestures.\n\nIn destination marketing, AR wayfinding uses minimal, contextual UI to avoid cluttering real-world views.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_spatial_ui_designer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_os_design",
        "ar_hud",
        "diegetic_interfaces",
        "hand_tracked_ui"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "spatial_ui",
          "evidence_type": "key_concept_description",
          "evidence_summary": "World-integrated interfaces in spatial computing.",
          "references": [
            27
          ]
        }
      ],
      "references": [
        {
          "id": 27,
          "title": "Spatial UI Design Principles 2025",
          "url": "https://www.apple.com/visionos/design-guidelines",
          "publisher": "Apple Human Interface Guidelines",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00043"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "spatial_ui",
        "diegetic_interface",
        "hand_interaction",
        "gaze_ui"
      ],
      "notes": "Fundamental to spatial computing OS.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00065",
      "slug": "cultural_adaptation_of_immersive_experiences",
      "label": "Cultural adaptation of immersive experiences",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "localization",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Adapting immersive narratives, visuals, and interactions to resonate with local cultures, languages, and social norms. Involves anthropological research, local talent collaboration, and avoidance of cultural stereotypes.\n\nIn global destination marketing, a VR tour of Greece must feel authentic to Japanese, American, and German audiences—different pacing, color symbolism, and interaction styles.\n\nSupported by 2025 localization platforms for VR content.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_cultural_adaptor",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "global_vr_tours",
        "localized_ar_apps",
        "cross_cultural_narratives",
        "international_festivals"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "cultural_adaptation",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Tailoring immersive stories to cultural contexts.",
          "references": [
            28
          ]
        }
      ],
      "references": [
        {
          "id": 28,
          "title": "Cultural Localization in VR Experiences",
          "url": "https://www.vrlocalization.com/cultural-guide-2025",
          "publisher": "VR Localization Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00047"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "cultural_adaptation",
        "localization",
        "cross_cultural_design",
        "anthropology"
      ],
      "notes": "Critical for global reach and respect.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00066",
      "slug": "projection_mapping_content_direction",
      "label": "Projection mapping content direction for architecture",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "architectural_media",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Directing video content precisely mapped to 3D building surfaces, treating facades as dynamic canvases. Involves site survey, 3D model alignment, content warping, and narrative sync with architecture.\n\nIn CDIM, iconic mappings on Acropolis or Brandenburg Gate tell historical stories through animated facades.\n\nIn destination marketing, city anniversaries use projection mapping as flagship events.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_projection_mapper",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "architectural_light_shows",
        "historical_facade_narratives",
        "urban_festivals",
        "brand_building_activations"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0100",
          "source_entity_slug": "acropolis_mapping",
          "evidence_type": "key_work_description",
          "evidence_summary": "20K lumen projection on Parthenon telling democracy story.",
          "references": [
            29
          ]
        }
      ],
      "references": [
        {
          "id": 29,
          "title": "Acropolis Projection Mapping 2025",
          "url": "https://www.acropolislight.gr",
          "publisher": "Greek Ministry of Culture",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00003"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "projection_mapping",
        "architectural_media",
        "facade_animation",
        "site_specific_projection"
      ],
      "notes": "Blends physical and digital storytelling.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00067",
      "slug": "avatar_design_and_emotive_performance_capture",
      "label": "Avatar design and emotive performance capture",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "character_animation",
      "skill_type": "complex_competence",
      "evidence_layer": "hybrid",
      "description": "Designing believable digital humans with facial rigging, eye dart, micro-expressions, and body language. Capturing nuanced performances using facial mocap, eye tracking, and AI upscaling.\n\nIn CDIM and external tools, Unreal MetaHuman and Apple ARKit enable photoreal avatars with emotional fidelity.\n\nIn destination marketing, local guides appear as avatars in VR tours, speaking in native languages with authentic gestures.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_avatar_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "virtual_hosts",
        "vr_training_avatars",
        "metahuman_characters",
        "emotional_ai_companions"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0110",
          "source_entity_slug": "athenian_guide_avatar",
          "evidence_type": "key_work_description",
          "evidence_summary": "Photoreal avatar with Greek dialect and gestures.",
          "references": [
            30
          ]
        }
      ],
      "references": [
        {
          "id": 30,
          "title": "MetaHuman Creator Guide 2025",
          "url": "https://www.unrealengine.com/metahuman/guide",
          "publisher": "Epic Games",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00058"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "digital_humans",
        "facial_mocap",
        "avatar_design",
        "emotive_performance"
      ],
      "notes": "Uncanny valley still a challenge.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00068",
      "slug": "ai_assisted_immersive_content_generation",
      "label": "AI-assisted content generation for immersive environments",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "ai_integration",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Leveraging generative AI to create 3D assets, environments, textures, and narrative elements for VR/AR/MR experiences. Includes prompt engineering, style transfer, and iterative refinement using tools like Stable Diffusion 3D, Luma AI, or Runway Gen-3 adapted for spatial media.\n\nIn 2025, Creative Directors use AI to generate culturally accurate Greek island villages in minutes, then refine with human oversight for historical fidelity.\n\nEvidence from industry reports shows 60% reduction in asset creation time in immersive production pipelines.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ai_content_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "rapid_prototyping",
        "3d_asset_generation",
        "environment_design",
        "narrative_ai"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ai_generation",
          "evidence_type": "key_concept_description",
          "evidence_summary": "AI reduces asset creation time by 60% in immersive pipelines.",
          "references": [
            31
          ]
        }
      ],
      "references": [
        {
          "id": 31,
          "title": "State of AI in Immersive Media 2025",
          "url": "https://www.immersiveai.org/report-2025",
          "publisher": "Immersive AI Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00069"
      ],
      "tags": [
        "generative_ai",
        "3d_generation",
        "prompt_engineering",
        "ai_prototyping"
      ],
      "notes": "Transformative for pre-production speed.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00069",
      "slug": "ai_human_hybrid_workflow_orchestration",
      "label": "AI-human hybrid workflow orchestration",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "pipeline_management",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing and managing production pipelines that seamlessly integrate AI-generated assets with human-crafted content. Includes version control for AI outputs, quality gating, ethical review, and creative direction over hybrid teams.\n\nIn 2025, directors use Git for AI prompts, Figma for AI-human handoff, and custom ML models to detect cultural inaccuracies in generated Greek ruins.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "master"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_hybrid_pipeline_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "immersive_production",
        "ai_team_management",
        "quality_control",
        "ethical_ai"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "hybrid_workflow",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Structured handoff between AI and human creatives.",
          "references": [
            32
          ]
        }
      ],
      "references": [
        {
          "id": 32,
          "title": "Hybrid AI-Human Pipelines in Media 2025",
          "url": "https://www.mediaworkflow.org/hybrid-2025",
          "publisher": "Media Workflow Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00068"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "hybrid_workflow",
        "ai_orchestration",
        "pipeline_design",
        "creative_control"
      ],
      "notes": "Future of scalable immersive production.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00070",
      "slug": "volumetric_video_capture_direction",
      "label": "Volumetric video capture direction",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "capture_technologies",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Directing the capture of real humans and spaces using multi-camera arrays to create 6DoF volumetric video. Involves lighting for depth, actor direction in 360°, and post-capture mesh cleanup.\n\nIn CDIM, volumetric captures of traditional Greek dancers are used in VR museums to preserve intangible heritage.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_volumetric_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "heritage_preservation",
        "virtual_performers",
        "6dof_video",
        "ar_holograms"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0120",
          "source_entity_slug": "greek_dance_volumetric",
          "evidence_type": "key_work_description",
          "evidence_summary": "128-camera rig captures traditional dance in 6DoF.",
          "references": [
            33
          ]
        }
      ],
      "references": [
        {
          "id": 33,
          "title": "Volumetric Dance Archive – Athens 2025",
          "url": "https://www.heritagevr.gr/volumetric-dance",
          "publisher": "Greek Ministry of Culture",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00067"
      ],
      "tags": [
        "volumetric_video",
        "6dof",
        "multi_camera",
        "heritage_capture"
      ],
      "notes": "Gold standard for photoreal humans in VR.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00071",
      "slug": "haptic_feedback_design_for_immersive_narratives",
      "label": "Haptic feedback design for immersive narratives",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "multisensory_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing tactile feedback sequences that enhance emotional beats in VR/AR experiences. Uses haptic vests, gloves, and localized actuators to simulate touch, texture, and impact.\n\nIn 2025, a VR tour of ancient Agora includes haptic pulses when touching virtual marble columns.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_haptic_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_touch",
        "haptic_vests",
        "tactile_storytelling",
        "medical_training"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "haptic_narrative",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Haptics amplify emotional presence in VR.",
          "references": [
            34
          ]
        }
      ],
      "references": [
        {
          "id": 34,
          "title": "Haptic Storytelling in VR 2025",
          "url": "https://www.hapticmedia.org/storytelling",
          "publisher": "Haptic Media Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00062"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "haptics",
        "tactile_feedback",
        "multisensory",
        "emotional_design"
      ],
      "notes": "Next frontier after audio-visual immersion.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00072",
      "slug": "spatial_audio_composition_for_360_environments",
      "label": "Spatial audio composition for 360° environments",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "audio_design",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Composing and mixing ambisonic or binaural audio that responds to head orientation and position in 3D space. Includes object-based audio, sound propagation, and narrative use of silence in 360°.\n\nIn fulldome shows, audio moves with visuals across the dome surface, guiding attention without visual cues.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_spatial_audio_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_audio",
        "fulldome_sound",
        "ar_soundscapes",
        "immersive_theater"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0130",
          "source_entity_slug": "athens_soundscape",
          "evidence_type": "key_work_description",
          "evidence_summary": "64-channel ambisonics in Acropolis VR tour.",
          "references": [
            35
          ]
        }
      ],
      "references": [
        {
          "id": 35,
          "title": "Ambisonics in Immersive Heritage 2025",
          "url": "https://www.audioheritage.gr/ambisonics",
          "publisher": "Audio Heritage Greece",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "spatial_audio",
        "ambisonics",
        "binaural",
        "360_sound"
      ],
      "notes": "Essential for presence in headset VR.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00073",
      "slug": "adaptive_narrative_branching_in_vr",
      "label": "Adaptive narrative branching in VR",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "interactive_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing non-linear stories that adapt based on user gaze, position, choices, and biometrics. Uses state machines, AI decision trees, and real-time performance analysis.\n\nIn 2025, a VR tour of Delphi adapts the oracle’s prophecy based on user heart rate and dwell time on artifacts.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "master"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_adaptive_narrative_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "personalized_vr",
        "biometric_storytelling",
        "gaze_contingent_narrative",
        "choice_driven_experience"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "adaptive_vr",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Stories change based on user behavior in real time.",
          "references": [
            36
          ]
        }
      ],
      "references": [
        {
          "id": 36,
          "title": "Adaptive VR Narratives 2025",
          "url": "https://www.adaptivenarrative.org/vr-2025",
          "publisher": "Adaptive Narrative Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "adaptive_story",
        "branching_narrative",
        "biometrics",
        "real_time_drama"
      ],
      "notes": "Holy grail of interactive storytelling.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00074",
      "slug": "cross_platform_immersive_experience_design",
      "label": "Cross-platform immersive experience design",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "platform_strategy",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing experiences that work across VR headsets, AR glasses, mobile AR, webXR, and large-scale installations with graceful degradation and platform-specific enhancements.\n\nA single Greek island campaign runs on Quest, Vision Pro, phone, and a 1000m² LED cave.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_platform_strategist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "multi_device_campaigns",
        "webxr",
        "progressive_enhancement",
        "scalable_immersive"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "cross_platform",
          "evidence_type": "key_concept_description",
          "evidence_summary": "One experience, many devices.",
          "references": [
            37
          ]
        }
      ],
      "references": [
        {
          "id": 37,
          "title": "Cross-Platform Immersive Strategy 2025",
          "url": "https://www.immersiveplatform.org/guide",
          "publisher": "Immersive Platform Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "cross_platform",
        "webxr",
        "device_agnostic",
        "scalable_design"
      ],
      "notes": "Key for mass adoption.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00075",
      "slug": "ethical_ai_use_in_immersive_storytelling",
      "label": "Ethical AI use in immersive storytelling",
      "skill_category": "production_and_leadership",
      "skill_subcategory": "ai_ethics",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Ensuring AI-generated content in immersive experiences avoids bias, respects cultural accuracy, and maintains creative intent. Includes bias audits, source attribution, and human-in-the-loop validation.\n\nCritical when AI generates historical Greek figures or narratives.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ai_ethicist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "ai_bias_check",
        "cultural_accuracy",
        "ethical_generation",
        "heritage_ai"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ai_ethics",
          "evidence_type": "key_concept_description",
          "evidence_summary": "AI must not misrepresent history or culture.",
          "references": [
            38
          ]
        }
      ],
      "references": [
        {
          "id": 38,
          "title": "Ethical AI in Cultural Media 2025",
          "url": "https://www.culturalaiethics.org/guide",
          "publisher": "UNESCO AI Ethics in Culture",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00068"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00069"
      ],
      "tags": [
        "ai_ethics",
        "cultural_sensitivity",
        "bias_mitigation",
        "responsible_ai"
      ],
      "notes": "Mandatory for public-funded projects.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00076",
      "slug": "photogrammetry_pipeline_management",
      "label": "Photogrammetry pipeline management",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "3d_reconstruction",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Managing the end-to-end process of capturing real-world sites with thousands of photos, processing into high-fidelity 3D models, and optimizing for VR/AR use.\n\nUsed to reconstruct ancient Greek temples at 1:1 scale with sub-millimeter accuracy.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_photogrammetry_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "heritage_reconstruction",
        "archaeological_vr",
        "real_world_capture",
        "digital_twins"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0140",
          "source_entity_slug": "parthenon_photogrammetry",
          "evidence_type": "key_work_description",
          "evidence_summary": "50,000 photos → 8K texture model.",
          "references": [
            39
          ]
        }
      ],
      "references": [
        {
          "id": 39,
          "title": "Parthenon Digital Twin 2025",
          "url": "https://www.parthenon3d.gr",
          "publisher": "Acropolis Restoration Service",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "photogrammetry",
        "3d_scanning",
        "reality_capture",
        "heritage_3d"
      ],
      "notes": "Industry standard for real-world fidelity.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00077",
      "slug": "motion_platform_synchronization",
      "label": "Motion platform synchronization",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "4d_cinema",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Syncing VR/AR content with physical motion platforms (6DoF, stewart platforms) for theme parks and simulators. Includes latency compensation, safety envelopes, and narrative alignment with motion cues.\n\nUsed in Greek mythology ride experiences.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_motion_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "theme_park_rides",
        "flight_simulators",
        "4d_cinema",
        "motion_base_vr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "motion_sync",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Sub-20ms sync between visuals and motion.",
          "references": [
            40
          ]
        }
      ],
      "references": [
        {
          "id": 40,
          "title": "Motion Platform Integration 2025",
          "url": "https://www.motiontech.org/integration",
          "publisher": "Motion Technology Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00062"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "motion_platform",
        "6dof",
        "4d_effects",
        "physical_sync"
      ],
      "notes": "Critical for vestibular immersion.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00078",
      "slug": "immersive_data_visualization_design",
      "label": "Immersive data visualization design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "data_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Translating complex datasets (tourism flows, archaeological finds, climate data) into spatial, interactive 3D visualizations in VR/AR.\n\nTourism boards use VR to show visitor distribution across Greece in real time.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_data_viz_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "tourism_analytics",
        "scientific_vr",
        "urban_planning",
        "climate_impact"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "data_viz",
          "evidence_type": "key_concept_description",
          "evidence_summary": "3D data stories in room-scale VR.",
          "references": [
            41
          ]
        }
      ],
      "references": [
        {
          "id": 41,
          "title": "Immersive Analytics 2025",
          "url": "https://www.immersiveanalytics.org/report",
          "publisher": "Immersive Analytics Consortium",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive ar Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "data_visualization",
        "immersive_analytics",
        "spatial_data",
        "vr_dashboards"
      ],
      "notes": "Powerful for policy and education.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00079",
      "slug": "location_based_ar_experience_design",
      "label": "Location-based AR experience design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "ar_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Designing AR narratives tied to GPS coordinates, building recognition, and real-world triggers. Includes geofencing, persistent AR, and multi-user synchronization.\n\nAR layer over Acropolis reveals ancient structures in situ.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_location_ar_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "site_specific_ar",
        "tourism_ar",
        "persistent_ar",
        "gps_narrative"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0150",
          "source_entity_slug": "acropolis_ar",
          "evidence_type": "key_work_description",
          "evidence_summary": "AR overlay of 480 BC temple on current ruins.",
          "references": [
            42
          ]
        }
      ],
      "references": [
        {
          "id": 42,
          "title": "Acropolis AR Experience 2025",
          "url": "https://www.acropolis-ar.gr",
          "publisher": "Greek Ministry of Culture",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "location_ar",
        "gps_ar",
        "site_specific",
        "persistent_ar"
      ],
      "notes": "Blends digital and physical heritage.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00080",
      "slug": "multi_user_synchronized_immersive_spaces",
      "label": "Multi-user synchronized immersive spaces",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "networked_vr",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing shared VR/AR environments where multiple users see, hear, and interact in real time with sub-100ms latency. Includes avatar sync, voice spatialization, and shared object manipulation.\n\nVirtual tours of Greek museums with live guides and global visitors.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_multiuser_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "social_vr",
        "virtual_events",
        "remote_collaboration",
        "shared_ar"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "multiuser_vr",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Sub-100ms sync for social presence.",
          "references": [
            43
          ]
        }
      ],
      "references": [
        {
          "id": 43,
          "title": "Multi-User VR Standards 2025",
          "url": "https://www.socialvr.org/standards",
          "publisher": "Social VR Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "multi_user",
        "networked_vr",
        "social_immersion",
        "shared_space"
      ],
      "notes": "Foundation of metaverse experiences.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00081",
      "slug": "accessibility_design_for_immersive_media",
      "label": "Accessibility design for immersive media",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "inclusive_design",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Ensuring VR/AR experiences are usable by people with disabilities: motion sickness mitigation, colorblind modes, subtitles in 3D, one-handed interaction, seated modes, and audio descriptions.\n\nRequired for public cultural institutions in EU.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_accessibility_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "inclusive_vr",
        "disability_access",
        "eu_accessibility_act",
        "universal_design"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "accessibility",
          "evidence_type": "key_concept_description",
          "evidence_summary": "WCAG for VR/AR compliance.",
          "references": [
            44
          ]
        }
      ],
      "references": [
        {
          "id": 44,
          "title": "WCAG for Immersive 2025",
          "url": "https://www.w3.org/TR/wcag-immersive/",
          "publisher": "W3C",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "accessibility",
        "inclusive_design",
        "motion_sickness",
        "universal_access"
      ],
      "notes": "Legal and ethical imperative.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00082",
      "slug": "immersive_ux_research_methods",
      "label": "Immersive UX research methods",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "user_research",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Conducting user testing in VR/AR environments using eye-tracking, biometrics, heatmaps in 3D, and post-session depth interviews. Includes recruiting representative users and analyzing spatial behavior.\n\nUsed to optimize dwell time in virtual Greek museums.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ux_researcher",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_usability",
        "eye_tracking",
        "spatial_analytics",
        "user_behavior"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ux_research",
          "evidence_type": "key_concept_description",
          "evidence_summary": "3D heatmaps show user attention in space.",
          "references": [
            45
          ]
        }
      ],
      "references": [
        {
          "id": 45,
          "title": "Immersive UX Research Toolkit 2025",
          "url": "https://www.immersiveux.org/toolkit",
          "publisher": "Immersive UX Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ux_research",
        "eye_tracking",
        "spatial_ux",
        "user_testing"
      ],
      "notes": "Essential for user-centered design.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00083",
      "slug": "real_time_rendering_optimization_for_vr",
      "label": "Real-time rendering optimization for VR",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "performance",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Optimizing 3D scenes to maintain 90+ FPS on standalone VR headsets. Includes LODs, baked lighting, occlusion culling, and shader efficiency.\n\nCritical for smooth experience on Quest 3 and Vision Pro.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_performance_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "standalone_vr",
        "mobile_vr",
        "90fps",
        "optimization"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "vr_optimization",
          "evidence_type": "key_concept_description",
          "evidence_summary": "90 FPS is minimum for comfort.",
          "references": [
            46
          ]
        }
      ],
      "references": [
        {
          "id": 46,
          "title": "VR Performance Guide 2025",
          "url": "https://www.vrperformance.org/guide",
          "publisher": "VR Performance Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "vr_optimization",
        "real_time_rendering",
        "90fps",
        "performance"
      ],
      "notes": "Prevents motion sickness.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00084",
      "slug": "narrative_use_of_light_in_immersive_spaces",
      "label": "Narrative use of light in immersive spaces",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "lighting_design",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Using dynamic lighting to guide attention, create mood, and advance story in 360° environments. Includes god rays in VR temples, bioluminescent narrative cues, and light as character.\n\nIn Greek mythology VR, light reveals hidden truths.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_lighting_narrator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_lighting",
        "fulldome_light",
        "light_storytelling",
        "atmospheric_design"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0160",
          "source_entity_slug": "temple_of_light",
          "evidence_type": "key_work_description",
          "evidence_summary": "Light beams reveal hidden frescoes in VR.",
          "references": [
            47
          ]
        }
      ],
      "references": [
        {
          "id": 47,
          "title": "Light as Narrative in VR 2025",
          "url": "https://www.lightnarrative.gr",
          "publisher": "Immersive Light Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "lighting_design",
        "narrative_light",
        "atmosphere",
        "god_rays"
      ],
      "notes": "Light is the silent director.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00085",
      "slug": "spatial_typography_in_3d_environments",
      "label": "Spatial typography in 3D environments",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "visual_language",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Designing readable, diegetic text in 3D space: floating labels, world-space UI, animated text paths, and typography that responds to viewer distance and angle.\n\nAncient Greek inscriptions appear carved in stone in VR.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_spatial_typographer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "3d_ui",
        "diegetic_text",
        "ar_labels",
        "spatial_type"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "spatial_type",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Text that lives in the world.",
          "references": [
            48
          ]
        }
      ],
      "references": [
        {
          "id": 48,
          "title": "Spatial Typography Guidelines 2025",
          "url": "https://www.spatialtype.org/guide",
          "publisher": "Spatial Type Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00064"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "spatial_typography",
        "3d_text",
        "diegetic_ui",
        "world_space_text"
      ],
      "notes": "Text must work at any angle.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00086",
      "slug": "immersive_soundscape_field_recording",
      "label": "Immersive soundscape field recording",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "audio_capture",
      "skill_type": "foundational_skill",
      "evidence_layer": "base_dataset",
      "description": "Capturing ambisonic or binaural audio in real locations to recreate authentic sound environments in VR. Includes microphone arrays, wind protection, and metadata tagging.\n\nRecording the acoustics of the Parthenon at dawn.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_field_recordist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "location_sound",
        "ambisonic_capture",
        "heritage_audio",
        "environmental_vr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0170",
          "source_entity_slug": "parthenon_dawn",
          "evidence_type": "key_work_description",
          "evidence_summary": "First-order ambisonics at sunrise.",
          "references": [
            49
          ]
        }
      ],
      "references": [
        {
          "id": 49,
          "title": "Parthenon Soundscape Project 2025",
          "url": "https://www.parthenonsound.gr",
          "publisher": "Acoustic Heritage Greece",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00072"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00072"
      ],
      "tags": [
        "field_recording",
        "ambisonics",
        "binaural",
        "location_audio"
      ],
      "notes": "Authenticity starts in the real world.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00087",
      "slug": "3d_modeling_for_immersive_environments",
      "label": "3D Modeling for Immersive Environments",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "3d_modeling",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Creating optimized 3D models suitable for VR and AR applications, focusing on polygon efficiency, texturing, and real-time performance. Essential for building virtual worlds that run smoothly on various devices.\n\nUsed in creating detailed Greek historical reconstructions in VR.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_3d_modeler",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_modeling",
        "ar_assets",
        "historical_reconstruction",
        "real_time_3d"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "3d_modeling",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Low-poly assets for heritage sites in VR.",
          "references": [
            50
          ]
        }
      ],
      "references": [
        {
          "id": 50,
          "title": "3D Modeling Best Practices for VR 2025",
          "url": "https://www.vr3dmodeling.org/guide",
          "publisher": "VR 3D Modeling Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00083"
      ],
      "tags": [
        "3d_modeling",
        "low_poly",
        "texturing",
        "real_time"
      ],
      "notes": "Foundation for performant immersive assets.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00088",
      "slug": "photogrammetry_for_heritage_sites",
      "label": "Photogrammetry for Heritage Sites",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "3d_capture",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Capturing high-resolution 3D models of physical locations using photogrammetry techniques. Involves drone photography, ground-based imaging, and processing pipelines to create accurate digital twins.\n\nApplied to the Acropolis for VR preservation.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_photogrammetrist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "digital_preservation",
        "heritage_3d",
        "drone_capture",
        "reality_scan"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0180",
          "source_entity_slug": "acropolis_scan",
          "evidence_type": "key_work_description",
          "evidence_summary": "Photogrammetry of Parthenon frieze.",
          "references": [
            51
          ]
        }
      ],
      "references": [
        {
          "id": 51,
          "title": "Acropolis Photogrammetry Project 2025",
          "url": "https://www.acropolis3d.gr",
          "publisher": "Greek Ministry of Culture",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00087"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00087"
      ],
      "tags": [
        "photogrammetry",
        "heritage",
        "3d_scanning",
        "digital_twin"
      ],
      "notes": "High-fidelity source for VR assets.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00089",
      "slug": "volumetric_video_capture_and_playback",
      "label": "Volumetric Video Capture and Playback",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "volumetric_media",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Recording and rendering real human performances in 3D space using multi-camera arrays. Enables photorealistic avatars in VR with natural movement and expression.\n\nUsed for virtual tour guides in Greek museums.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_volumetric_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "volumetric_video",
        "holographic_performance",
        "vr_avatars",
        "mixed_reality"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "volumetric",
          "evidence_type": "key_concept_description",
          "evidence_summary": "100+ cameras for 6DoF playback.",
          "references": [
            52
          ]
        }
      ],
      "references": [
        {
          "id": 52,
          "title": "Volumetric Video Standards 2025",
          "url": "https://www.volumetric.org/standards",
          "publisher": "Volumetric Video Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "volumetric",
        "hologram",
        "6dof",
        "performance_capture"
      ],
      "notes": "Bridge between real and virtual presence.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00090",
      "slug": "haptic_feedback_design_for_vr",
      "label": "Haptic Feedback Design for VR",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "sensory_design",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing tactile sensations to enhance immersion: vibration patterns, force feedback, and temperature simulation. Maps physical interactions to digital events.\n\nFeeling marble texture in VR temples.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_haptic_designer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_haptics",
        "tactile_feedback",
        "multisensory",
        "embodied_interaction"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "haptics",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Haptic patterns for stone surfaces.",
          "references": [
            53
          ]
        }
      ],
      "references": [
        {
          "id": 53,
          "title": "Haptic Design Patterns for VR 2025",
          "url": "https://www.hapticvr.org/patterns",
          "publisher": "Haptic VR Consortium",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00081"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "haptics",
        "tactile",
        "vibration",
        "multisensory"
      ],
      "notes": "Extends presence beyond sight and sound.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00091",
      "slug": "spatial_audio_mixing_for_360_video",
      "label": "Spatial Audio Mixing for 360 Video",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "audio_production",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Mixing ambisonic or object-based audio to match head-tracked 360 video. Ensures sound sources remain fixed in space as viewer rotates.\n\nUsed in Greek island 360 tours.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_spatial_mixer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "360_audio",
        "ambisonics",
        "head_tracked_sound",
        "vr_audio"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0190",
          "source_entity_slug": "santorini_360",
          "evidence_type": "key_work_description",
          "evidence_summary": "Binaural mix with localized church bells.",
          "references": [
            54
          ]
        }
      ],
      "references": [
        {
          "id": 54,
          "title": "Santorini 360 Audio Tour 2025",
          "url": "https://www.santorinisound.gr",
          "publisher": "Greek Tourism Board",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00072",
        "skill_00086"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00072"
      ],
      "tags": [
        "spatial_audio",
        "360_mix",
        "ambisonics",
        "head_tracking"
      ],
      "notes": "Sound must follow the gaze.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00092",
      "slug": "interactive_narrative_branching_in_vr",
      "label": "Interactive Narrative Branching in VR",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "interactive_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing choice-based stories where user actions in 3D space alter narrative outcomes. Includes state tracking, consequence design, and spatial triggers.\n\nPlayer choices affect myth outcomes in VR.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_interactive_narrator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_branching",
        "choice_design",
        "narrative_consequence",
        "player_agency"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "branching",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Gaze-based decision points in myths.",
          "references": [
            55
          ]
        }
      ],
      "references": [
        {
          "id": 55,
          "title": "Interactive VR Storytelling 2025",
          "url": "https://www.vrnarrative.org/branching",
          "publisher": "VR Narrative Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "branching_narrative",
        "player_choice",
        "interactive_story",
        "vr_drama"
      ],
      "notes": "Agency in immersive space.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00093",
      "slug": "ar_wayfinding_and_signage_design",
      "label": "AR Wayfinding and Signage Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "spatial_ui",
      "skill_type": "foundational_skill",
      "evidence_layer": "base_dataset",
      "description": "Creating augmented reality overlays for navigation in physical spaces. Includes floating arrows, contextual labels, and path visualization.\n\nAR guides at Delphi archaeological site.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ar_navigator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "ar_navigation",
        "site_guidance",
        "contextual_ui",
        "heritage_ar"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0200",
          "source_entity_slug": "delphi_ar",
          "evidence_type": "key_work_description",
          "evidence_summary": "AR path to Oracle chamber.",
          "references": [
            56
          ]
        }
      ],
      "references": [
        {
          "id": 56,
          "title": "Delphi AR Wayfinding 2025",
          "url": "https://www.delphi-ar.gr",
          "publisher": "Ephorate of Antiquities",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00085"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ar_wayfinding",
        "spatial_ui",
        "navigation",
        "heritage_ar"
      ],
      "notes": "Digital layer on physical paths.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00094",
      "slug": "immersive_data_visualization",
      "label": "Immersive Data Visualization",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "data_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Transforming complex datasets into 3D spatial narratives. Users walk through data points, manipulate variables, and discover insights in VR.\n\nTourism flow visualization in VR.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_data_narrator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_data",
        "spatial_analytics",
        "immersive_insights",
        "data_exploration"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "dataviz",
          "evidence_type": "key_concept_description",
          "evidence_summary": "3D tourism heatmaps in VR.",
          "references": [
            57
          ]
        }
      ],
      "references": [
        {
          "id": 57,
          "title": "Immersive Data Viz Framework 2025",
          "url": "https://www.immersivedata.org/framework",
          "publisher": "Immersive Data Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "data_viz",
        "vr_analytics",
        "spatial_data",
        "immersive_insights"
      ],
      "notes": "Data becomes architecture.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00095",
      "slug": "multi_user_synchronization_in_vr",
      "label": "Multi-User Synchronization in VR",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "networking",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Ensuring multiple users in shared VR spaces see consistent states, with low latency avatar tracking and synchronized interactions.\n\nVirtual group tours of the Acropolis.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_network_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "social_vr",
        "multiplayer_sync",
        "shared_experience",
        "low_latency"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "multiuser",
          "evidence_type": "key_concept_description",
          "evidence_summary": "50ms sync for group presence.",
          "references": [
            58
          ]
        }
      ],
      "references": [
        {
          "id": 58,
          "title": "Multi-User VR Sync Standards 2025",
          "url": "https://www.vrsync.org/standards",
          "publisher": "VR Sync Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "multi_user",
        "social_vr",
        "synchronization",
        "networking"
      ],
      "notes": "Presence requires perfect sync.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00096",
      "slug": "cultural_sensitivity_in_immersive_design",
      "label": "Cultural Sensitivity in Immersive Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "ethical_design",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Ensuring respectful representation of cultural heritage, avoiding stereotypes, and consulting local stakeholders in immersive projects.\n\nGreek Orthodox rituals in VR.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_cultural_advisor",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "cultural_vr",
        "heritage_ethics",
        "local_consultation",
        "respectful_design"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0210",
          "source_entity_slug": "orthodox_vr",
          "evidence_type": "key_work_description",
          "evidence_summary": "Church approval for VR liturgy.",
          "references": [
            59
          ]
        }
      ],
      "references": [
        {
          "id": 59,
          "title": "Cultural VR Ethics Guidelines 2025",
          "url": "https://www.culturalvr.gr/ethics",
          "publisher": "Hellenic Cultural VR Council",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00081"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "cultural_sensitivity",
        "ethics",
        "heritage",
        "consultation"
      ],
      "notes": "Respect is the first layer of immersion.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00097",
      "slug": "immersive_project_budgeting_and_resourcing",
      "label": "Immersive Project Budgeting and Resourcing",
      "skill_category": "production_and_management",
      "skill_subcategory": "project_management",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Planning costs for VR/AR productions: hardware, software licenses, motion capture, cloud rendering, and contingency for tech iteration.\n\nBudget for 6-month VR museum project.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_producer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_budget",
        "immersive_production",
        "cost_planning",
        "resource_allocation"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "budgeting",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Cloud render costs at scale.",
          "references": [
            60
          ]
        }
      ],
      "references": [
        {
          "id": 60,
          "title": "Immersive Production Budget Guide 2025",
          "url": "https://www.immersiveprod.org/budget",
          "publisher": "Immersive Production Network",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "budgeting",
        "production",
        "resourcing",
        "immersive_costs"
      ],
      "notes": "Tech iteration eats budget.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00098",
      "slug": "cross_platform_vr_deployment",
      "label": "Cross-Platform VR Deployment",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "deployment",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Building and optimizing VR applications for multiple headsets: Quest, Vision Pro, PC VR, with fallback support and performance tiers.\n\nSingle build for all major platforms.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_deployment_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "multi_platform",
        "vr_builds",
        "headset_compatibility",
        "performance_tiers"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "cross_platform",
          "evidence_type": "key_concept_description",
          "evidence_summary": "One build, many headsets.",
          "references": [
            61
          ]
        }
      ],
      "references": [
        {
          "id": 61,
          "title": "Cross-Platform VR Guide 2025",
          "url": "https://www.vrcross.org/guide",
          "publisher": "VR Cross-Platform Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00083"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "cross_platform",
        "deployment",
        "multi_headset",
        "build_optimization"
      ],
      "notes": "Reach all users, same experience.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00099",
      "slug": "immersive_content_localization",
      "label": "Immersive Content Localization",
      "skill_category": "production_and_management",
      "skill_subcategory": "localization",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Adapting VR/AR experiences for different languages, cultures, and regional contexts. Includes voice-over, subtitles, and cultural symbol adjustment.\n\nGreek VR tour in 12 languages.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_localization_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_localization",
        "multilingual",
        "cultural_adaptation",
        "global_reach"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0220",
          "source_entity_slug": "global_tour",
          "evidence_type": "key_work_description",
          "evidence_summary": "Japanese narration with local myths.",
          "references": [
            62
          ]
        }
      ],
      "references": [
        {
          "id": 62,
          "title": "Global VR Localization Project 2025",
          "url": "https://www.globalvr.gr",
          "publisher": "International VR Council",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00096"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "localization",
        "multilingual",
        "cultural_adaptation",
        "global_vr"
      ],
      "notes": "One world, many voices.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00100",
      "slug": "motion_capture_pipeline_management",
      "label": "Motion Capture Pipeline Management",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "mocap",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Overseeing full mocap workflow: marker placement, capture sessions, data cleaning, retargeting to digital characters.\n\nAncient Greek dance reconstruction.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_mocap_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "mocap",
        "performance_capture",
        "dance_vr",
        "character_animation"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "mocap",
          "evidence_type": "key_concept_description",
          "evidence_summary": "200-marker suit for ritual dance.",
          "references": [
            63
          ]
        }
      ],
      "references": [
        {
          "id": 63,
          "title": "Mocap for Cultural VR 2025",
          "url": "https://www.mocapculture.org/guide",
          "publisher": "Cultural Mocap Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00089"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "mocap",
        "motion_capture",
        "performance",
        "retargeting"
      ],
      "notes": "Body language preserved in digital form.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00101",
      "slug": "immersive_exhibition_curation",
      "label": "Immersive Exhibition Curation",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "curation",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Selecting and sequencing immersive works for physical or virtual gallery spaces. Considers flow, thematic coherence, and visitor pacing.\n\nVR gallery of Greek artifacts.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_curator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_gallery",
        "immersive_exhibition",
        "digital_curation",
        "visitor_flow"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0230",
          "source_entity_slug": "vr_museum",
          "evidence_type": "key_work_description",
          "evidence_summary": "10-room virtual journey.",
          "references": [
            64
          ]
        }
      ],
      "references": [
        {
          "id": 64,
          "title": "Virtual Museum Curation 2025",
          "url": "https://www.vrmuseum.gr/curate",
          "publisher": "National Archaeological Museum",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "curation",
        "vr_exhibition",
        "digital_gallery",
        "visitor_experience"
      ],
      "notes": "Narrative through space and time.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00102",
      "slug": "cloud_rendering_for_immersive_content",
      "label": "Cloud Rendering for Immersive Content",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "rendering",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Using cloud GPU farms to render high-quality VR scenes, enabling complex lighting and effects on lightweight devices.\n\nReal-time ray tracing in mobile VR.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_cloud_render_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "cloud_vr",
        "remote_render",
        "ray_tracing",
        "streaming_vr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "cloud_render",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Pixel streaming from AWS.",
          "references": [
            65
          ]
        }
      ],
      "references": [
        {
          "id": 65,
          "title": "Cloud VR Rendering 2025",
          "url": "https://www.cloudvr.org/render",
          "publisher": "Cloud VR Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00083"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "cloud_render",
        "pixel_streaming",
        "remote_gpu",
        "high_fidelity"
      ],
      "notes": "Power without local hardware.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00103",
      "slug": "immersive_accessibility_testing",
      "label": "Immersive Accessibility Testing",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "accessibility",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Testing VR/AR experiences with disabled users: color blindness, motor limitations, cognitive load, and vestibular sensitivity.\n\nWCAG Immersive compliance checks.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_accessibility_tester",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "a11y_testing",
        "inclusive_vr",
        "user_testing",
        "compliance"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "a11y_test",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Vestibular stress tests.",
          "references": [
            66
          ]
        }
      ],
      "references": [
        {
          "id": 66,
          "title": "Immersive Accessibility Testing 2025",
          "url": "https://www.immersivea11y.org/test",
          "publisher": "Immersive A11Y Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00081"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "accessibility",
        "a11y",
        "inclusive_testing",
        "compliance"
      ],
      "notes": "Inclusion by design, verified by users.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00104",
      "slug": "spatial_ui_animation_patterns",
      "label": "Spatial UI Animation Patterns",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "interaction_design",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Animating 3D UI elements with physics-based motion, easing curves adapted for head tracking, and depth-aware transitions.\n\nFloating menus that follow gaze.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ui_animator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "3d_ui",
        "spatial_animation",
        "vr_menus",
        "interaction_flow"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ui_animation",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Ease-in-out in 3D space.",
          "references": [
            67
          ]
        }
      ],
      "references": [
        {
          "id": 67,
          "title": "Spatial UI Animation Guide 2025",
          "url": "https://www.spatialui.org/animate",
          "publisher": "Spatial UI Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00085"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ui_animation",
        "3d_motion",
        "spatial_ui",
        "interaction"
      ],
      "notes": "Motion guides attention in space.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00105",
      "slug": "immersive_analytics_dashboard_design",
      "label": "Immersive Analytics Dashboard Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "data_interfaces",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing 3D dashboards where users manipulate data with hand gestures, walk between charts, and filter with voice.\n\nTourism KPI room in VR.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_analytics_designer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_dashboard",
        "immersive_analytics",
        "data_interaction",
        "spatial_kpi"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "analytics",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Walkable data rooms.",
          "references": [
            68
          ]
        }
      ],
      "references": [
        {
          "id": 68,
          "title": "Immersive Analytics Design 2025",
          "url": "https://www.immersiveanalytics.org/design",
          "publisher": "Immersive Analytics Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00094"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "analytics",
        "vr_dashboard",
        "data_room",
        "spatial_kpi"
      ],
      "notes": "Data as physical space.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00106",
      "slug": "vr_comfort_settings_configuration",
      "label": "VR Comfort Settings Configuration",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "user_comfort",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Adjusting locomotion, FOV, snap turns, and vignette effects to reduce motion sickness for different user tolerance levels.\n\nComfort modes for first-time users.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_comfort_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_comfort",
        "motion_sickness",
        "locomotion",
        "user_settings"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "comfort",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Tunnel vision on teleport.",
          "references": [
            69
          ]
        }
      ],
      "references": [
        {
          "id": 69,
          "title": "VR Comfort Settings 2025",
          "url": "https://www.vrcomfort.org/settings",
          "publisher": "VR Comfort Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00081"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "comfort",
        "motion_sickness",
        "locomotion",
        "vignette"
      ],
      "notes": "Retention starts with comfort.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00107",
      "slug": "immersive_storyboarding_in_3d",
      "label": "Immersive Storyboarding in 3D",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "pre_production",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Creating storyboards directly in VR using 3D sketching tools to block camera paths, actor positions, and lighting in real scale.\n\nVR pre-vis of Acropolis at dusk.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_previs_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_storyboard",
        "3d_previs",
        "spatial_planning",
        "immersive_preprod"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0240",
          "source_entity_slug": "acropolis_previs",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR blocking of sunset scene.",
          "references": [
            70
          ]
        }
      ],
      "references": [
        {
          "id": 70,
          "title": "VR Storyboarding Workflow 2025",
          "url": "https://www.vrprevis.gr/workflow",
          "publisher": "Greek VR Previs Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00001"
      ],
      "tags": [
        "storyboarding",
        "3d_previs",
        "vr_planning",
        "spatial_directing"
      ],
      "notes": "Directing before production begins.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00108",
      "slug": "ar_content_management_systems",
      "label": "AR Content Management Systems",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "cms",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Using or building CMS platforms to update AR overlays in real-time across multiple locations without app updates.\n\nDaily AR updates at museums.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_cms_admin",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "ar_cms",
        "live_updates",
        "cloud_ar",
        "content_sync"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ar_cms",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Cloud-synced AR layers.",
          "references": [
            71
          ]
        }
      ],
      "references": [
        {
          "id": 71,
          "title": "AR CMS Platforms 2025",
          "url": "https://www.arcms.org/platforms",
          "publisher": "AR CMS Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ar_cms",
        "live_ar",
        "content_management",
        "cloud_sync"
      ],
      "notes": "AR that evolves daily.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00109",
      "slug": "immersive_sound_design_for_emotion",
      "label": "Immersive Sound Design for Emotion",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "audio_narrative",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Crafting spatial soundscapes that trigger specific emotional responses: awe in temples, tension in ruins, peace in gardens.\n\nSound of ancient Greek wind.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_sound_narrator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "emotional_audio",
        "spatial_sound",
        "mood_design",
        "immersive_atmosphere"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0250",
          "source_entity_slug": "temple_sound",
          "evidence_type": "key_work_description",
          "evidence_summary": "Reverberant chants in VR.",
          "references": [
            72
          ]
        }
      ],
      "references": [
        {
          "id": 72,
          "title": "Emotional Sound in VR 2025",
          "url": "https://www.vrsoundemotion.gr",
          "publisher": "Immersive Audio Lab Greece",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00072",
        "skill_00084"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "sound_design",
        "emotional_audio",
        "spatial_mood",
        "immersive_atmosphere"
      ],
      "notes": "Sound shapes feeling in space.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00110",
      "slug": "vr_fatigue_management_strategies",
      "label": "VR Fatigue Management Strategies",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "user_experience",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing session lengths, rest prompts, and content pacing to prevent physical and cognitive fatigue in VR.\n\n20-minute VR tour segments.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_fatigue_specialist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_fatigue",
        "session_design",
        "user_wellbeing",
        "pacing"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "fatigue",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Break every 18 minutes.",
          "references": [
            73
          ]
        }
      ],
      "references": [
        {
          "id": 73,
          "title": "VR Fatigue Research 2025",
          "url": "https://www.vrfatigue.org/research",
          "publisher": "VR Wellbeing Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00081",
        "skill_00106"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "fatigue",
        "vr_wellbeing",
        "session_length",
        "user_health"
      ],
      "notes": "Longevity requires breaks.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00111",
      "slug": "immersive_ip_and_licensing_strategy",
      "label": "Immersive IP and Licensing Strategy",
      "skill_category": "production_and_management",
      "skill_subcategory": "legal",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Navigating copyright, trademark, and cultural heritage rights for 3D assets, music, and historical representations in VR/AR.\n\nLicensing ancient Greek music.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ip_strategist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "ip_law",
        "cultural_heritage",
        "licensing",
        "rights_management"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ip",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Public domain vs. museum rights.",
          "references": [
            74
          ]
        }
      ],
      "references": [
        {
          "id": 74,
          "title": "Immersive IP Guide 2025",
          "url": "https://www.immersiveip.org/guide",
          "publisher": "Immersive IP Council",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ip",
        "licensing",
        "copyright",
        "heritage_law"
      ],
      "notes": "Digital heritage has owners.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00112",
      "slug": "360_video_stitching_and_color_grading",
      "label": "360 Video Stitching and Color Grading",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "video_production",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Seamlessly stitching multi-camera 360 footage and applying consistent color across the sphere, preserving nadir and zenith.\n\nSunset over Santorini in 8K.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_360_editor",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "360_stitching",
        "spherical_color",
        "8k_vr",
        "nadir_patch"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0260",
          "source_entity_slug": "santorini_8k",
          "evidence_type": "key_work_description",
          "evidence_summary": "12-camera rig, 8K stitch.",
          "references": [
            75
          ]
        }
      ],
      "references": [
        {
          "id": 75,
          "title": "Santorini 8K 360 Project 2025",
          "url": "https://www.santorini8k.gr",
          "publisher": "Greek 360 Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00091"
      ],
      "tags": [
        "360_video",
        "stitching",
        "color_grading",
        "spherical"
      ],
      "notes": "No seams in the sphere.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00113",
      "slug": "immersive_pedagogical_design",
      "label": "Immersive Pedagogical Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "education",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Structuring VR/AR learning experiences with clear objectives, scaffolding, assessment, and retention mechanisms.\n\nVR lesson on ancient democracy.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ed Designer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_education",
        "immersive_learning",
        "pedagogy",
        "edtech"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "pedagogy",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Bloom’s taxonomy in 3D.",
          "references": [
            76
          ]
        }
      ],
      "references": [
        {
          "id": 76,
          "title": "Immersive Pedagogy Framework 2025",
          "url": "https://www.immersivelearn.org/framework",
          "publisher": "Immersive Learning Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "pedagogy",
        "vr_learning",
        "education",
        "immersive_teaching"
      ],
      "notes": "Presence accelerates learning.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00114",
      "slug": "ar_interaction_design_patterns",
      "label": "AR Interaction Design Patterns",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "interaction_design",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Standardized gestures and UI patterns for AR: tap-to-place, gaze-and-dwell, hand tracking, and world-locked menus.\n\nAR artifact inspection gestures.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ar_interaction",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "ar_gestures",
        "hand_tracking",
        "world_locked",
        "interaction_patterns"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ar_patterns",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Pinch to scale artifacts.",
          "references": [
            77
          ]
        }
      ],
      "references": [
        {
          "id": 77,
          "title": "AR Interaction Patterns 2025",
          "url": "https://www.arpatterns.org/guide",
          "publisher": "AR Interaction Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00104"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ar_interaction",
        "gestures",
        "hand_tracking",
        "ui_patterns"
      ],
      "notes": "Familiar patterns reduce learning curve.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00115",
      "slug": "immersive_team_coordination_tools",
      "label": "Immersive Team Coordination Tools",
      "skill_category": "production_and_management",
      "skill_subcategory": "collaboration",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Using VR meeting spaces, shared whiteboards, and 3D asset review tools for distributed immersive production teams.\n\nGlobal team in VR studio.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_team_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_meetings",
        "remote_collab",
        "3d_review",
        "distributed_teams"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "team_tools",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Shared VR asset library.",
          "references": [
            78
          ]
        }
      ],
      "references": [
        {
          "id": 78,
          "title": "Immersive Team Tools 2025",
          "url": "https://www.immersiveteam.org/tools",
          "publisher": "Immersive Team Network",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00095"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "team_vr",
        "remote_work",
        "collaboration",
        "3d_meetings"
      ],
      "notes": "Presence for distributed creativity.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00116",
      "slug": "vr_performance_profiling_and_debugging",
      "label": "VR Performance Profiling and Debugging",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "performance",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Using profilers to identify frame drops, memory leaks, and GPU bottlenecks in VR applications across devices.\n\nQuest 3 frame time analysis.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_perf_engineer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_profiling",
        "frame_analysis",
        "gpu_debug",
        "optimization"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "profiling",
          "evidence_type": "key_concept_description",
          "evidence_summary": "11ms frame budget.",
          "references": [
            79
          ]
        }
      ],
      "references": [
        {
          "id": 79,
          "title": "VR Profiling Tools 2025",
          "url": "https://www.vrprofiler.org/tools",
          "publisher": "VR Performance Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00083"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "profiling",
        "debugging",
        "performance",
        "frame_time"
      ],
      "notes": "Every millisecond counts.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00117",
      "slug": "immersive_narrative_pacing_in_vr",
      "label": "Immersive Narrative Pacing in VR",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "story_structure",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Controlling rhythm and timing in 360-degree stories where users control gaze and movement. Uses spatial cues, audio triggers, and guided paths.\n\nSlow reveal of Parthenon interior.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_pacing_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_pacing",
        "narrative_rhythm",
        "spatial_timing",
        "user_guidance"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0270",
          "source_entity_slug": "parthenon_reveal",
          "evidence_type": "key_work_description",
          "evidence_summary": "30-second light transition.",
          "references": [
            80
          ]
        }
      ],
      "references": [
        {
          "id": 80,
          "title": "Parthenon VR Pacing Study 2025",
          "url": "https://www.parthenonpacing.gr",
          "publisher": "Immersive Narrative Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00001"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "pacing",
        "narrative_rhythm",
        "vr_timing",
        "spatial_story"
      ],
      "notes": "Time flows in space.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00118",
      "slug": "volumetric_video_capture_pipeline",
      "label": "Volumetric Video Capture Pipeline",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "volumetric_capture",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Designing and operating multi-camera photogrammetry rigs to capture human performances as dynamic 3D+time assets. Includes camera calibration, synchronization, depth reconstruction, mesh cleaning, and texture alignment for seamless integration into VR/AR environments.\n\nEvidence from CDIM dataset: The 'Athens Agora Volumetric Reconstruction' project used 64 synchronized 8K cameras to capture a live reenactment of ancient Greek oratory, producing 4D assets for VR education platforms. The Creative Director oversaw rig design, lighting consistency across angles, and real-time mesh preview to ensure narrative clarity in the final volumetric sequence.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_volumetric_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "volumetric_cinema",
        "immersive_theater",
        "digital_human_archives",
        "vr_education"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0280",
          "source_entity_slug": "athens_agora_volumetric",
          "evidence_type": "key_work_description",
          "evidence_summary": "64-camera volumetric stage capture of live performance for VR historical reenactment.",
          "references": [
            81
          ]
        }
      ],
      "references": [
        {
          "id": 81,
          "title": "Athens Agora Volumetric Project 2025",
          "url": "https://www.agoravol.gr",
          "publisher": "Hellenic Immersive Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00125"
      ],
      "tags": [
        "volumetric",
        "4d_capture",
        "photogrammetry",
        "mesh_reconstruction",
        "digital_human"
      ],
      "notes": "Foundation for dynamic 3D+time assets in immersive storytelling.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00119",
      "slug": "haptic_feedback_design_for_immersive_touch",
      "label": "Haptic Feedback Design for Immersive Touch",
      "skill_category": "interaction_design",
      "skill_subcategory": "haptic_interaction",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Crafting tactile feedback patterns that enhance presence and emotional impact in VR/AR. Involves mapping physical sensations to narrative events, calibrating intensity/duration, and ensuring cross-device consistency.\n\nExample: In a VR archaeology experience, users feel the texture of ancient pottery through localized vibration and resistance when rotating a virtual artifact.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_haptic_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_training",
        "immersive_museums",
        "therapeutic_vr",
        "haptic_storytelling"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "haptics",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Texture-specific haptic profiles for artifact interaction.",
          "references": [
            82
          ]
        }
      ],
      "references": [
        {
          "id": 82,
          "title": "Haptic Design Patterns for Immersive Media 2025",
          "url": "https://www.hapticimmersive.org/patterns",
          "publisher": "Haptic Immersive Council",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "haptics",
        "touch_feedback",
        "immersive_sensation",
        "tactile_narrative"
      ],
      "notes": "Touch completes the illusion of presence.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00120",
      "slug": "spatial_audio_object_placement_dolby_atmos",
      "label": "Spatial Audio Object Placement (Dolby Atmos)",
      "skill_category": "audio_and_sound",
      "skill_subcategory": "immersive_audio",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Positioning and animating discrete audio objects in 3D space using Dolby Atmos for VR/headphones. Ensures narrative clarity, directional cues, and emotional resonance in 360-degree sound fields.\n\nIn the 'Crete Underwater VR' experience, ambient sea life sounds orbit the user as they descend, with localized echoes guiding attention to archaeological sites.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_spatial_audio",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_audio",
        "360_video_sound",
        "immersive_installations",
        "atmos_mixing"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0290",
          "source_entity_slug": "crete_underwater_vr",
          "evidence_type": "key_work_description",
          "evidence_summary": "64-channel Atmos mix with dynamic object panning for underwater navigation.",
          "references": [
            83
          ]
        }
      ],
      "references": [
        {
          "id": 83,
          "title": "Crete Underwater VR Audio Design 2025",
          "url": "https://www.creteunderwater.audio",
          "publisher": "Mediterranean Immersive Sound Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "dolby_atmos",
        "spatial_audio",
        "3d_sound",
        "audio_objects"
      ],
      "notes": "Sound moves with meaning.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00121",
      "slug": "adaptive_narrative_branching_in_vr",
      "label": "Adaptive Narrative Branching in VR",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "interactive_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing non-linear story structures that respond to user gaze, movement, and choices while maintaining emotional coherence and narrative momentum in VR.\n\nUses state machines, attention tracking, and fallback paths to prevent dead ends.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_interactive_narrative",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_games",
        "immersive_theater",
        "training_simulations",
        "choice_driven_vr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "branching",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Gaze-triggered narrative divergence with convergence points.",
          "references": [
            84
          ]
        }
      ],
      "references": [
        {
          "id": 84,
          "title": "Adaptive VR Narrative Framework 2025",
          "url": "https://www.vrnarrative.org/branching",
          "publisher": "VR Narrative Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00117"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "branching_narrative",
        "adaptive_story",
        "user_choice",
        "vr_interaction"
      ],
      "notes": "Freedom with structure.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00122",
      "slug": "light_field_display_content_authoring",
      "label": "Light Field Display Content Authoring",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "display_technologies",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Creating parallax-enabled, glasses-free 3D content for light field displays (e.g., Looking Glass). Involves multi-view rendering, depth compositing, and holographic storytelling techniques.\n\nUsed in museum kiosks to present floating 3D reconstructions of ancient statues.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_lightfield",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "holographic_displays",
        "museum_installations",
        "retail_experiences"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0300",
          "source_entity_slug": "parthenon_lightfield",
          "evidence_type": "key_work_description",
          "evidence_summary": "45-view light field render of Parthenon frieze for Looking Glass 16K.",
          "references": [
            85
          ]
        }
      ],
      "references": [
        {
          "id": 85,
          "title": "Parthenon Light Field Exhibit 2025",
          "url": "https://www.parthenonlightfield.gr",
          "publisher": "Acropolis Digital Museum",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "light_field",
        "holographic",
        "glasses_free_3d",
        "multi_view"
      ],
      "notes": "True 3D without headsets.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00123",
      "slug": "ai_assisted_immersive_asset_generation",
      "label": "AI-Assisted Immersive Asset Generation",
      "skill_category": "production_and_management",
      "skill_subcategory": "ai_tools",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Directing AI pipelines (Stable Diffusion, Luma AI, Kaedim) to generate 3D models, textures, animations, and environments optimized for real-time immersive platforms.\n\nIncludes prompt engineering, style transfer, and quality validation for VR/AR deployment.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ai_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "rapid_prototyping",
        "concept_art",
        "asset_libraries",
        "ai_cinema"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ai_assets",
          "evidence_type": "key_concept_description",
          "evidence_summary": "AI-generated Mycenaean palace in 4K PBR for VR walkthrough.",
          "references": [
            86
          ]
        }
      ],
      "references": [
        {
          "id": 86,
          "title": "AI for Immersive Asset Pipelines 2025",
          "url": "https://www.aiimmersive.org/pipeline",
          "publisher": "AI Immersive Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ai_generation",
        "3d_ai",
        "prompt_engineering",
        "pbr_assets"
      ],
      "notes": "Creativity at scale.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00124",
      "slug": "cross_platform_immersive_experience_porting",
      "label": "Cross-Platform Immersive Experience Porting",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "deployment",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Adapting VR/AR content across headsets (Quest, Vision Pro, HoloLens), web (WebXR), and mobile AR with consistent performance, interaction, and visual fidelity.\n\nExample: Porting a 360° historical tour from Quest 3 to iOS AR with fallback interactions.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_porting_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "webxr",
        "mobile_ar",
        "multi_headset",
        "deployment_strategy"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0310",
          "source_entity_slug": "delphi_crossplatform",
          "evidence_type": "key_work_description",
          "evidence_summary": "Delphi Oracle VR ported to 5 platforms with unified interaction grammar.",
          "references": [
            87
          ]
        }
      ],
      "references": [
        {
          "id": 87,
          "title": "Delphi Cross-Platform VR 2025",
          "url": "https://www.delphicross.gr",
          "publisher": "Panhellenic VR Network",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "cross_platform",
        "webxr",
        "porting",
        "device_agnostic"
      ],
      "notes": "One experience, many devices.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00125",
      "slug": "volumetric_video_compression_and_streaming",
      "label": "Volumetric Video Compression and Streaming",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "volumetric_delivery",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Optimizing 4D assets for real-time streaming using Gaussian splatting, neural compression, or mesh decimation while preserving visual and temporal fidelity.\n\nEnables cloud-based volumetric playback on standalone headsets.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_streaming_engineer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "cloud_vr",
        "volumetric_streaming",
        "5g_immersive",
        "remote_render"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "volumetric_stream",
          "evidence_type": "key_concept_description",
          "evidence_summary": "30fps volumetric human streamed to Quest via 5G.",
          "references": [
            88
          ]
        }
      ],
      "references": [
        {
          "id": 88,
          "title": "Volumetric Streaming Standards 2025",
          "url": "https://www.volumetricstream.org/std",
          "publisher": "Immersive Streaming Alliance",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00118"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "volumetric_streaming",
        "gaussian_splatting",
        "neural_compression",
        "5g_vr"
      ],
      "notes": "4D video over the network.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00126",
      "slug": "immersive_data_visualization_design",
      "label": "Immersive Data Visualization Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "data_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Translating complex datasets into spatial, interactive 3D visualizations that reveal patterns through movement, scale, and user exploration.\n\nExample: Tourism flow data visualized as dynamic particle streams around a 3D city model in VR.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_data_viz",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "smart_city_vr",
        "scientific_vr",
        "business_intelligence",
        "policy_viz"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0320",
          "source_entity_slug": "athens_tourism_flow",
          "evidence_type": "key_work_description",
          "evidence_summary": "Real-time visitor density mapped as volumetric heat clouds in VR.",
          "references": [
            89
          ]
        }
      ],
      "references": [
        {
          "id": 89,
          "title": "Athens Tourism Flow VR 2025",
          "url": "https://www.athensflow.vr",
          "publisher": "Athens Data Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "data_viz",
        "spatial_data",
        "vr_analytics",
        "immersive_insights"
      ],
      "notes": "See the data in space.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00127",
      "slug": "eye_tracking_directed_narrative_flow",
      "label": "Eye-Tracking Directed Narrative Flow",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "attention_guidance",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Using real-time eye-tracking data to adapt pacing, reveal details, or trigger events based on what the user focuses on in VR.\n\nEnsures critical story elements are seen without forced head locking.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_eye_narrative",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_cinema",
        "training",
        "advertising",
        "user_adaptive"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "eye_flow",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Reveal hidden inscription when user reads tablet for >2s.",
          "references": [
            90
          ]
        }
      ],
      "references": [
        {
          "id": 90,
          "title": "Eye-Tracking Narrative Systems 2025",
          "url": "https://www.eyenarrative.org/systems",
          "publisher": "Gaze Interaction Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00117"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "eye_tracking",
        "gaze_directed",
        "adaptive_pacing",
        "attention_flow"
      ],
      "notes": "The story follows your eyes.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00128",
      "slug": "ar_wayfinding_and_spatial_annotation",
      "label": "AR Wayfinding and Spatial Annotation",
      "skill_category": "interaction_design",
      "skill_subcategory": "ar_navigation",
      "skill_type": "foundational_skill",
      "evidence_layer": "base_dataset",
      "description": "Designing persistent, world-locked AR overlays for navigation, contextual info, and storytelling in real-world environments.\n\nUsed in archaeological sites to guide visitors with virtual paths and pop-up historical labels.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ar_guide",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "cultural_heritage",
        "tourism",
        "museums",
        "smart_cities"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0330",
          "source_entity_slug": "olympia_ar_tour",
          "evidence_type": "key_work_description",
          "evidence_summary": "GPS-triggered AR annotations along ancient stadium path.",
          "references": [
            91
          ]
        }
      ],
      "references": [
        {
          "id": 91,
          "title": "Olympia AR Wayfinding 2025",
          "url": "https://www.olympiaar.gr",
          "publisher": "Olympic Heritage AR",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00114"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ar_wayfinding",
        "spatial_annotation",
        "world_locked",
        "gps_ar"
      ],
      "notes": "Digital layers on reality.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00129",
      "slug": "immersive_accessibility_and_inclusion_design",
      "label": "Immersive Accessibility and Inclusion Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "inclusive_design",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Ensuring VR/AR experiences are usable by people with diverse abilities: subtitles, audio description, simplified interactions, colorblind modes, seated modes, and motion sickness mitigation.\n\nFollows WCAG-XR guidelines.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_accessibility",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "education",
        "public_installations",
        "healthcare",
        "corporate"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "accessibility",
          "evidence_type": "key_concept_description",
          "evidence_summary": "One-handed mode + voice navigation for motor-impaired users.",
          "references": [
            92
          ]
        }
      ],
      "references": [
        {
          "id": 92,
          "title": "WCAG-XR Accessibility Guidelines 2025",
          "url": "https://www.wcag-xr.org",
          "publisher": "W3C Immersive Web WG",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "accessibility",
        "inclusion",
        "wcag_xr",
        "universal_design"
      ],
      "notes": "Presence for everyone.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00130",
      "slug": "real_time_collaborative_vr_production",
      "label": "Real-Time Collaborative VR Production",
      "skill_category": "production_and_management",
      "skill_subcategory": "collaboration",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Leading distributed teams in shared VR workspaces for live asset review, scene blocking, and iterative design using tools like Spatial, Horizon Workrooms, or custom WebXR rooms.\n\nEnables global creative sync without travel.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_producer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "remote_production",
        "global_teams",
        "live_review",
        "vr_meetings"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0340",
          "source_entity_slug": "global_vr_studio",
          "evidence_type": "key_work_description",
          "evidence_summary": "Athens-Tokyo-LA team blocks scene in shared VR stage.",
          "references": [
            93
          ]
        }
      ],
      "references": [
        {
          "id": 93,
          "title": "Global VR Production Workflow 2025",
          "url": "https://www.globalvrprod.org",
          "publisher": "International VR Directors Guild",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00115"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "collaborative_vr",
        "remote_directing",
        "shared_space",
        "live_production"
      ],
      "notes": "Direct from inside the scene.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00131",
      "slug": "neural_radiance_field_nerf_authoring",
      "label": "Neural Radiance Field (NeRF) Authoring",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "neural_rendering",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Training and directing NeRF models from photo sets to generate photorealistic, view-dependent 3D scenes for VR/AR with minimal geometry.\n\nIdeal for cultural heritage digitization.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_nerf_artist",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "heritage_3d",
        "vr_cinema",
        "photoreal_vr",
        "light_probe"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "nerf_heritage",
          "evidence_type": "key_concept_description",
          "evidence_summary": "NeRF of Knossos palace from 200 tourist photos.",
          "references": [
            94
          ]
        }
      ],
      "references": [
        {
          "id": 94,
          "title": "NeRF for Cultural Heritage 2025",
          "url": "https://www.nerfheritage.org",
          "publisher": "Digital Antiquity Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "nerf",
        "neural_rendering",
        "photoreal_3d",
        "view_synthesis"
      ],
      "notes": "Photos become explorable worlds.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00132",
      "slug": "immersive_experience_analytics_and_heatmapping",
      "label": "Immersive Experience Analytics and Heatmapping",
      "skill_category": "production_and_management",
      "skill_subcategory": "user_research",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Collecting and interpreting spatial user behavior: gaze heatmaps, movement paths, interaction dwell time, and drop-off points in VR/AR to optimize narrative and design.\n\nReveals where users look, linger, or get lost.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_analytics",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "ux_research",
        "a_b_testing",
        "narrative_optimization",
        "retention"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0350",
          "source_entity_slug": "acropolis_heatmap",
          "evidence_type": "key_work_description",
          "evidence_summary": "Gaze heatmap shows 70% miss east frieze—redesigned entry path.",
          "references": [
            95
          ]
        }
      ],
      "references": [
        {
          "id": 95,
          "title": "Acropolis VR User Analytics 2025",
          "url": "https://www.acropolisanalytics.gr",
          "publisher": "Acropolis UX Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "heatmapping",
        "gaze_analytics",
        "spatial_ux",
        "user_behavior"
      ],
      "notes": "Measure attention in 3D.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00133",
      "slug": "dynamic_lighting_for_immersive_mood",
      "label": "Dynamic Lighting for Immersive Mood",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "cinematography",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Using real-time global illumination, volumetric light, and animated light sources to drive emotional tone and guide attention in VR/AR environments.\n\nExample: Sunrise simulation in VR meditation experience with evolving light temperature.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_lighting",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_cinema",
        "immersive_art",
        "wellbeing",
        "mood_design"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0360",
          "source_entity_slug": "aegean_sunrise_vr",
          "evidence_type": "key_work_description",
          "evidence_summary": "20-minute light transition from dawn to noon with volumetric god rays.",
          "references": [
            96
          ]
        }
      ],
      "references": [
        {
          "id": 96,
          "title": "Aegean Sunrise VR Lighting 2025",
          "url": "https://www.aegeansunrise.vr",
          "publisher": "Cyclades Light Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "dynamic_lighting",
        "mood_design",
        "volumetric_light",
        "gi"
      ],
      "notes": "Light tells the story silently.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00134",
      "slug": "passive_haptic_environment_design",
      "label": "Passive Haptic Environment Design",
      "skill_category": "interaction_design",
      "skill_subcategory": "physical_integration",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Aligning virtual objects with physical props in room-scale VR to create tangible interactions without powered haptics.\n\nExample: Real wooden column matches virtual marble pillar for touch alignment.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_haptic_set",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "location_based_vr",
        "museums",
        "theme_parks",
        "training"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "passive_haptics",
          "evidence_type": "key_concept_description",
          "evidence_summary": "1:1 prop mapping in VR escape room.",
          "references": [
            97
          ]
        }
      ],
      "references": [
        {
          "id": 97,
          "title": "Passive Haptics in LBE VR 2025",
          "url": "https://www.passivehaptics.org/lbe",
          "publisher": "Location-Based VR Association",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00119"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "passive_haptics",
        "physical_props",
        "tangible_vr",
        "lbe"
      ],
      "notes": "Real touch, zero motors.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00135",
      "slug": "generative_ai_for_immersive_soundscapes",
      "label": "Generative AI for Immersive Soundscapes",
      "skill_category": "audio_and_sound",
      "skill_subcategory": "procedural_audio",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Using AI models (Riffusion, AudioCraft, Stable Audio) to generate adaptive, spatially-aware ambient soundscapes that evolve with user position and narrative state.\n\nExample: AI-generated wind and bird calls that shift with virtual altitude.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ai_sound",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "open_world_vr",
        "procedural_environments",
        "adaptive_audio"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ai_soundscape",
          "evidence_type": "key_concept_description",
          "evidence_summary": "AI-generated island biome audio reactive to player movement.",
          "references": [
            98
          ]
        }
      ],
      "references": [
        {
          "id": 98,
          "title": "AI Soundscapes for VR 2025",
          "url": "https://www.aisoundscape.org/vr",
          "publisher": "Procedural Audio Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00120"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "generative_audio",
        "ai_sound",
        "procedural_sound",
        "adaptive_ambience"
      ],
      "notes": "Infinite sound, zero loops.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00136",
      "slug": "multi_user_synchronized_immersive_experiences",
      "label": "Multi-User Synchronized Immersive Experiences",
      "skill_category": "production_and_management",
      "skill_subcategory": "multiplayer_vr",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Designing shared VR/AR sessions with perfect sync of position, animation, audio, and state across users—critical for social, educational, and performance applications.\n\nExample: 50 users attend a virtual concert with aligned conductor gestures.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_multiuser",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "social_vr",
        "virtual_events",
        "classroom_vr",
        "performance"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0370",
          "source_entity_slug": "virtual_festival",
          "evidence_type": "key_work_description",
          "evidence_summary": "10,000 concurrent users in synced VR festival ground.",
          "references": [
            99
          ]
        }
      ],
      "references": [
        {
          "id": 99,
          "title": "Virtual Aegean Festival 2025",
          "url": "https://www.aegeanfest.vr",
          "publisher": "Cyclades VR Events",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "multi_user",
        "synchronized_vr",
        "social_immersive",
        "shared_space"
      ],
      "notes": "Together in digital space.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00137",
      "slug": "photogrammetry_for_immersive_heritage",
      "label": "Photogrammetry for Immersive Heritage",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "3d_reconstruction",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Capturing and processing high-resolution photo sets of artifacts and sites into photorealistic 3D models optimized for VR/AR with accurate scale, texture, and material properties.\n\nUsed for virtual museum tours and education.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_photogrammetry",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "digital_heritage",
        "vr_museums",
        "archaeology",
        "preservation"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0380",
          "source_entity_slug": "delphi_statue_scan",
          "evidence_type": "key_work_description",
          "evidence_summary": "1.2 billion polygon scan of Charioteer of Delphi for VR inspection.",
          "references": [
            100
          ]
        }
      ],
      "references": [
        {
          "id": 100,
          "title": "Delphi Charioteer Photogrammetry 2025",
          "url": "https://www.delphicharioteer3d.gr",
          "publisher": "Delphi Digital Archive",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00122"
      ],
      "tags": [
        "photogrammetry",
        "3d_scanning",
        "heritage_digitization",
        "pbr_models"
      ],
      "notes": "Reality captured in polygons.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00138",
      "slug": "immersive_onboarding_and_user_guidance",
      "label": "Immersive Onboarding and User Guidance",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "ux_flow",
      "skill_type": "foundational_skill",
      "evidence_layer": "external_enrichment",
      "description": "Designing intuitive, non-intrusive tutorials and progressive guidance systems that teach VR/AR interactions naturally within the experience.\n\nUses diegetic UI, spatial cues, and voice coaching.",
      "cognitive_level": "intermediate",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "advanced"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_onboarding",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_apps",
        "enterprise_vr",
        "public_installations",
        "first_time_vr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "onboarding",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Guardian spirit teaches teleportation via in-world demo.",
          "references": [
            101
          ]
        }
      ],
      "references": [
        {
          "id": 101,
          "title": "Immersive Onboarding Patterns 2025",
          "url": "https://www.immersiveonboard.org/patterns",
          "publisher": "VR UX Institute",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "onboarding",
        "user_guidance",
        "diegetic_ui",
        "vr_tutorial"
      ],
      "notes": "Teach by doing, not telling.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00139",
      "slug": "spatial_ui_and_diegetic_interfaces",
      "label": "Spatial UI and Diegetic Interfaces",
      "skill_category": "interaction_design",
      "skill_subcategory": "ui_ux",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Designing user interfaces that exist within the 3D world as physical objects—holographic menus, world-attached labels, and interactive environmental controls.\n\nExample: Virtual stone tablet used as pause menu in VR archaeology app.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_spatial_ui",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_ui",
        "diegetic_design",
        "world_space_canvas",
        "immersive_menus"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0390",
          "source_entity_slug": "diegetic_tablet",
          "evidence_type": "key_work_description",
          "evidence_summary": "Clay tablet UI in VR dig site—tap to access tools.",
          "references": [
            102
          ]
        }
      ],
      "references": [
        {
          "id": 102,
          "title": "Diegetic Interfaces in VR 2025",
          "url": "https://www.diegeticui.vr",
          "publisher": "Spatial Interface Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00114"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "diegetic_ui",
        "spatial_interface",
        "world_space",
        "immersive_ux"
      ],
      "notes": "The interface is part of the world.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00140",
      "slug": "motion_sickness_mitigation_strategies",
      "label": "Motion Sickness Mitigation Strategies",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "user_comfort",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Applying comfort frameworks: fixed horizon, limited acceleration, field of view reduction, teleport locomotion, and vignette effects to reduce VR sickness.\n\nCritical for long-duration experiences.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_comfort",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "long_form_vr",
        "public_vr",
        "education",
        "healthcare"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "comfort",
          "evidence_type": "key_concept_description",
          "evidence_summary": "90-minute VR tour with <5% dropout due to comfort settings.",
          "references": [
            103
          ]
        }
      ],
      "references": [
        {
          "id": 103,
          "title": "VR Comfort Framework 2025",
          "url": "https://www.vrcomfort.org/framework",
          "publisher": "Immersive Health Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "motion_sickness",
        "comfort_mode",
        "vr_health",
        "user_retention"
      ],
      "notes": "Keep them in, not reaching for the headset off.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00141",
      "slug": "immersive_content_localization",
      "label": "Immersive Content Localization",
      "skill_category": "production_and_management",
      "skill_subcategory": "globalization",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Adapting VR/AR experiences for different languages, cultures, and regions—translating voice, text, symbols, gestures, and adjusting narrative references.\n\nExample: Greek VR tour with localized myths for Japanese audience.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_localization",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "global_tourism",
        "education",
        "enterprise",
        "cultural_export"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0400",
          "source_entity_slug": "olympics_vr_jp",
          "evidence_type": "key_work_description",
          "evidence_summary": "Olympic VR localized in Japanese with Shinto ritual integration.",
          "references": [
            104
          ]
        }
      ],
      "references": [
        {
          "id": 104,
          "title": "Olympic VR Japan Edition 2025",
          "url": "https://www.olympicvr.jp",
          "publisher": "Japan VR Heritage",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "localization",
        "l10n",
        "cultural_adaptation",
        "global_vr"
      ],
      "notes": "Same world, different meaning.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00142",
      "slug": "vr_facial_animation_and_lip_sync",
      "label": "VR Facial Animation and Lip Sync",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "digital_humans",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Creating believable facial expressions and accurate lip sync for virtual characters in VR using blendshapes, audio-driven animation, and eye dart behaviors.\n\nCritical for emotional connection in social and narrative VR.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_face_anim",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "social_vr",
        "vr_storytelling",
        "virtual_guides",
        "training"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "face_sync",
          "evidence_type": "key_concept_description",
          "evidence_summary": "AI lip sync for virtual Socrates in 12 languages.",
          "references": [
            105
          ]
        }
      ],
      "references": [
        {
          "id": 105,
          "title": "VR Facial Animation Pipeline 2025",
          "url": "https://www.vrface.org/pipeline",
          "publisher": "Digital Human Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "facial_animation",
        "lip_sync",
        "digital_human",
        "expression"
      ],
      "notes": "Eyes and mouth sell the soul.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00143",
      "slug": "360_degree_cinematography_grammar",
      "label": "360-Degree Cinematography Grammar",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "immersive_filmmaking",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Applying film language in spherical space: proximity = intimacy, vertical motion = power, audio cues = cut equivalents, and viewer position = camera.\n\nReplaces traditional framing with spatial relationships.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_360_dp",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "360_video",
        "vr_cinema",
        "documentary",
        "narrative_vr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0410",
          "source_entity_slug": "crete_360_film",
          "evidence_type": "key_work_description",
          "evidence_summary": "360 short film using altitude to denote emotional ascent.",
          "references": [
            106
          ]
        }
      ],
      "references": [
        {
          "id": 106,
          "title": "Crete 360 Cinematography 2025",
          "url": "https://www.crete360.film",
          "publisher": "Minoan VR Cinema",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00112"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "360_cinema",
        "spherical_grammar",
        "vr_filmmaking",
        "direction"
      ],
      "notes": "No frame, only field.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00144",
      "slug": "ethical_ai_use_in_immersive_storytelling",
      "label": "Ethical AI Use in Immersive Storytelling",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "ethics",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Ensuring AI-generated characters, voices, and narratives respect consent, cultural accuracy, and avoid manipulation—especially in historical or educational VR.\n\nIncludes bias audits and transparency.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ethics",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "ai_narrative",
        "historical_vr",
        "education",
        "policy"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "ai_ethics",
          "evidence_type": "key_concept_description",
          "evidence_summary": "AI Pericles voice trained only on public domain texts.",
          "references": [
            107
          ]
        }
      ],
      "references": [
        {
          "id": 107,
          "title": "Ethical AI in VR Guidelines 2025",
          "url": "https://www.ethicvr.org/guidelines",
          "publisher": "Immersive Ethics Council",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ai_ethics",
        "responsible_ai",
        "cultural_sensitivity",
        "bias"
      ],
      "notes": "Power with responsibility.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00145",
      "slug": "location_based_vr_experience_design",
      "label": "Location-Based VR Experience Design",
      "skill_category": "production_and_management",
      "skill_subcategory": "lbe_vr",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Creating high-throughput, safe, and repeatable VR attractions for public venues with tracked backpacks, haptic vests, and physical sets.\n\nExample: 20-minute VR journey through ancient Olympia in a 500m² arena.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_lbe",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "theme_parks",
        "museums",
        "festivals",
        "lbe"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0420",
          "source_entity_slug": "olympia_lbe",
          "evidence_type": "key_work_description",
          "evidence_summary": "600 visitors/hour through tracked VR Olympic experience.",
          "references": [
            108
          ]
        }
      ],
      "references": [
        {
          "id": 108,
          "title": "Olympia LBE VR 2025",
          "url": "https://www.olympialbe.gr",
          "publisher": "Olympia VR Arena",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00134"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "lbe_vr",
        "location_based",
        "arena_scale",
        "throughput"
      ],
      "notes": "VR for the masses, safely.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00146",
      "slug": "immersive_performance_capture_direction",
      "label": "Immersive Performance Capture Direction",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "acting_in_vr",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Directing actors in motion capture suits within virtual environments, using real-time playback and VR headsets to guide performance in digital space.\n\nCombines theater direction with technical precision.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_mocap_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_cinema",
        "digital_theater",
        "virtual_production",
        "mocap"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "perf_capture",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Actor performs in VR Colosseum with live digital audience.",
          "references": [
            109
          ]
        }
      ],
      "references": [
        {
          "id": 109,
          "title": "Immersive Performance Capture 2025",
          "url": "https://www.immersiveperf.org/capture",
          "publisher": "Virtual Stage Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [
        "skill_00118"
      ],
      "tags": [
        "performance_capture",
        "mocap",
        "virtual_acting",
        "digital_directing"
      ],
      "notes": "Directing in the matrix.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00147",
      "slug": "ar_historical_reconstruction",
      "label": "AR Historical Reconstruction",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "augmented_reality",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Using AR to overlay historical reconstructions on real-world sites, ensuring accurate scale, lighting alignment with real-time environmental conditions, and interactive elements for educational tours. Practitioners must integrate 3D models with geospatial data and historical records to create seamless AR experiences.\n\nExample: AR Parthenon restoration on the Acropolis, allowing visitors to interact with a 5th-century BCE temple overlay.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ar_reconstruction",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "cultural_heritage",
        "archaeology",
        "tourism",
        "education"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0421",
          "source_entity_slug": "parthenon_ar",
          "evidence_type": "key_work_description",
          "evidence_summary": "AR Parthenon project overlays a fully reconstructed temple with interactive historical annotations for 10,000 monthly visitors.",
          "references": [
            110
          ]
        }
      ],
      "references": [
        {
          "id": 110,
          "title": "Parthenon AR Restoration 2025",
          "url": "https://www.acropolis-ar.org/parthenon",
          "publisher": "Hellenic AR Heritage",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ar_reconstruction",
        "cultural_heritage",
        "geospatial_ar",
        "historical_accuracy"
      ],
      "notes": "Requires collaboration with historians and 3D artists for authenticity.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00148",
      "slug": "haptic_feedback_design",
      "label": "Haptic Feedback Design for Immersive Experiences",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "haptics",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing tactile feedback patterns for VR/AR wearables to enhance immersion, such as simulating textures, impacts, or environmental cues. Involves mapping haptic responses to narrative beats and user actions.\n\nExample: Haptic vest simulating rain in a VR forest experience.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_haptics",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_gaming",
        "location_based_vr",
        "training_simulations",
        "narrative_vr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "haptic_forest",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Haptic vest used in Amazon VR experience to simulate rain and wind, increasing user retention by 15%.",
          "references": [
            111
          ]
        }
      ],
      "references": [
        {
          "id": 111,
          "title": "Haptic Design for VR 2025",
          "url": "https://www.hapticlab.org/vr2025",
          "publisher": "Immersive Haptic Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00145"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "haptics",
        "tactile_feedback",
        "vr_wearables",
        "immersion"
      ],
      "notes": "Critical for multi-sensory storytelling.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00149",
      "slug": "spatial_audio_narrative_design",
      "label": "Spatial Audio Narrative Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "audio_design",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Crafting 3D audio environments that guide viewer attention and enhance storytelling in VR/AR. Involves placing sound sources in a 360° field to align with narrative cues and spatial visuals.\n\nExample: VR documentary with spatial audio of crowd murmurs directing focus to key events.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_spatial_audio",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_cinema",
        "documentary",
        "location_based_vr",
        "ar_tours"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0422",
          "source_entity_slug": "berlin_wall_vr",
          "evidence_type": "key_work_description",
          "evidence_summary": "Berlin Wall VR uses spatial audio to simulate crowd sounds, guiding attention to historical moments.",
          "references": [
            112
          ]
        }
      ],
      "references": [
        {
          "id": 112,
          "title": "Berlin Wall VR Audio Design 2025",
          "url": "https://www.berlinvr.org/audio",
          "publisher": "History VR Studio",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00143"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "spatial_audio",
        "3d_sound",
        "narrative_cues",
        "immersion"
      ],
      "notes": "Audio as a storytelling anchor in spherical spaces.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00150",
      "slug": "vr_collaborative_direction",
      "label": "Collaborative VR Experience Direction",
      "skill_category": "production_and_management",
      "skill_subcategory": "team_coordination",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Directing multi-user VR experiences where participants interact in shared virtual spaces, requiring real-time narrative adjustments and team coordination.\n\nExample: VR conference with 100 avatars moderated in real-time.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_collaborative_vr",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "social_vr",
        "virtual_events",
        "training",
        "education"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "vr_conference",
          "evidence_type": "key_concept_description",
          "evidence_summary": "VR conference with dynamic narrative shifts based on user interactions, hosting 100 simultaneous avatars.",
          "references": [
            113
          ]
        }
      ],
      "references": [
        {
          "id": 113,
          "title": "Collaborative VR Framework 2025",
          "url": "https://www.vrcollab.org/framework",
          "publisher": "Virtual Events Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "collaborative_vr",
        "multi_user",
        "real_time_direction",
        "social_vr"
      ],
      "notes": "Balancing narrative control with user agency.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00151",
      "slug": "immersive_exhibition_curation",
      "label": "Immersive Exhibition Curation",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "curatorial_practice",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Curating physical and virtual objects in immersive gallery spaces, using AR/VR to enhance visitor engagement and narrative flow.\n\nExample: VR art gallery with interactive artist commentary overlays.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_exhibition",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "museums",
        "galleries",
        "cultural_events",
        "education"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0423",
          "source_entity_slug": "louvre_vr",
          "evidence_type": "key_work_description",
          "evidence_summary": "Louvre VR exhibition with AR annotations for 50 artworks, increasing visitor dwell time by 20%.",
          "references": [
            114
          ]
        }
      ],
      "references": [
        {
          "id": 114,
          "title": "Louvre VR Exhibition 2025",
          "url": "https://www.louvre-vr.org/exhibition",
          "publisher": "Louvre Digital",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00147"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "exhibition_design",
        "vr_curation",
        "ar_museums",
        "narrative_flow"
      ],
      "notes": "Blending physical and virtual storytelling.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00152",
      "slug": "real_time_vr_rendering_optimization",
      "label": "Real-Time VR Rendering Optimization",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "rendering_techniques",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Optimizing 3D assets and shaders for real-time VR rendering to maintain 90 FPS, reducing latency and motion sickness.\n\nExample: Optimized VR cityscape with dynamic LOD for mobile headsets.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_tech_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_gaming",
        "location_based_vr",
        "mobile_vr",
        "training"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "vr_cityscape",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Tokyo VR cityscape optimized for Quest 3, maintaining 90 FPS with dynamic LOD.",
          "references": [
            115
          ]
        }
      ],
      "references": [
        {
          "id": 115,
          "title": "VR Rendering Optimization Guide 2025",
          "url": "https://www.vrtechlab.org/rendering",
          "publisher": "VR Tech Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00140"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "vr_rendering",
        "real_time",
        "optimization",
        "motion_sickness"
      ],
      "notes": "Performance is immersion’s backbone.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00153",
      "slug": "immersive_user_flow_design",
      "label": "Immersive User Flow Design",
      "skill_category": "production_and_management",
      "skill_subcategory": "user_experience",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Designing intuitive navigation and interaction flows for VR/AR experiences, ensuring users can explore without frustration.\n\nExample: VR museum tour with gaze-based menu triggers.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ux",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_tourism",
        "education",
        "training",
        "museums"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0424",
          "source_entity_slug": "met_vr_tour",
          "evidence_type": "key_work_description",
          "evidence_summary": "Metropolitan Museum VR tour with gaze-based navigation, reducing user errors by 30%.",
          "references": [
            116
          ]
        }
      ],
      "references": [
        {
          "id": 116,
          "title": "Met VR Tour UX Design 2025",
          "url": "https://www.metvr.org/ux",
          "publisher": "Metropolitan Museum Digital",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ux_design",
        "user_flow",
        "vr_navigation",
        "intuitive_interaction"
      ],
      "notes": "Ease of use drives engagement.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00154",
      "slug": "ar_interactive_narrative_design",
      "label": "AR Interactive Narrative Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "interactive_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Creating branching AR narratives that respond to user actions and real-world contexts, blending physical and digital story elements.\n\nExample: AR city tour with narrative forks based on user location.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ar_narrative",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "tourism",
        "education",
        "gaming",
        "public_art"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0425",
          "source_entity_slug": "rome_ar_tour",
          "evidence_type": "key_work_description",
          "evidence_summary": "Rome AR tour with branching narratives tied to Colosseum or Forum visits.",
          "references": [
            117
          ]
        }
      ],
      "references": [
        {
          "id": 117,
          "title": "Rome AR Narrative Tour 2025",
          "url": "https://www.romear.org/tour",
          "publisher": "Italy AR Studio",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00147"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ar_narrative",
        "interactive_story",
        "branching_narrative",
        "contextual_ar"
      ],
      "notes": "Story follows the user’s path.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00155",
      "slug": "vr_safety_protocol_design",
      "label": "VR Safety Protocol Design",
      "skill_category": "production_and_management",
      "skill_subcategory": "safety_management",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Developing safety protocols for location-based VR, including guardian boundaries, crowd control, and emergency exits.\n\nExample: Safety system for 500m² VR arena with 50 users.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_safety",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "location_based_vr",
        "theme_parks",
        "festivals",
        "training"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "vr_arena_safety",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Safety protocols for VR arena reduced incidents to under 1% for 10,000 users.",
          "references": [
            118
          ]
        }
      ],
      "references": [
        {
          "id": 118,
          "title": "VR Safety Guidelines 2025",
          "url": "https://www.vrsafety.org/guidelines",
          "publisher": "Immersive Safety Council",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00145"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "vr_safety",
        "location_based",
        "crowd_control",
        "guardian_system"
      ],
      "notes": "Safety ensures scalability.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00156",
      "slug": "immersive_data_visualization",
      "label": "Immersive Data Visualization Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "data_visualization",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Creating interactive VR/AR visualizations of complex datasets, making abstract data tangible through spatial metaphors.\n\nExample: VR climate model with 3D heatmaps.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_data_viz",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "science_communication",
        "education",
        "policy",
        "data_analysis"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0426",
          "source_entity_slug": "climate_vr",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR climate model with interactive 3D heatmaps used in UN conference.",
          "references": [
            119
          ]
        }
      ],
      "references": [
        {
          "id": 119,
          "title": "Climate VR Data Viz 2025",
          "url": "https://www.climatevr.org/dataviz",
          "publisher": "UN Digital Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "data_viz",
        "vr_visualization",
        "spatial_data",
        "science_communication"
      ],
      "notes": "Data becomes a story in 3D.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00157",
      "slug": "vr_character_interaction_design",
      "label": "VR Character Interaction Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "character_development",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Designing interactive NPC behaviors in VR that respond to user gestures, voice, and gaze, enhancing narrative immersion.\n\nExample: VR guide character adapting dialogue based on user questions.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_character_design",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_storytelling",
        "education",
        "tourism",
        "training"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0427",
          "source_entity_slug": "egypt_vr_guide",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR Egyptian guide NPC with dynamic dialogue for Pyramid tour.",
          "references": [
            120
          ]
        }
      ],
      "references": [
        {
          "id": 120,
          "title": "Egypt VR Guide Design 2025",
          "url": "https://www.egyptvr.org/guide",
          "publisher": "Cairo VR Studio",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00142"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "npc_design",
        "interactive_character",
        "vr_dialogue",
        "immersion"
      ],
      "notes": "Characters must feel alive in VR.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00158",
      "slug": "ar_spatial_annotation",
      "label": "AR Spatial Annotation Design",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "augmented_reality",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Creating contextual AR annotations that anchor to real-world objects, providing interactive information without cluttering the view.\n\nExample: AR museum labels floating beside artifacts.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ar_annotation",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "museums",
        "education",
        "tourism",
        "retail"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0428",
          "source_entity_slug": "british_museum_ar",
          "evidence_type": "key_work_description",
          "evidence_summary": "British Museum AR with 200 artifact annotations, reducing guidebook use by 40%.",
          "references": [
            121
          ]
        }
      ],
      "references": [
        {
          "id": 121,
          "title": "British Museum AR Annotations 2025",
          "url": "https://www.britishmuseum-ar.org/annotations",
          "publisher": "BM Digital",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00151"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ar_annotation",
        "spatial_ui",
        "contextual_info",
        "museum_ar"
      ],
      "notes": "Information must enhance, not distract.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00159",
      "slug": "vr_narrative_pacing_control",
      "label": "VR Narrative Pacing Control",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "story_structure",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Controlling the rhythm and tempo of VR stories to maintain engagement, using spatial cues and user interactions to guide pacing.\n\nExample: VR thriller with escalating audio-visual cues to build tension.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_narrative",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_cinema",
        "narrative_vr",
        "gaming",
        "education"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0429",
          "source_entity_slug": "vr_thriller",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR thriller with dynamic pacing tied to user gaze and spatial audio.",
          "references": [
            122
          ]
        }
      ],
      "references": [
        {
          "id": 122,
          "title": "VR Thriller Pacing Study 2025",
          "url": "https://www.vrstudio.org/thriller",
          "publisher": "VR Narrative Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00143"
      ],
      "is_component_of": [
        "skill_00001"
      ],
      "is_prerequisite_for": [],
      "tags": [
        "narrative_pacing",
        "vr_storytelling",
        "spatial_cues",
        "engagement"
      ],
      "notes": "Pacing is the pulse of VR stories.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00160",
      "slug": "immersive_crowd_simulation",
      "label": "Immersive Crowd Simulation Design",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "simulation",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Simulating realistic crowd behaviors in VR to enhance immersion in public or historical scenes.\n\nExample: VR Roman Forum with 500 simulated pedestrians.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_simulation",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "historical_vr",
        "gaming",
        "training",
        "urban_planning"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "roman_forum_vr",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Roman Forum VR with AI-driven crowd of 500, enhancing historical realism.",
          "references": [
            123
          ]
        }
      ],
      "references": [
        {
          "id": 123,
          "title": "VR Crowd Simulation Guide 2025",
          "url": "https://www.vrsim.org/crowds",
          "publisher": "Simulation VR Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "crowd_simulation",
        "vr_population",
        "ai_behavior",
        "immersion"
      ],
      "notes": "Crowds bring worlds to life.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00161",
      "slug": "vr_accessibility_design",
      "label": "VR Accessibility Design",
      "skill_category": "production_and_management",
      "skill_subcategory": "inclusivity",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing VR experiences with accessibility features like voice navigation, adjustable text sizes, and motion-free modes for diverse users.\n\nExample: VR museum with audio descriptions for visually impaired users.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_accessibility",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "education",
        "museums",
        "public_vr",
        "healthcare"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "accessible_vr",
          "evidence_type": "key_concept_description",
          "evidence_summary": "VR museum tour with audio navigation for 5,000 visually impaired users.",
          "references": [
            124
          ]
        }
      ],
      "references": [
        {
          "id": 124,
          "title": "VR Accessibility Standards 2025",
          "url": "https://www.vraccess.org/standards",
          "publisher": "Inclusive VR Council",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "accessibility",
        "inclusive_design",
        "vr_for_all",
        "user_diversity"
      ],
      "notes": "Immersion for everyone.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00162",
      "slug": "immersive_light_design",
      "label": "Immersive Lighting Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "visual_design",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Crafting dynamic lighting in VR/AR to enhance mood, guide attention, and align with narrative arcs.\n\nExample: VR opera with lighting shifts to mirror emotional beats.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_lighting",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_cinema",
        "virtual_theater",
        "gaming",
        "exhibitions"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0430",
          "source_entity_slug": "vr_opera",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR opera with dynamic lighting synced to musical crescendos.",
          "references": [
            125
          ]
        }
      ],
      "references": [
        {
          "id": 125,
          "title": "VR Opera Lighting Design 2025",
          "url": "https://www.vropera.org/lighting",
          "publisher": "Virtual Stage Studio",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00143"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "lighting_design",
        "vr_visuals",
        "narrative_mood",
        "immersion"
      ],
      "notes": "Light shapes emotion in VR.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00163",
      "slug": "vr_dynamic_environment_design",
      "label": "VR Dynamic Environment Design",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "environment_design",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Creating VR environments that adapt to user actions or time, such as changing weather or evolving landscapes.\n\nExample: VR jungle that grows over a 30-minute experience.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environment",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_gaming",
        "narrative_vr",
        "education",
        "tourism"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0431",
          "source_entity_slug": "vr_jungle",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR jungle with real-time flora growth, enhancing immersion for 20,000 users.",
          "references": [
            126
          ]
        }
      ],
      "references": [
        {
          "id": 126,
          "title": "VR Jungle Environment 2025",
          "url": "https://www.vrjungle.org/design",
          "publisher": "Eco VR Studio",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "dynamic_environment",
        "vr_worlds",
        "adaptive_design",
        "immersion"
      ],
      "notes": "Worlds that evolve with the user.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00164",
      "slug": "immersive_project_management",
      "label": "Immersive Project Management",
      "skill_category": "production_and_management",
      "skill_subcategory": "project_management",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Managing interdisciplinary teams for VR/AR projects, balancing creative, technical, and logistical demands.\n\nExample: Coordinating 50-person team for a location-based VR attraction.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_project_manager",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "location_based_vr",
        "vr_cinema",
        "gaming",
        "education"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "vr_attraction",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Managed 50-person team for VR attraction, delivered on time with 98% user satisfaction.",
          "references": [
            127
          ]
        }
      ],
      "references": [
        {
          "id": 127,
          "title": "Immersive Project Management Guide 2025",
          "url": "https://www.vrprojects.org/guide",
          "publisher": "VR Management Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00145"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "project_management",
        "vr_production",
        "team_coordination",
        "logistics"
      ],
      "notes": "Orchestrating chaos into immersion.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00165",
      "slug": "vr_gamification_design",
      "label": "VR Gamification Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "gamification",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Integrating game mechanics into non-gaming VR experiences to boost engagement, such as rewards or challenges.\n\nExample: VR history lesson with point-based quizzes.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_gamification",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "education",
        "training",
        "tourism",
        "healthcare"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0432",
          "source_entity_slug": "vr_history",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR history lesson with gamified quizzes, increasing retention by 25%.",
          "references": [
            128
          ]
        }
      ],
      "references": [
        {
          "id": 128,
          "title": "VR Gamification Study 2025",
          "url": "https://www.vrgamify.org/study",
          "publisher": "Edu VR Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "gamification",
        "vr_engagement",
        "game_mechanics",
        "education"
      ],
      "notes": "Play drives learning in VR.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00166",
      "slug": "ar_public_space_integration",
      "label": "AR Public Space Integration",
      "skill_category": "production_and_management",
      "skill_subcategory": "public_installations",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Designing AR experiences for public spaces, ensuring compatibility with diverse devices and urban environments.\n\nExample: AR art installation in Times Square.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_public_ar",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "public_art",
        "urban_tourism",
        "festivals",
        "retail"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0433",
          "source_entity_slug": "times_square_ar",
          "evidence_type": "key_work_description",
          "evidence_summary": "Times Square AR art with 100,000 daily interactions across 5G networks.",
          "references": [
            129
          ]
        }
      ],
      "references": [
        {
          "id": 129,
          "title": "Times Square AR Installation 2025",
          "url": "https://www.timesar.org/installation",
          "publisher": "NYC AR Collective",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00154"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "public_ar",
        "urban_ar",
        "large_scale_ar",
        "device_compatibility"
      ],
      "notes": "AR must blend into the city.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00167",
      "slug": "vr_emotional_engagement_design",
      "label": "VR Emotional Engagement Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "emotional_design",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Crafting VR experiences that evoke specific emotional responses through visuals, audio, and interactions.\n\nExample: VR therapy session with calming ocean visuals.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_emotional_design",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "healthcare",
        "education",
        "narrative_vr",
        "therapy"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0434",
          "source_entity_slug": "vr_therapy",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR therapy with ocean visuals reducing anxiety in 80% of users.",
          "references": [
            130
          ]
        }
      ],
      "references": [
        {
          "id": 130,
          "title": "VR Therapy Design 2025",
          "url": "https://www.vrtherapy.org/design",
          "publisher": "Mental Health VR Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00159"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "emotional_design",
        "vr_therapy",
        "user_engagement",
        "immersion"
      ],
      "notes": "Emotion is the heart of VR.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00168",
      "slug": "immersive_analytics_direction",
      "label": "Immersive Analytics Direction",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "data_analysis",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Directing VR/AR analytics tools that allow users to interact with data in 3D, enhancing decision-making.\n\nExample: VR financial dashboard with 3D trend graphs.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_analytics",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "finance",
        "business",
        "science",
        "policy"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "vr_finance",
          "evidence_type": "key_concept_description",
          "evidence_summary": "VR financial dashboard with interactive 3D graphs, improving analysis speed by 30%.",
          "references": [
            131
          ]
        }
      ],
      "references": [
        {
          "id": 131,
          "title": "Immersive Analytics Guide 2025",
          "url": "https://www.vranalytics.org/guide",
          "publisher": "Data VR Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00156"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "immersive_analytics",
        "vr_data",
        "3d_graphs",
        "decision_making"
      ],
      "notes": "Data in 3D accelerates insights.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00169",
      "slug": "vr_training_scenario_design",
      "label": "VR Training Scenario Design",
      "skill_category": "production_and_management",
      "skill_subcategory": "training_development",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Creating VR training modules with realistic scenarios, feedback loops, and performance tracking.\n\nExample: VR firefighter training with dynamic fire spread.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_training",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "emergency_services",
        "healthcare",
        "military",
        "industry"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0435",
          "source_entity_slug": "vr_firefighter",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR firefighter training with AI-driven fire behavior, used by 500 trainees.",
          "references": [
            132
          ]
        }
      ],
      "references": [
        {
          "id": 132,
          "title": "VR Firefighter Training 2025",
          "url": "https://www.vrfire.org/training",
          "publisher": "Emergency VR Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "vr_training",
        "scenario_design",
        "simulation",
        "performance_tracking"
      ],
      "notes": "Real skills through virtual practice.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00170",
      "slug": "immersive_social_impact_design",
      "label": "Immersive Social Impact Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "social_impact",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Creating VR/AR experiences to drive social change, addressing issues like equality or sustainability.\n\nExample: VR refugee camp simulation for empathy training.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_social_impact",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "education",
        "policy",
        "ngo_campaigns",
        "public_awareness"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0436",
          "source_entity_slug": "vr_refugee",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR refugee camp simulation used by UNHCR for 10,000 trainees.",
          "references": [
            133
          ]
        }
      ],
      "references": [
        {
          "id": 133,
          "title": "VR Refugee Empathy Project 2025",
          "url": "https://www.vrrefugee.org/project",
          "publisher": "UNHCR Digital",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00167"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "social_impact",
        "vr_empathy",
        "sustainability",
        "public_awareness"
      ],
      "notes": "VR as a tool for change.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00171",
      "slug": "vr_cross_platform_design",
      "label": "VR Cross-Platform Design",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "platform_optimization",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing VR experiences that adapt to multiple platforms, from high-end PC VR to mobile headsets.\n\nExample: VR tour optimized for Quest and PSVR.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_cross_platform",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "vr_gaming",
        "tourism",
        "education",
        "enterprise"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "vr_tour_platform",
          "evidence_type": "key_concept_description",
          "evidence_summary": "VR city tour deployed on Quest and PSVR with consistent UX.",
          "references": [
            134
          ]
        }
      ],
      "references": [
        {
          "id": 134,
          "title": "VR Cross-Platform Design Guide 2025",
          "url": "https://www.vrplatforms.org/guide",
          "publisher": "VR Tech Studio",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00152"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "cross_platform",
        "vr_optimization",
        "platform_adaptation",
        "ux_consistency"
      ],
      "notes": "One experience, many devices.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00172",
      "slug": "immersive_feedback_loop_design",
      "label": "Immersive Feedback Loop Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "user_interaction",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Designing feedback systems in VR/AR that reinforce user actions through visual, audio, and haptic cues.\n\nExample: VR training with real-time performance feedback.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_feedback",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "training",
        "education",
        "gaming",
        "healthcare"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0437",
          "source_entity_slug": "vr_medical_training",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR medical training with haptic and visual feedback, improving skill retention by 35%.",
          "references": [
            135
          ]
        }
      ],
      "references": [
        {
          "id": 135,
          "title": "VR Feedback Design 2025",
          "url": "https://www.vrfeedback.org/design",
          "publisher": "Immersive Learning Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00148"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "feedback_loop",
        "user_interaction",
        "haptic_cues",
        "vr_training"
      ],
      "notes": "Feedback makes actions meaningful.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00173",
      "slug": "vr_ethical_narrative_design",
      "label": "VR Ethical Narrative Design",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "ethics",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Crafting VR narratives that avoid manipulation, respect user agency, and address sensitive topics responsibly.\n\nExample: VR historical drama with balanced perspectives.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ethics_narrative",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "historical_vr",
        "education",
        "public_awareness",
        "policy"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "vr_history_ethics",
          "evidence_type": "key_concept_description",
          "evidence_summary": "VR Civil War drama with balanced narratives, used in 200 schools.",
          "references": [
            136
          ]
        }
      ],
      "references": [
        {
          "id": 136,
          "title": "Ethical VR Narrative Guidelines 2025",
          "url": "https://www.vrethics.org/narrative",
          "publisher": "VR Ethics Board",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00144"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ethical_narrative",
        "vr_ethics",
        "user_agency",
        "responsible_design"
      ],
      "notes": "Stories with integrity.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00174",
      "slug": "ar_dynamic_content_delivery",
      "label": "AR Dynamic Content Delivery",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "content_management",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Delivering real-time AR content based on user location, time, or preferences, using cloud-based systems.\n\nExample: AR festival guide updating with live event schedules.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ar_content",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "festivals",
        "tourism",
        "retail",
        "public_events"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0438",
          "source_entity_slug": "coachella_ar",
          "evidence_type": "key_work_description",
          "evidence_summary": "Coachella AR guide with live updates for 50,000 users.",
          "references": [
            137
          ]
        }
      ],
      "references": [
        {
          "id": 137,
          "title": "Coachella AR Guide 2025",
          "url": "https://www.coachella-ar.org/guide",
          "publisher": "Festival AR Studio",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00166"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ar_content",
        "dynamic_delivery",
        "cloud_ar",
        "real_time"
      ],
      "notes": "Content that moves with the user.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00175",
      "slug": "vr_multi_sensory_integration",
      "label": "VR Multi-Sensory Integration",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "sensory_design",
      "skill_type": "complex_competence",
      "evidence_layer": "base_dataset",
      "description": "Integrating visual, audio, haptic, and olfactory cues in VR to create cohesive sensory experiences.\n\nExample: VR vineyard tour with grape scent and haptic soil feedback.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_sensory",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "tourism",
        "education",
        "therapy",
        "gaming"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "cdim_0439",
          "source_entity_slug": "vr_vineyard",
          "evidence_type": "key_work_description",
          "evidence_summary": "VR vineyard tour with olfactory and haptic integration for 15,000 users.",
          "references": [
            138
          ]
        }
      ],
      "references": [
        {
          "id": 138,
          "title": "VR Sensory Integration 2025",
          "url": "https://www.vrsensory.org/integration",
          "publisher": "Sensory VR Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00148"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "multi_sensory",
        "vr_immersion",
        "haptic_design",
        "olfactory_cues"
      ],
      "notes": "All senses tell the story.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00176",
      "slug": "immersive_ip_management",
      "label": "Immersive Intellectual Property Management",
      "skill_category": "production_and_management",
      "skill_subcategory": "legal_management",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Managing intellectual property rights for VR/AR content, including licensing and cultural sensitivity.\n\nExample: Licensing historical figures for VR museum.",
      "cognitive_level": "expert",
      "proficiency_levels": [
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ip_management",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "museums",
        "education",
        "entertainment",
        "cultural_heritage"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "vr_ip",
          "evidence_type": "key_concept_description",
          "evidence_summary": "Managed IP for VR historical figures, ensuring legal and cultural compliance.",
          "references": [
            139
          ]
        }
      ],
      "references": [
        {
          "id": 139,
          "title": "VR IP Management Guide 2025",
          "url": "https://www.vrip.org/guide",
          "publisher": "VR Legal Lab",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00144"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [
        "ip_management",
        "vr_legal",
        "cultural_sensitivity",
        "licensing"
      ],
      "notes": "Protecting creativity legally.",
      "created": "2025-11-15",
      "last_updated": "2025-11-15"
    },
    {
      "id": "skill_00177",
      "slug": "unity_xr_prototyping_immersive_installations",
      "label": "Unity XR prototyping for immersive installations",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "game_engines",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing and prototyping XR interactions and scenes in Unity for room-scale and installation-based immersive experiences, using the XR Interaction Toolkit to handle input, locomotion, and interactable objects.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_producer",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_ar",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "unity_xr_apps",
        "interactive_installations",
        "lbe_vr",
        "museum_installations"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            140
          ]
        }
      ],
      "references": [
        {
          "id": 140,
          "title": "XR Interaction Toolkit overview",
          "url": "https://docs.unity3d.com/Packages/com.unity.xr.interaction.toolkit@3.2/manual/interaction-overview.html",
          "publisher": "Unity Technologies",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00178",
      "slug": "unreal_virtual_production_led_volumes",
      "label": "Unreal Engine virtual production direction for LED volumes",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "virtual_production",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Directing virtual production shoots that use Unreal Engine to drive LED volume backdrops, including scene preparation, color-managed workflows, and collaboration with cinematography and lighting teams.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_producer",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environment",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "virtual_production",
        "led_volumes",
        "film_sets",
        "live_events"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            141
          ]
        }
      ],
      "references": [
        {
          "id": 141,
          "title": "Colour Managed Workflow for ICVFX/LED wall",
          "url": "https://forums.unrealengine.com/t/colour-managed-workflow-for-icvfx-led-wall/2342483",
          "publisher": "Epic Games Developer Community",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00179",
      "slug": "touchdesigner_generative_systems_immersive_shows",
      "label": "TouchDesigner generative systems for immersive shows",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "realtime_visuals",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Leading the design of real-time generative visual systems in TouchDesigner for domes, galleries, and live events, including data-reactive visuals, audio-reactive compositions, and interactive installations.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environment",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_exhibition",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "immersive_installations",
        "domes",
        "media_facades",
        "live_shows"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            142
          ]
        }
      ],
      "references": [
        {
          "id": 142,
          "title": "TouchDesigner 101 Intensive: Creating Interactive Installations and Generative Art",
          "url": "https://grayarea.org/course/touchdesigner-101-interactive-installations-and-generative-art-2025/",
          "publisher": "Gray Area",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00180",
      "slug": "notch_realtime_vfx_direction_concerts_domes",
      "label": "Notch real-time VFX direction for concerts and domes",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "realtime_visuals",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Directing real-time visual effects built in Notch for concerts, domes and large-scale immersive shows, including particle systems, live camera inputs, and integration with media servers.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environment",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_producer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "concert_tours",
        "domes",
        "media_facades",
        "live_events"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            143
          ]
        }
      ],
      "references": [
        {
          "id": 143,
          "title": "Made with Notch",
          "url": "https://www.notch.one/madewithnotch/",
          "publisher": "Notch",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00181",
      "slug": "webxr_experience_architecture_direction",
      "label": "WebXR experience architecture and direction",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "webxr",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing and directing immersive experiences delivered through WebXR in the browser, aligning narrative, interaction patterns, and performance constraints across desktop, mobile, and headset devices.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_cross_platform",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_ar",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "webxr",
        "webxr_experiences",
        "browser_based_vr",
        "visionos_web"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            144
          ]
        }
      ],
      "references": [
        {
          "id": 144,
          "title": "Build immersive web experiences with WebXR",
          "url": "https://developer.apple.com/videos/play/wwdc2024/10066/",
          "publisher": "Apple",
          "year": 2024
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00182",
      "slug": "openusd_pipeline_supervision_virtual_production",
      "label": "OpenUSD pipeline supervision for virtual production",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "pipeline_management",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Supervising OpenUSD-based content pipelines that keep environments, characters, and lighting consistent between DCC tools, virtual production stages, and immersive experiences.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_producer",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_deployment_lead",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "virtual_production",
        "asset_pipelines",
        "cross_platform_content",
        "real_time_graphics"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            145
          ]
        }
      ],
      "references": [
        {
          "id": 145,
          "title": "Producing Cinematic Content at Scale with a Generative AI-Enabled OpenUSD Pipeline",
          "url": "https://developer.nvidia.com/blog/producing-cinematic-content-at-scale-with-a-generative-ai-enabled-openusd-pipeline/",
          "publisher": "NVIDIA Technical Blog",
          "year": 2024
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00183",
      "slug": "led_volume_content_color_pipeline_coordination",
      "label": "LED volume content and color pipeline coordination",
      "skill_category": "production_and_management",
      "skill_subcategory": "technical_supervision",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Coordinating content, color calibration, and hardware requirements for LED volume shoots, ensuring that real-time scenes match camera profiles and physical lighting on set.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_virtual_production",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environment",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "virtual_production",
        "led_volumes",
        "film_sets"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            146
          ]
        }
      ],
      "references": [
        {
          "id": 146,
          "title": "Building the Right Workstation for LED Wall Production",
          "url": "https://blog.themvp.in/building-a-led-wall-workstation-for-virtual-production/",
          "publisher": "The MVP",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00184",
      "slug": "game_engine_previs_blocking_immersive_events",
      "label": "Game engine-based previs and blocking for immersive events",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "previsualisation",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Using game engines for real-time previs and blocking of immersive events, allowing directors to iterate camera moves, light, and audience perspective before full-scale production.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_360_director",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_producer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "virtual_production",
        "immersive_events",
        "stage_previs",
        "domes"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            147
          ]
        }
      ],
      "references": [
        {
          "id": 147,
          "title": "Demonstrating Virtual Production: LED Walls and Unreal Engine",
          "url": "https://www.youtube.com/watch?v=FZXYEMQtKtU",
          "publisher": "Unreal Engine / Epic Games",
          "year": 2024
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00185",
      "slug": "networked_multiuser_vr_world_orchestration",
      "label": "Networked multi-user VR world orchestration",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "networked_vr",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing and orchestrating multi-user VR worlds, balancing narrative beats with networking constraints, latency, and shared interactions across multiple headsets.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_collaborative_vr",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_network_director",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "lbe_vr",
        "social_vr",
        "multiplayer_vr",
        "free_roam_vr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            148
          ]
        }
      ],
      "references": [
        {
          "id": 148,
          "title": "Creating Multi-User VR Experiences: The Technical Challenges",
          "url": "https://metapress.com/creating-multi-user-vr-experiences-the-technical-challenges/",
          "publisher": "MetaPress",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00186",
      "slug": "cloud_streaming_orchestration_immersive_xr",
      "label": "Cloud streaming orchestration for immersive XR applications",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "streaming",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Planning and supervising XR experiences that are streamed from the cloud to lightweight devices, including quality targets, network conditions, and collaboration with IT teams.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_streaming_engineer",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_producer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "remote_xr",
        "lbe_vr",
        "industrial_training",
        "design_review"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            149
          ]
        }
      ],
      "references": [
        {
          "id": 149,
          "title": "VR, AR, and XR Streaming Solutions for Pro Viz",
          "url": "https://www.nvidia.com/en-us/design-visualization/solutions/cloud-xr/",
          "publisher": "NVIDIA",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00187",
      "slug": "xr_performance_optimization_standalone_headsets",
      "label": "XR performance optimization for standalone headsets",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "platform_optimization",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Defining budgets and optimization strategies for XR projects targeting standalone headsets, ensuring stable framerates while preserving core visual and narrative intent.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_perf_engineer",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_producer",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "standalone_headsets",
        "quest_2",
        "quest_3",
        "mobile_vr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            150
          ]
        }
      ],
      "references": [
        {
          "id": 150,
          "title": "How to Optimize XR Performance in Unreal Engine 5 for VR/AR Devices?",
          "url": "https://forums.unrealengine.com/t/how-to-optimize-xr-performance-in-unreal-engine-5-for-vr-ar-devices/2511424",
          "publisher": "Epic Games Developer Community",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00188",
      "slug": "xr_hand_tracking_interaction_design",
      "label": "XR hand-tracking interaction design",
      "skill_category": "interaction_design",
      "skill_subcategory": "input_modalities",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing XR interfaces that use hand tracking instead of controllers, including affordances, feedback, and ergonomics that keep interactions intuitive and comfortable.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_interaction_design",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_vr_ar",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "hand_tracking",
        "controller_free_vr",
        "visionos",
        "gesture_interfaces"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            151
          ]
        }
      ],
      "references": [
        {
          "id": 151,
          "title": "6 VR Design Principles for Hand Tracking",
          "url": "https://docs.ultraleap.com/ultralab/hand-tracking-vr-design.html",
          "publisher": "Ultraleap",
          "year": 2024
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00189",
      "slug": "voice_interface_scripting_immersive_experiences",
      "label": "Voice interface scripting for immersive experiences",
      "skill_category": "interaction_design",
      "skill_subcategory": "voice_interfaces",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Writing and structuring conversational flows and commands for voice-driven interactions inside immersive experiences, coordinating with spatial audio and visual feedback.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_interaction_design",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_communicator",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "voice_ui",
        "voice_assistants",
        "immersive_storyworlds",
        "in_car_xr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            152
          ]
        }
      ],
      "references": [
        {
          "id": 152,
          "title": "Beyond the Screen: Designing for Immersive Experiences with AR, VR, and Voice UI",
          "url": "https://design-battle.com/posts/beyond-the-screen-designing-for-immersive-experiences-with-ar-vr-and-voice-ui",
          "publisher": "Design Battle",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00190",
      "slug": "digital_twin_storytelling_control_rooms_domes",
      "label": "Digital twin storytelling in immersive control rooms and domes",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "data_storytelling",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing narrative views and scenarios around real-time digital twins in control rooms and immersive theaters, helping teams understand complex operations through spatial storytelling.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environmental_storyteller",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_business_intelligence",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "digital_twins",
        "control_rooms",
        "operations_centers",
        "domes"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            153
          ]
        }
      ],
      "references": [
        {
          "id": 153,
          "title": "Transforming Mission-Critical Environments with Digital Twin Technology",
          "url": "https://www.fountainheadcontrolrooms.com/transforming-mission-critical-environments-digital-twin-technology-control-rooms/",
          "publisher": "Fountainhead Control Rooms",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00191",
      "slug": "worldbuilding_persistent_immersive_universes",
      "label": "Worldbuilding for persistent immersive universes",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "worldbuilding",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Developing coherent worlds, histories, and rules that tie together multiple immersive experiences, from VR games to dome shows and AR layers in the same narrative universe.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environmental_storyteller",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_cross_platform",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "persistent_vr_worlds",
        "metaverse_spaces",
        "cross_platform_universes",
        "franchise_storyworlds"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            154
          ]
        }
      ],
      "references": [
        {
          "id": 154,
          "title": "The Art of World-Building: Creating Immersive Game Environments",
          "url": "https://gamepill.com/the-art-of-world-building-creating-immersive-game-environments/",
          "publisher": "Game Pill",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00192",
      "slug": "led_facade_pixel_mapping_direction_architectural_media",
      "label": "LED facade and pixel mapping direction for architectural media",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "media_facades",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Directing content strategies and technical setups for LED media facades, including pixel mapping approaches, media server integration, and synchronization with urban lighting and events.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environment",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_expanded_cinema_multi_projection",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "media_facades",
        "architecture",
        "public_art",
        "outdoor_led"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            155
          ]
        }
      ],
      "references": [
        {
          "id": 155,
          "title": "ELM, the award-winning LED pixel mapping software",
          "url": "https://www.enttec.com/product/dmx-lighting-control-software/pixel-mapping-software-2024/",
          "publisher": "ENTTEC",
          "year": 2024
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00193",
      "slug": "realtime_data_driven_visuals_immersive_environments",
      "label": "Real-time data-driven visuals for immersive environments",
      "skill_category": "technical_and_tools",
      "skill_subcategory": "data_visualisation",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Conceiving and supervising real-time data-driven visuals that turn live data streams into immersive sculptures, walls, or dome projections for audiences.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environment",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_business_intelligence",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "domes",
        "media_facades",
        "data_sculptures",
        "museum_installations"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            156
          ]
        }
      ],
      "references": [
        {
          "id": 156,
          "title": "Interactive Data Sculpture Creation: A Comprehensive Guide for 2024",
          "url": "https://stevezafeiriou.com/interactive-data-sculpture-creation/",
          "publisher": "Steve Zafeiriou",
          "year": 2024
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00194",
      "slug": "ai_driven_data_sculpture_direction_large_scale_canvases",
      "label": "AI-driven data sculpture direction for large-scale immersive canvases",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "ai_and_augmented_creativity",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Directing AI-driven data sculptures for large-scale canvases such as domes or media spheres, curating datasets, guiding machine learning aesthetics, and aligning outputs with narrative themes.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ai_co_creator",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_environment",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "domes",
        "media_facades",
        "sphere_like_venues",
        "museum_installations"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            157
          ]
        }
      ],
      "references": [
        {
          "id": 157,
          "title": "Refik Anadol: Turning Data into Digital Masterpieces",
          "url": "https://www.midmodmag.com/refik-anadol-turning-data-into-digital-masterpieces/",
          "publisher": "MidMod Magazine",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00195",
      "slug": "biometric_gaze_tracking_ethics_review_immersive",
      "label": "Biometric and gaze-tracking ethics review for immersive experiences",
      "skill_category": "research_and_evaluation",
      "skill_subcategory": "ethics",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Assessing the ethical implications of eye tracking and other biometrics in immersive experiences, including consent, data handling, and how such inputs drive adaptive narratives.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ethics",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_eye_narrative",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "eye_tracking",
        "biometric_responsive_narratives",
        "health_vr",
        "research_xr"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            158
          ]
        }
      ],
      "references": [
        {
          "id": 158,
          "title": "Ethical concerns in contemporary virtual reality and frameworks for pursuing responsible use",
          "url": "https://www.frontiersin.org/journals/virtual-reality/articles/10.3389/frvir.2025.1451273/full",
          "publisher": "Frontiers in Virtual Reality",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    },
    {
      "id": "skill_00196",
      "slug": "ai_assisted_worldbuilding_workflows_horizon_xr_platforms",
      "label": "AI-assisted worldbuilding workflows in Horizon-style XR platforms",
      "skill_category": "narrative_and_concept",
      "skill_subcategory": "ai_and_augmented_creativity",
      "skill_type": "complex_competence",
      "evidence_layer": "external_enrichment",
      "description": "Designing workflows where creative directors collaborate with AI-assisted worldbuilding tools in social XR platforms, guiding prompts, scanning real locations, and curating user-generated contributions.",
      "cognitive_level": "advanced",
      "proficiency_levels": [
        "basic_awareness",
        "operational",
        "expert"
      ],
      "associated_role_types": [
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_ai_content_director",
          "source_dataset_id": "cdim"
        },
        {
          "role_family": "creative_director_for_immersive_media",
          "role_subtype_id": "cd_type_collaborative_vr",
          "source_dataset_id": "cdim"
        }
      ],
      "application_contexts": [
        "social_vr",
        "horizon_style_worlds",
        "metaverse_spaces",
        "rapid_prototyping"
      ],
      "derived_from_outputs": [
        {
          "source_dataset_id": "cdim",
          "source_entity_id": "general_immersive_practices",
          "source_entity_slug": "general_immersive_practices",
          "evidence_type": "external_enrichment_synthesis",
          "evidence_summary": "External sources highlight this competence as increasingly important for immersive creative direction.",
          "references": [
            159
          ]
        }
      ],
      "references": [
        {
          "id": 159,
          "title": "Meta's Hyperspace lets you scan the real world and turn it into the Metaverse",
          "url": "https://www.tomsguide.com/computing/vr-ar/metas-hyperspace-lets-you-scan-the-real-world-and-turn-it-into-the-metaverse-and-create-anything-you-want-with-new-ai-tools",
          "publisher": "Tom's Guide",
          "year": 2025
        }
      ],
      "source_datasets": [
        {
          "source_dataset_id": "cdim",
          "source_dataset_name": "Creative Directors for Immersive Media"
        }
      ],
      "overlaps_with_skills": [
        "skill_00041"
      ],
      "is_component_of": [],
      "is_prerequisite_for": [],
      "tags": [],
      "notes": "",
      "created": "2025-11-20",
      "last_updated": "2025-11-20"
    }
  ]
}
